name,description,long_description
RNA-seq: Differential Gene Expression (DGE) Analysis for RNA-seq Data,Differential Gene Expression analysis for high throughput RNA sequencing data.,"DGE analysis is a very common method for RNA-Seq data. This method allows for the investigation of expressed genes between two or more conditions. Tools included in this app are SRA Toolkit, FastQC, STAR, featureCounts, and DESeq2."
scDeepCluster: Deep Clustering for Single Cell RNA-Seq Data,Model-based deep embedding clustering for Single Cell RNA-seq data.,"<p><span style=""color: rgb(34,34,34); background-color: rgb(255,255,255)"">scDeepCluster, is a single-cell model-based deep embedded clustering method, which simultaneously learns feature representation and clustering via explicit modelling of scRNA-seq data generation. Based on testing extensive simulated data and real datasets from four representative single-cell sequencing platforms, scDeepCluster outperformed state-of-the-art methods under various clustering performance metrics and exhibited improved scalability, with running time increasing linearly with sample size. Its accuracy and efficiency make scDeepCluster a promising algorithm for clustering large-scale scRNA-seq data.</span><span style=""font-size: 14px""><br><br></span><span style=""font-weight: bold"">Example use case: </span>exploring cell heterogeneity and diversity in cancer research<span style=""font-weight: bold; font-size: 14px""><br></span><span style=""font-size: 14px""><br></span><span style=""font-weight: bold"">Technology: </span>Autoencoders</p>"
Prostate Region Segmentation: Medical Image-nnUnet,Prostate transitional zone and peripheral zone segmentation,"<p>Prostate multiparametric MRI (mpMRI) studies comprising T2-weighted, Diffusion-weighted and T1-weighted contrast enhanced series.Â </p>"
Brain Tumor Segmentation: Medical Image-nnUnet,Gliomas segmentation tumour and oedema in on brain images,"<p>Segmentation of possible glioma tumours and edemas on brain MRI scans using a pre-trained nnU-Net architecture. Given an MRI scan in .NIfTI format, this app will return your MRI scans with glioma and edema regions highlighted, available for download.</p>
<p>Data requirements: Brain tumor MRI scans, with four MRI modalities as T1w, t1gd, T2w, and FLAIR.</p>
"
Clipper: Find Discoveries in High-Throughput Data,Statistical method for controlling false positive rates in high-throughput biological data with two conditions of diverse types.,"<p>Identifying ""interesting"" features with false discovery rate (FDR) control where ""interesting"" means ""enriched"" or ""differential"", without using <span style=""font-style: italic"">p</span>-values<br><br><span style=""font-weight: bold"">Example use case: </span>identification of differentially expressed genes from genome-wide gene expression data or peak-calling from ChIP-seq data, peptide-identification from mass spectrometry data<br><br><span style=""font-weight: bold"">Limitations: </span>Works best with two conditions</p>"
PathfindR: Enrichment Analysis for Omics Data,"pathfindR is a tool for enrichment analysis via active subnetworks. The package also offers functionalities to cluster the enriched terms and identify representative terms in each cluster, score the enriched terms per sample, and visualize analysis results.","<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">The active-subnetwork-oriented enrichment analysis approach of pathfindR involves mapping input genes onto a protein interaction network, identifying active subnetworks based on their scores and significant gene content, and then performing enrichment analyses to identify significantly enriched terms. The results are reported in a data frame and an HTML report with visualizations.<br></span><br><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Example use case: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">Analyzing gene expression data to identify enriched pathways or gene sets associated with differentially expressed genes<br><br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Technology: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">A software tool for enrichment analysis of gene expression data. Input data should be in .csv, .txt, or .tsv format, and should include 3 columns only: (i) gene names, symbols or pseudonyms, (ii) log fold change (logFC), and (iii) p-values, in this order.</span><span style=""display: inline !important; font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px""><br></span>&nbsp;<span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box""><br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Limitations:<br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">-</span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">&nbsp;</span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">Reliance on protein interaction network data for mapping input genes.</span></div>
<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">- Need for appropriate thresholding of adjusted p-values for enrichment analysis.</span></div>
<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">- Potential for false positives or false negatives in the identification of active subnetworks and enriched terms.</span></div>
<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">- May not be suitable for datasets with small sample sizes or low statistical power.</span></div>
<div style=""--tw-invert: ; --tw-skew-y: 0; box-sizing: border-box; display: block; padding-left: 0.375em; --tw-slashed-zero: ; --tw-backdrop-invert: ; --tw-rotate: 0; list-style-type: disc; --tw-ring-offset-shadow: 0 0 transparent; --tw-ordinal: ; --tw-backdrop-sepia: ; position: relative; --tw-shadow: 0 0 transparent; --tw-ring-inset: ; --tw-scale-x: 1; border: 0px solid rgb(217, 217, 227); --tw-scale-y: 1; --tw-numeric-fraction: ; --tw-contrast: ; --tw-sepia: ; --tw-scroll-snap-strictness: proximity; --tw-numeric-figure: ; margin: 0px; --tw-translate-x: 0; --tw-backdrop-contrast: ; --tw-pinch-zoom: ; --tw-translate-y: 0; --tw-ring-color: rgba(59,130,246,0.5); --tw-blur: ; --tw-ring-shadow: 0 0 transparent; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-saturate: ; --tw-numeric-spacing: ; --tw-backdrop-grayscale: ; --tw-hue-rotate: ; --tw-brightness: ; --tw-ring-offset-color: #fff; --tw-backdrop-saturate: ; --tw-backdrop-hue-rotate: ; --tw-grayscale: ; --tw-pan-x: ; --tw-backdrop-brightness: ; --tw-backdrop-opacity: ; --tw-pan-y: ; --tw-skew-x: 0; --tw-ring-offset-width: 0px; --tw-shadow-colored: 0 0 transparent""><br></div>"
scJoint: Transfer Learning for Combined Annotated CITE-seq and ASAP-seq Data,"scJoint is a transfer learning method to integrate atlas-scale, heterogeneous collections of scRNA-seq and scATAC-seq data.","<p><span style=""font-size: 12px"">scJoint leverages information from annotated scRNA-seq data in a semisupervised framework and uses a neural network to simultaneously train labeled and unlabeled data, allowing label transfer and joint visualization in an integrative framework. Using atlas data as well as multimodal datasets generated with ASAP-seq and CITE-seq, we demonstrate that scJoint is computationally efficient and consistently achieves substantially higher cell-type label accuracy than existing methods while providing meaningful joint visualizations. Thus, scJoint overcomes the heterogeneity of different data modalities to enable a more comprehensive understanding of cellular phenotypes.</span></p>"
Liver Cancer Segmentation: Medical Image-nnUnet,Liver cancer segmentation,"<p>Automatic segmentation of liver and liver tumor in contrast-enhanced abdominal CT scans using a pre-trained nnU-Net architecture.</p>
"
Hippocampus Anterior & Posterior Segmentation: Medical Image-nnUnet,Hippocampus identification and segmentation,"<p>Segments the hippocampus into anterior and posterior regions</p>
"
AlphaFold2: 3D Protein Structure Prediction,AlphaFold predicts 3D models of protein structures and has the potential to accelerate research in every field of biology.,"<p>Revolutionary 3D protein structure prediction model with high accuracy that allows for a close study of proteins without an expensive X-ray crystallography process<br><br><span style=""font-weight: bold"">Example use case: </span>Prediction of protein disorders, studying enzymes, and developing novel protein-based drugs<br><br><span style=""font-weight: bold"">Technology: </span>Novel neural network architectures and training procedures</p>"
Molecule Toxicity Prediction: ChemBERTa with Clintox Dataset,Toxicity prediction for molecules in SMILES-format using ChemBERTa and the ClinTox dataset.,<p>Toxicity prediction for molecules in SMILES-format using ChemBERTa and the ClinTox dataset.</p>
Pancreas Tumor Segmentation: Medical Image-nnUnet,Tumor identification and segmentation in pancreas based on the automated analysis of CT pancreas scans (3D volumes),"<p>Tumor identification and segmentation in pancreas based on the automated analysis of CT pancreas scans (3D volumes)</p>
"
DeepPurpose-DTI: Deep Learning-based Drug Target Interaction Prediction Tool,DeepPurpose is a pytorch-based deep learning framework that is initiated to provide a simple but powerful toolkit for drug-target interaction (DTI) prediction and its related applications.,"<p>Measures the binding strength of drug molecules to the protein targets<br><br><strong>Example use case: </strong>fundamental for drug discovery supporting drug screening and repurposing<br><br><strong>Technology: </strong>Message passing neural network &amp; Convolutional neural network</p>
"
Stardist2D: Cell detection and segmentation,Automatic detection and segmentation of cells and nuclei in microscopy using Stardistâs algorithms. Works well with fluorescent nuclei images.,"<p>Detection and segmentation of cells and nuclei in microscopy. Works well with fluorescent images.<br><br><strong>Example use case: </strong>image-based cellular research &amp; disease<br><br><strong>Technology: </strong>Convolutional neural network<br><br><strong>Limitations: </strong>Currently only accepts black &amp; white images</p>
"
Neural Forecast: Deep Learning for Time Series Forecasting,"NeuralForecast is a Python library for time series forecasting with deep learning models. It includes benchmark datasets, data-loading utilities, evaluation functions, statistical tests, univariate model benchmarks and SOTA models implemented in PyTorch and PyTorchLightning.","<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Nixtla's neuralforecast is a python library for time series forecasting with deep learning models. This app provides AutoRNN functionality, implemented using PyTorch, PyTorchLightning and Ray. This package automatically tests different settings, identifying over multiple iterations which parameters perform the best. The results for the champion model are then provided. If trained using CPU, then a maximum of 32 time series will be processed, while if trained using GPU a maximum of 128 will be processed instead. Models are trained using all series, meaning that with more series included, performance is likely to improve. Models can be saved, and then applied to similar time series, or trained further.</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""><br><br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Please provide data in three columns, in the following order:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc""><span style=""background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">unique_id for each time series (up to 16 time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series)</span></li>
<li style=""list-style-type: disc""><span style=""background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">date-time column can be in any format (date, time, number, other), but must be in ascending order.</span></li>
<li style=""list-style-type: disc""><span style=""background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">value. The value of the time series at each timeÂ </span></li></ul>"
Stats Forecast: ARIMA Modelling for Time Series Forecasting,"StatsForecast offers a collection of widely used univariate time series forecasting models, including automatic ARIMA and ETS modeling optimized for high performance using numba. It also includes a large battery of benchmarking models.","<p>StatsForecast offers a collection of widely used univariate time series forecasting models, including automatic ARIMA and ETS modeling optimized for high performance using numba. It also includes a large battery of benchmarking models.</p>"
ML Forecast: Machine Learning for Time Series Forecasting,"mlForecast allows users to apply scikit-learn models, such as random forests or gradient boosting to time series data. Distributed implementations of xgBoost and LightGBM are also available.","<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">mlForecast allows users to apply scikit-learn models, such as random forests or gradient boosting to time series data. This particular implementation uses the hyperopt python package, automatically training numerous sklearn random forest, XGBoost, and LightGBM models, identifying over multiple iterations which parameters perform the best. The results for the champion model are then provided. If trained using CPU, then a maximum of 32 time series will be processed, while if trained using GPU a maximum of 128 will be processed instead, and the maximum iterations used to identify the best models will be higher. Models are trained using all series, meaning that with more series included performance is likely to improve. The seasonality parameter can be altered to reflect known cycles in the data (for example, if hourly data that is expected to vary in a regular pattern over a 24 hour period, then a seasonality of 24 may be suitable).A seasonality of 1 implies that no seasonality is included in the mode</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif"">l.<br><br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Please provide data in three columns, in the following order:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">unique_id for each time series (up to 32 time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series).</span></li>
<li style=""list-style-type: disc""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">date-time column can be in any format (date, time, number, other), but must be in ascending order.</span></li>
<li style=""list-style-type: disc""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">value. The value of the time series at each time</span></li></ul>"
Deep Molecule Property Optimiser,"Deep Molecular Optimization aims to replicate a chemistâs intuition to produce molecules with desirable properties from a given starting molecule. Here, three ADMET properties are optimized simultaneously (logD, solubility, and clearance) from a given starting molecule in SMILES representation. This is achieved with graph-to-graph translation model HierG2G which has state-of-the-art performance in molecular optimization.","<p>Generates new molecules with desirable properties given a starting molecule, essentially replicating a chemist's intuition to optimize molecular properties, accelerating drug discovery<br><br><span style=""font-weight: bold"">Example use case: </span>molecular optimization for finding drug candidates<br><br><span style=""font-weight: bold"">Limitations: </span>works with 3 ADMET properties: logD, solubility and clearance<br><br><span style=""font-weight: bold"">Technology: </span>Message passing neural network<br><br><span style=""font-weight: bold"">Metrics: </span><span style=""text-decoration: underline; color: #0088FF""><a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7980633/table/Tab1/?report=objectonly"" target=""_blank"" rel=""noreferrer"">As reported by He et al.</a></span>&nbsp;</p>"
GenNet: Interpretable Neural Network Framework for Genetics,"Framework for Interpretable Neural Networks for Genetics.
","<p><span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 19.2;font-family: Poppins, sans-serif;"">You can use GenNet to create neural networks specifically for genetics. GenNet gives you the ability to decide what knowledge should be connected to what.</span>&nbsp;</p>
"
Enformer: Gene Expression Prediction tool from DNA Sequence (Variant Scoring),Enformer is a gene expression prediction tool from DNA sequence through the use of a deep learning architecture.,"<p>There is a significant unsolved problem about how non-coding DNA regulates gene expression in many cell types, and important downstream applications in human genetics rely on improved solutions. Enformer is a deep learning architecture that can incorporate data from long-distance interactions (up to 100 kb apart) in the genome. Predicting the impact of genetic variations on cell-type-specific gene expression is a key objective of this app.</p>
<p><span style=""font-weight: bold"">Example use case: </span>Variant effect prediction</p>
<p><span style=""font-weight: bold"">Technology: </span>Neural Network, Transformers</p>
<p><span style=""font-weight: bold"">Limitation: </span>Pretrained models created based on human and mouse genomes only.</p>
<p><span style=""font-weight: bold"">Metrics: </span>Some metrics related to research can be foundÂ <span style=""text-decoration: underline; color: #0088FF""><a href=""https://www.nature.com/articles/s41592-021-01252-x#Sec8"" target=""_blank"" rel=""noreferrer"">here</a></span>.</p>
<p><span style=""font-weight: bold; font-style: italic; text-decoration: underline"">Note:</span><span style=""font-weight: bold; font-style: italic""> ""Select Targets"" </span>section below is optional!</p>"
DeepCRISPR: Off Target sgRNA Cleavage Profile Prediction,"DeepCRISPR, is an efficient and extendable computational model for prediction of CRISPR sgRNA off-target profile which would facilitate the optimized design of sgRNAs with high
sensitivity and specificity. DeepCRISPR was trained on two different cell types: 293-related cell lines (18 sgRNAs) and K562 t (12sgRNAs)","<p>An efficient and extendable computational model for prediction of CRISPR sgRNA off-target profile, facilitating optimized sgRNA design with high sensitivity and specificity<br><br><strong>Example use case: </strong>Epigenetics research<br><br><strong>Limitations: </strong>Different off-target assays may have different sensitivities<br><br><strong>Technology: </strong>Convolutional neural network-based deep learning network, trained on two different cell types: 293-related cell lines (18 sgRNAs) and K562 t (12 sgRNAs)<br><br><strong>Metrics: </strong><a href=""https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1459-4/figures/3"" target=""_blank"">As reported by Chuai et al.</a>&nbsp;</p>
"
DeepCRISPR: On Target sgRNA Knockout Efficacy Prediction,"DeepCRISPR, is an efficient and extendable computational model for prediction of CRISPR sgRNA on-target knockout efficacy which would facilitate the optimized design of sgRNAs with high
sensitivity and specificity","<p>An efficient and extendable computational model for prediction of CRISPR sgRNA on-target knockout efficacy, facilitating optimized sgRNA with high sensitivity and specificity<br><br><strong>Example use case: </strong>Epigenetics research<br><br><strong>Limitations: </strong>Focuses on conventional NGG-based sgRNA design for SpCas9 in humans<br><br><strong>Technology: </strong><a href=""https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1459-4/figures/1"" target=""_blank"">Convolutional neural network-based deep learning network</a>, trained on ~15,000 sgRNAs containing 1071 genes from <br>four different cell lines (hct116, hek293t, hela, and hl60) with redundancy removed and can generalise well in new cell types for <br>sgRNA on-target knockout efficacy prediction<br><br><strong>Metrics: </strong><a href=""https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1459-4/figures/2"" target=""_blank"">As reported by Chuai et al. </a>&nbsp;</p>
"
Single Cell RNA-Seq Differential Expression,Deep generative modeling for single-cell transcriptomics,"<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Trains an scVI variational auto encoder to identify differential expression in genes between observations. Data should be in .h5ad, .h5, or .csv format. Uses the Anndata python package, which natively supports .h5ad meaning that file format is most suitable.</span></p>
<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif; font-weight: bold"">Example use case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Differential expression analysis is one of the primary downstream analyses of single cell RNA-seq data to identify gene markers for cell type detection and also provide inputs to other secondary analyses.Â </span></p>"
ChemProp: Solubility Prediction of Small Molecules,"App uses ChemProp machine learning library to calculate solubilities of a list of SMILES strings. The output is a .CSV file with the predicted log(S) solubility values.

The app was trained on the AqSolDB database of aqueous solubility.","<p>Solubility model trained on AqSolDB using ChemProp<br><br><strong>Example use case: </strong>Filtering out drug candidates based on solubility<br><br><strong>Limitations: </strong>Applicable for organic molecules only, as the training dataset consisted only of organic molecules<br><br><strong>Technology: </strong>Message passing neural networks<br><br><strong>Metrics: </strong>On test data; Mean average error = 0.66; RMSE = 0.99; R<sup>2</sup>= 0.82</p>
"
ChemProp: Molecular Property Prediction Training App,"This app provides an interface for training models on ChemProp. The user inputs are the .CSV file that contains SMILES and molecular property columns, a .CSV with only SMILES column on which to predict the molecular property.","<p>Classification model training for molecular property prediction by analyzing learned molecular representations<br><br><strong>Example use case: </strong>drug toxicity prediction during lead generation<br><br><strong>Technology: </strong>Message passing neural networks</p>
"
C. Elegans Cell Annotation: Single Cell Inference & Retraining,scANVI model trained on C. Elegans dataset,<p>scANVI model trained on C. Elegans dataset from: âA lineage-resolved molecular atlas of C. elegans embryogenesis at single-cell resolutionâ. Transcriptomes covering 89701 cells and 20222 genes</p>
PBMC Annotation: Single Cell Inference & Retraining,scANVI model trained on Purified PBMC dataset,<p>scANVI model trained on Purified PBMC dataset from: âMassively parallel digital transcriptional profiling of single cellsâ. Transcriptomes covering 68k peripheral blood mononuclear cells.</p>
Mouse Spleen & Lymph Cell Annotation: Single Cell Inference & Retraining,scANVI model trained on Mouse Spleen and Lymph Nodes Cite Seq dataset,<p>scANVI model trained on Mouse Spleen and Lymph Nodes Cite Seq dataset from: âJoint probabilistic modeling of single-cell multi-omic data with totalVIâ. Immune cells from murine spleen and lymph nodes</p>
Drug Repurposing Knowledge Graph,"DRKG is a biological knowledge graph relating genes, compounds, diseases, side effects and more.","Drug Repurposing Knowledge Graph (DRKG) is a comprehensive biological knowledge graph relating genes, compounds, diseases, biological processes, side effects and symptoms. DRKG includes information from six existing databases including DrugBank, Hetionet, GNBR, String, IntAct and DGIdb, and more. It includes 97,238 entities belonging to 13 entity-types; and 5,874,261 triplets belonging to 107 edge-types. These 107 edge-types show a type of interaction between one of the 17 entity-type pairs (multiple types of interactions are possible between the same entity-pair). See information on how to use DRKG here: https://bit.ly/3CcQCB5"
Reinvent: DRD2 Use Case,This app explores new compounds for the DRD2 receptor by using reinforcement learning.,"<p>Reinvent library consists of jupyter notebooks related to in silico drug discovery applications including data preparation and training steps. The aim of this app is to show the use case for finding new molecules for the DRD2 receptor with Reinforcement Learning. Inputs are two .csv files that SMILES strings should be provided. Please see the data structure below for more information. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br> <br><strong>Example Use Case: </strong>Finding new molecules for DRD2 receptor<br><br><strong>Limitation: </strong>Some of the parameters are kept default like in the demo notebook.<br><br><strong>Technology:</strong> Reinforcement Learning<br><br><strong>Metrics: </strong>Some of the metrics shown in the <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Complete_Use-Case-DRD2_Demo.ipynb"" target=""_blank"">demo notebook</a>&nbsp;</p>
"
UNet2D Segmentation Training Pipeline,This pipeline will train a UNet2D segmentation model that produces image masks that to represent the segmentations.,"<p>This pipeline will train a UNet2D segmentation model that produces image masks that to represent the segmentations. The pipeline can augment the training dataset to increase model performance if you wish. To train a model you will need a set of source images and a set of target segmentation images. The target segmentation images will be binary images that are segmentation masks of the source images, each source image must have an associated target image.  <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case:</strong> Highlight blood vessels in a retinal image.<br><br><strong>Technology: </strong>UNet2D is an encoder-decoder network architecture.<br><br><strong>Limitations: </strong>The maximum image input size UNet2D can take is 512x512, your images will be converted to patches if they are bigger than 512x512. Currently only greyscale images are supported.</p>
"
Unet2D Multilabel Segmentation Training Pipeline,This pipeline will train a UNet2D multilabel segmentation model that produces image masks that represent the segmentations.,"<p>This pipeline will train a UNet2D multilabel segmentation model that produces image masks that represent the segmentations. The pipeline can augment the training dataset to increase model performance if you wish. To train a model you will need a set of source images and a set of target segmentation images. The target segmentation images will be that are segmentation masks of the source images where each pixel value is a label, each source image must have an associated target image.  <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case: </strong>Highlight various parts of cells<br><br><strong>Technology: </strong>U-Net Encoder-decoder<br><br><strong>Limitations:</strong> The maximum image input size UNet2D can take is 512x512, your images will be converted to patches if they are bigger than 512x512. Currently only greyscale images are supported&nbsp;</p>
"
COVID-Net: COVID-19 Detection from Chest X-ray,Covid19 detection from X-ray,"<p>Prediction of COVID-19 diagnosis, pneumonia probability, airspace severity, and disease severity from chest x-ray images<br><br><strong>Example use case: </strong>COVID-19 research<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use COVID-Net for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/lindawangg/COVID-Net#results"" target=""_blank"">As reported by the COVID-Net Open Source Initiative</a>&nbsp;</p>
"
Noise2Void: 2D Image Denoising Training Pipeline,Train a model to denoise your medical images in a self-supervised manner.,"<p>Train a model to denoise your medical images. Noise2Void is a deep-learning method that can be used to denoise many types of images, including microscopy images. It allows denoising of image data in a self-supervised manner, therefore high-quality, low noise equivalent images are not necessary to train this network. This is performed by ""masking"" a random subset of pixels in the noisy image and training the network to predict the values in these pixels. <span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Model saving and GPU access available soon.</span><br><br><span style=""font-weight: bold"">Example use case:</span> Train a model to take noisey images and remove noise to make the image clearer without needing examples of the clear images to train the model<br><br><span style=""font-weight: bold"">Technology:</span> U-Net<br><br><span style=""font-weight: bold"">Limitations:</span> Currently only gray scale images are supported</p>"
Reinvent: Data Preparation Module,"This app provides how to process, analyze, and filter data from ChEMBL or other sources.","<p>This app provides how to process, analyze, and filter data from ChEMBL or other sources. There are several reasons why data used to train a generative model should be pre-processed. Invalid or duplicate entries need to be removed. Unusual compounds that are clearly not drug-like need to be excluded (too big, reactive groups and etc.) and rare tokens can be removed. There are some rare compounds that can be considered outliers and excluding them frees up space in the vocabulary, making it smaller. Input is SMILES strings in <strong><em>.smi</em></strong> format. Output is filtered SMILES in <strong><em>.csv</em></strong> format that can be used in other Reinvent apps. (e.g. <a href=""https://app.superbio.ai/apps/167?id=636ada2f7d6789757197927a"" target=""_blank"">Reinvent: Create Initial Prior/Agent Generative Model</a>). For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps. <br><br><strong>Example Use Case:</strong> Pre-processing SMILES strings from big sources for downstream analysis.<br><br><strong>Limitation: </strong>Filtering options are kept like in the demo notebook. Other options will be added next versions.</p>
"
Noise2Void: 3D Image Denoising Training Pipeline,Train a model to denoise your 3D medical images in a self-supervised manner.,"<p>Train a model to denoise your 3D medical images. Noise2Void is a deep-learning method that can be used to denoise many types of images, including microscopy images. It allows denoising of image data in a self-supervised manner, therefore high-quality, low noise equivalent images are not necessary to train this network. This is performed by ""masking"" a random subset of pixels in the noisy image and training the network to predict the values in these pixels. The resulting output is a denoised version of the image. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case:</strong> Train a model to take noisey images and remove noise to make the image clearer without needing examples of the clear images to train the model<br><br><strong>Technology:</strong> U-Net</p>
"
DeepStorm: High-density Single-molecule Localization Microscopy Image Reconstruction Training,Train Deep Storm for image reconstruction of high-density single-molecule localization microscopy.,"<p>Ultrafast, precise, and parameter-free image reconstruction from high-density single-molecule localization microscopy (SMLM). <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 13.66;font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case: </strong>Research with single-molecule localization microscopy<br><br><strong>Technology: </strong>U-Net based network without skip connections&nbsp;</p>
"
Reinvent: Create Initial Prior/Agent Generative Model,This application builds an initial generative model for prior/agent based on SMILES data.,"<p>Based on the Create_Model_Demo notebook from the ReinventCommunity repo. If you are planning to train a new model from scratch, this app is the first step of the process. This module creates an initial generative model of prior/agents for the next step (<a href=""https://app.superbio.ai/apps/170?id=636e0620614bfa9ffd879d75"" target=""_blank"">Reinvent: Train Initial Generative Model for Prior/Agent</a> ) by generating a vocabulary based on your SMILES training data. The vocabulary defines what tokens the model can propose, which directly controls the possible atom types in the SMILES output. The output of this app (empty_model.ckpt) will be the input for the next app (<a href=""https://app.superbio.ai/apps/170?id=636e0620614bfa9ffd879d75"" target=""_blank"">Reinvent: Train Initial Generative Model for Prior/Agent</a> ) that trains the generative model. Finally, the output file of the second app is what you can use in <a href=""https://app.superbio.ai/apps/181?id=637b69712ffa50c6deecda32"" target=""_blank"">Reinvent: Reinforcement Learning.</a> For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br><br><strong>Example Use Case</strong>: Generate generative model of prior/agents<br><br><strong>Limitation:</strong> At least 100.000 SMILES are recommended for creating a generative model</p>
"
DFCAN: 2D Image Up-sampling Training Pipeline,DFCAN transforms low-resolution images to super-resolved images.,"<p>DFCAN transforms low-resolution (LR) images to super-resolved (SR) images. The training is done using LR-SR image pairs, taking the LR images as input and obtaining an output as close to SR as possible. DFCAN achieves comparable image quality to SIM over a tenfold longer duration in multicolor live-cell imaging experiments, which reveal the detailed structures of mitochondrial cristae and nucleoids and the interaction dynamics of organelles and cytoskeleton. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case: </strong>Take low-resolution microscapy images and increase the resoution of them to reveal clearer structures in the images<br><br><strong>Technology: </strong>Deep Fourier channel attention network&nbsp;</p>
"
Reinvent: Train Initial Generative Model for Prior/Agent,Train model created by the Reinvent: Create Initial Prior/Agent Generative Model app,"<p>This app was originally created based on notebook (Transfer Learning Mode) from the ReinventCommunity repo. The purpose of this app is to train an empty model created from the previous <a href=""https://app.superbio.ai/apps/167?id=636ada2f7d6789757197927a"" target=""_blank"">Reinvent: Create Initial prior/agent Generative Model.</a>  In this scenario, inputs are an empty model (.ckpt file) and a processed dataset (.csv file) generated by <a href=""https://app.superbio.ai/apps/162?id=6364d7049c2c44f0b26d486a"" target=""_blank"">Reinvent: Data Preparation Module</a>. The output will be the Prior that can be used afterward forÂ other apps of Reinvent such as reinforcement learning. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br><br><strong>Example Use Case:</strong> Train generative model with Transfer Learning<br><br><strong>Limitations: </strong>Some of the parameters are kept the same as in the original notebook.<br><br><strong>Technology: </strong>Transfer Learning (TL)<br></p>
"
Pix2Pix: Image to Image Translation Training,Train pix2pix to translate one image domain to another image domain.,"<p>Train pix2pix to translate one image domain to another image domain. The image transformation requires paired images for training (supervised learning) to learn information from the input image and obtain the equivalent translated image. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 13.66;font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br> <br><strong>Example use case:</strong> in silico cell painting, semantic segmentation, background removal, style transfer.<br><br><strong>Technology:</strong> Generative Adversarial Network</p>
"
COVID-Net-CT: COVID-19 Detection from CT-scan,Covid19 detection from chest CT images.,"<p>Prediction of COVID-19 diagnosis from chest CT images<br><br><strong>Example use case: </strong>COVID-19 research<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use COVID-Net for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/haydengunraj/COVIDNet-CT#results"" target=""_self"">As reported by the COVID-Net Open Source Initiative</a>&nbsp;</p>
"
Reinvent: Train QSAR Models for Target Proteins,This tool of REINVENT provides you to create QSAR models for your target protein(e.g.DRD2 receptor),"<p>This app derives from a notebook (Model Building Demo) in the ReinventCommunity repo. The aim of this app is to generate a QSAR model for a target protein that you are interested. QSAR modeling is an estimation of the activity/property/toxicity of new chemical entities in the drug discovery process. In the demo, SMILES that known activities on the DRD2 receptor were used. SMILES are transformed into fingerprints and act as the input in the code. Since REINVENT only supports pickled scikit-learn models, the output files are in <strong>(.pkl)</strong> format. The output file either can be used by <a href=""https://app.superbio.ai/apps/181?id=637b69712ffa50c6deecda32"" target=""_blank""><strong>(Reinvent: Reinforcement Learning Module)</strong></a>  or  <a href=""https://app.superbio.ai/apps/182?id=637b6ba22ffa50c6deecda3a"" target=""_blank""><strong>(Reinvent: Scoring Module)</strong></a>  apps. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps. <br><br><strong>Example Use Case:  </strong>Generating QSAR models for target protein<br><br><strong>Limitations: </strong><br>     - Only scikit-learn models <strong>(.pkl)</strong> are accepted by REINVENT<br>     - Since the demo notebook contains only classification methodology for the random forest, the app provides this option currently.<br><br><strong>Technology: </strong>Random Forest, scikit-learn, Quantitative structure-activity relationship<br><br><strong>Metrics: </strong>AUC score metrics from demo data are represented <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Model_Building_Demo.ipynb"" target=""_blank"">here</a>. Also, you can check the Example Output of this app.</p>
"
Tuberculosis-Net (TB-Net),Tuberculosis detection from chest X-ray images.,"<p>Prediction of Tuberculosis diagnosis from chest X-ray images</p>
<p><strong>Example use case: </strong> TB case detection<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use TB-Net for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/darwinai/TuberculosisNet#results"" target=""_blank"">As reported by the TB-Net Open Source Initiative</a>&nbsp;</p>
"
Cancer-Net SCa,Skin cancer detection from dermoscopy images.,"<p>Prediction of skin cancer diagnosis from dermoscopy images</p>
<p><strong>Example use case: </strong> Skin cancer detection research<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use Cancer-Net SCa for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/jamesrenhoulee/CancerNet-SCa#results"" target=""_blank"">As reported by the Cancer-Net SCa Open Source Initiative</a>&nbsp;</p>
"
CycleGAN: Unpaired Image to Image Translation Training,CycleGAN captures characteristics of an image domain and learns to translate said characteristics into another image domain,"<p>CycleGAN is a method that can capture the characteristics of one image domain and learn how these characteristics can be translated into another image domain, all in the absence of any paired training examples. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 13.66;font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br> <br><strong>Example use case:  </strong>In silico cell painting, semantic segmentation, background removal, style transfer.<br><br><strong>Limitations:</strong> If your dataset is paired, use <a href=""https://app.superbio.ai/apps/171?id=6372c90c2ffa50c6deecd907"" target=""_blank"">the pix2pix app</a> instead, paired training generally provides more information to the deep learning model and so can perform more effectively.<br><br><strong>Technology:</strong> Two Generative Adversairal Networks that learn to transform images both from the first domain to the second and vice-versa.</p>
"
Image Classification Transfer Learning,Transfer learning shortcuts much of the model training process by taking a piece of a model that has already been trained on a related task and reusing it in a new model.,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">Image classification models have millions of parameters. Training them from scratch requires a lot of labelled training data and a lot of computing power. Transfer learning is a technique that shortcuts much of this by taking a piece of a model that has already been trained on a related task and reusing it in a new model. Model saving and GPU access available soon.</span><br><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Example use case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">Lesion, tumour, bacteria, animal etc. classification<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Technology:</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)""> Pretrained models from </span><span style=""color: #0088FF; background-color: rgb(255,255,255); text-decoration: underline""><a href=""https://www.tensorflow.org/hub"" target=""_blank"" rel=""noreferrer"">TensorFlow Hub</a></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">.<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Metrics:</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)""> All models trained on the </span><span style=""color: #0088FF; background-color: rgb(255,255,255); text-decoration: underline""><a href=""https://www.image-net.org/"" target=""_blank"" rel=""noreferrer"">ImageNet</a></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)""> dataset containing 14,197,122 images labelled under 1000 classes.</span></p>"
Reinvent: Reinforcement Learning Module,This app directs the generative model toward relevant areas in the chemical space with help of RL.,"<p>The reference notebook of this app is ""Reinforcement Learning Demo"" from the ReinventCommunity repository. The purpose of this app decides which molecules are ""good"" or ""bad"" by using RL. Generally, the generative model that was created before must be directed to a relevant region of chemical space that involve compounds of interest. To achieve this, a Reinforcement Learning methodology is used with several scoring functions defined by the user. During the RL, molecules are generated by the <strong><em>agent </em></strong>and receive a score between 0 and 1. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br> <br><strong>Example use case:</strong> Generate molecules with RL setup.<br><br><strong>Limitations:</strong><br>-Some of the parameters are kept as default and not shown here (they will be added next versions)<br>-Currently, only the CPU version is available<br><br><strong>Technology:</strong> Reinforcement Learning<br><br><strong>Metrics: </strong>See metrics in the original demo <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Reinforcement_Learning_Demo.ipynb"" target=""_blank"">notebook</a> this app is derived from</p>
"
Reinvent: Scoring Mode,The scoring mode of Reinvent enables users to use scoring functions to evaluate SMILES directly.,"<p>This app is derived from the <span style=""color: #0088FF""><a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Scoring_Demo.ipynb"" target=""_blank"" rel=""noreferrer"">""Scoring Demo""</a></span> notebook in the ReinventCommunity repository. The purpose of this module is to estimate SMILES scores with the same scoring function as intended for the RL. For example, in the RL process inception, SMILES can be used. In order to evaluate whether these SMILES are good or not for your case independently, they can be used in this app to produce scores for evaluation. For more information, please see the tutorial <span style=""color: #0088FF""><a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank"" rel=""noreferrer"">page</a></span> of Reinvent Apps.<br><br><span style=""font-weight: bold"">Example use case:</span> Evaluation of SMILES strings by utilizing the same scoring function in the RL<br><br><span style=""font-weight: bold"">Limitation:</span><br>- Some of the parameters are kept as default and not shown here (they will be added next versions)<br><br><span style=""font-weight: bold"">Technology:</span> RDkit</p>"
Reinvent: Sampling Module,This module allows users to sample further SMILES from a given model state(agent).,"<p>This app is based on <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Sampling_Demo.ipynb"" target=""_blank"">""Sampling_Demo.ipynb</a>"" from the ReinventCommunity notebook. The purpose of the notebook is to show how to sample further compounds from a given model state (agent). During the RL process, each iteration of the agent produces an output of a number of molecules and stores it inside. If more ideas are necessary for the project afterward, this can be achieved through this module. The sampling module enables you to extract molecules from the trained agent (given model state) to use for more investigation. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank"">page</a> of Reinvent Apps.<br> <br><strong>Example Use Case: </strong>A sampling of SMILES from the generative trained agent<br><br><strong>Limitation: </strong><br>- Job only can be submitted in CPU version<br>- Currently, maximum 5 million SMILES can be sampled</p>
"
Cutadapt: Sequence Trimming For High-Throughput Reads,Cutadapt allows you to remove unwanted sequences (e.g. adapters) from your high-throughput reads.,"<p>Data quality can be important for downstream analysis (e.g. alignment) and data cleaning is one of the most important steps to improve data quality. This app eliminates unnecessary reads from your sequence (e.g. adapters, primers, Poly-A tails). Inputs are FASTQ reads and adapters sequences. Output is an info table generated by the Cudatapt algorithm. Based on <a href=""https://cutadapt.readthedocs.io/en/v4.1/"" target=""_blank"">Cutadapt</a> version  <strong><em>v4.1</em></strong>. <br><br><strong>Example Use Case:</strong> Remove unwanted 3' adapters from the FASTQ sequence<br><br><strong>Limitation:</strong> Currently, only 3' adapters are accepted</p>
"
DeepNull: Modeling Non-Linear Covariate Effects,DeepNull determines and rearranges non-linear and interactive covariate effects with a deep neural network to increase power in genome-wide association studies (GWAS).,"<p>A typical strategy for examining the relationship between genotype and phenotype while controlling for a number of factors is genome-wide association studies (GWAS). Covariates that could have non-linear or interaction effects are typically ignored by GWAS. When such non-linearity is detected, DeepNull can model the non-linear impact of variables on phenotypes. It learns this potentially complicated and non-linear relationship using a flexible deep neural network (DNN), and during association testing, makes adjustments for the network's expectation of phenotype (based on covariates only).<br><br><span style=""font-weight: bold"">Example use case:</span> Improve phenotype prediction and association power in GWAS<br><br><span style=""font-weight: bold"">Technology: </span>Deep Neural Network (DNN)<br><br><span style=""font-weight: bold"">Limitation: </span>Some of the DNN parameters were left as default. Please check this <span style=""color: #0088FF""><a href=""https://github.com/Google-Health/genomics-research/blob/main/nonlinear-covariate-gwas/config.py"" target=""_blank"" rel=""noreferrer"">page</a></span> for more information.</p>"
MetaESM: One Shot Protein Variant Prediction,Predict variant sequences without supervision or additional training,"<p style=""text-align: left""><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255)"">The approach to date has been to fit a model to a family of related sequences. The conventional setting is limited, since a new model must be trained for each prediction task. These </span><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif"">state-of-the-art</span><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""> models </span><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255)"">use only zero-shot inference, without any supervision from experimental data or additional training, capturing the functional effects of sequence variation.</span><br><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Example use case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">Predicting protein sequence variants, along with the effects of these variants on protein function.<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Technology: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">The training mode adjusts the number of models used to generate predictions. Fast uses a single model, standard three, and intensive five. Where multiple models are used their ensemble is used to provide overall metrics.Â </span></p>"
MetaESM: Protein Contact Prediction,Generate accurate protein contact predictions.,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">ESM-2 outperforms all tested single-sequence protein language models across a range of structure prediction tasks. There are many ways to define a protein contact. Here we're using the definition of 8 angstroms between carbon beta atoms. Note that the position of the carbon beta is imputed from the position of the N, CA, and C atoms for each residue. Inputs required: 1-10 .a3m files (aligned fasta).</span><br><br><span style=""font-weight: bold"">Example Use Case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">predicting where amino acids at different points along a sequence are in close proximity. Contact maps are generated, which provide a 2D representation of the proximity of amino acids in 3D space. This can provide clues about protein function and 3D protein structure.</span></p>
<p><br><span style=""font-weight: bold"">Technology: </span><span style=""color: rgba(0,0,0,0.87); background-color: rgb(255,255,255)"">if CPU is selected when submitting the job, then the esm2_t12_35M_UR50D model will be used (35M parameters), while if GPU is selected, then the more powerful esm2_t33_650M_UR50D model will be used (650M parameters).Â </span></p>"
MetaESM: Protein Variant Prediction,Generate accurate protein variant predictions.,"<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">ESM-2 outperforms all tested single-sequence protein language models across a range of structure prediction tasks. This app has three stages. First, an embedding (fixed-dimensional vector representation) is obtained for each mutated sequence. Second, PCA is applied to reduce the number of dimensions prior to modelling. Third, a regression model is trained that can predict the mutation ""effect"" score given the embedding. Three types of model will be compared: random forests, support vector machines, and K nearest neighbours.</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""><br><br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Example Use Case</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">: predicting the biological activity of mutations of a protein, using fixed embeddings from ESM. The output in this case describes scaled effect of the mutation.<br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""><br></span><span style=""color: rgba(0,0,0,0.87); background-color: rgb(255,255,255); font-weight: bold"">Technology</span><span style=""color: rgba(0,0,0,0.87); background-color: rgb(255,255,255)"">: if CPU is selected when submitting the job, then the esm2_t12_35M_UR50D model will be used (35M parameters), while if GPU is selected, then the more powerful esm2_t33_650M_UR50D model will be used (650M parameters).Â </span></p>"
Single Cell RNA-Seq Quality Control with AUTOZI,Check distribution and zero-inflation of an scRNA dataset,"<p>AutoZI is a deep generative model adapted from scVI allowing a gene-specific treatment of zero-inflation. Plots relating to batch effects and gene expression levels are also generated. Ideally, data should be provided in .h5ad format, which is native to the Anndata python package. Alternatively, .h5, .csv or.mtx files can be provided if their formatting is suitable.<br><span style=""font-size: 14px""><br></span><span style=""font-weight: bold"">Example use case:</span><span style=""font-size: 14px"">&nbsp;</span>In single-cell RNA sequencing data, biological processes or technical factors may induce an overabundance of zero measurements. Existing probabilistic approaches to interpreting these data either model all genes as zero-inflated, or none. But the overabundance of zeros might be gene-specific. AutoZI can distinguish between zero-inflated and non-zero inflated genes.</p>"
Single Cell LDVAE,LDVAE produces a generative model comparable to probabilistic PCA or factor analysis,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">LDVAE (Linearly-decoded Variational Auto-encoder, also called Linear scVI) is a flavor of scVI with a linear decoder.<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">The advantages of LDVAE are: (i) Can be used to interpret latent dimensions with factor loading matrix. (ii) Scalable to very large datasets (>1 million cells).<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">The limitations of LDVAE include: (i) Less capacity than scVI differential expression or scANVI for annotation, which use a neural network decoder. (ii) Less capable of integrating data with complex batch effects.Â </span></p>"
Single Cell Assign,CellAssign predict cell types for each cell using known cell-type-specific gene markers.,"<p>CellAssign is a simple yet, efficient approach for annotating scRNA-seq data in the scenario in which cell-type-specific gene markers are known. The method also allows users to control for nuisance covariates like batch or donor. The scvi-tools implementation of CellAssign uses stochastic inference, such that CellAssign will scale to very large datasets.</p>
<p>The advantages of CellAssign are: (i) Lightweight model that can be fit quickly, (ii) Ability to control for nuisance factors.</p>
<p>The limitations of CellAssign include: (i) Requirement for a cell types by gene markers binary matrix, (ii) The simple linear model may not handle non-linear batch effects.</p>"
GrapHiC: Imputing missing Hi-C reads with graph-based approach,GrapHiC is a Hi-C imputation framework that imputes Hi-C contact matrices using a conditional Graph Autoencoder Network.,"<p>The three-dimensional (3D) architecture of the genome at various structural scales can be comprehended and investigated by scientists using Hi-C, a high-throughput chromosomal conformation capture technique. Generally, Hi-C experiment data is stored in a contact map of sizeÂ <em>N Ã N</em>. Each row and column correspond to fixed-widthÂ <em>N</em> windows (âbinsâ) in the range of 1 kbps to 1 mbps. The examination of these contact maps revealed significant structural features such as topologically associated domains (TADs).<br><br>Building high-resolution Hi-C contact maps often necessitate billions of reads, which is often impossible. GrapHiC imputes Hi-C contact maps by reformulating the Hi-C data as a position-aware graph, using less expensive ChIP-seq signals, and proposing a generative graph-autoencoder that first encodes the input graph into a latent representation.<br><br><strong>Example use case:</strong>  Imputation of Hi-C data<br><br><strong>Technology:</strong> Graph Auto-Encoder (GAE)<br><br><strong>Limitation:</strong><br>- Some of the parameters were left as default. Please check this <a href=""https://github.com/rsinghlab/GrapHiC/blob/main/parameters.py"" target=""_blank"">page</a> for more information.<br><br><strong>Metrics:</strong> Detailed metrics of the study can be found in <a href=""https://www.biorxiv.org/content/10.1101/2022.10.19.512942v2.supplementary-material"" target=""_blank"">the supplementary file</a>. <br><br><strong>Epigenetic Features:</strong><br><br><strong>All: </strong>['RAD-21', 'RNA-Pol2','CTCF', 'DNASE-Seq', 'H3K27ME3', 'H3K27AC', 'H3K36ME3', 'H3K4ME1', 'H3K4ME2', 'H3K4ME3', 'H3K79ME2', 'H3K9AC', 'H4K20ME1', 'H3K9ME3']<br><strong>DNA-Acessibility: </strong>['RAD-21', 'RNA-Pol2','CTCF', 'DNASE-Seq']<br><strong>Repression-Marker</strong>: ['H3K27ME3', 'H3K4ME2', 'H4K20ME1']<br><strong>Activating-Marker: </strong>['H3K4ME3', 'H3K9AC', 'H3K9ME3']<br><strong>Enchancer-Interaction-Marker:</strong> ['H3K36ME3', 'H3K79ME2']<br><strong>Gene-Related: </strong>['H3K36ME3', 'H3K79ME2']<br><strong>HiC-Reg-Reduced:</strong> ['CTCF', 'DNASE-Seq', 'H4K20ME1', 'H3K27ME3', 'H3K9ME3', 'H3K9AC', 'H3K4ME1', 'H3K27AC']</p>
"
Single Cell Assign: HGSC Inference,A pretrained model for generating high-grade serous carcinoma (HGSC) cell type predictions,"<p>High-grade serous carcinoma (HGSC) is a type of tumour that arises from the serous epithelial layer in the abdominopelvic cavity and is mainly found in the ovary. This pretrained model can be used to generate cell type predictions, based on precalculated gene-cell associations. <span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Note that the marker genes must be present in the uploaded dataset.Â </span></p>"
Single Cell Assign: Follicular Lymphoma Inference,A pretrained model for generating follicular lymphoma cell type predictions,"<p>Follicular lymphoma is the most common type of of low-grade non-Hodgkin lymphoma (NHL). It develops when white blood cells cluster together to form lumps in lymph glands or organs. There are two main types of lymphoma: Hodgkin lymphoma and non-Hodgkin lymphoma. <span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">This pretrained model can be used to generate cell type predictions, based on precalculated gene-cell associations. Note that the marker genes must be present in the uploaded dataset.</span></p>"
Stereoscope for Spatial Transcriptomics,"Stereoscope can stratify cells into discrete cell types, providing spatial representations of each","<p>Stereoscope posits a probabilistic model of spatial transcriptomics and an associated method for the deconvoluton of cell type profiles using a single-cell RNA sequencing reference dataset.<br><br>The advantages of Stereoscope are: (i) Can stratify cells into discrete cell types, (ii) Scalable to very large datasets (>1 million cells).<br><br>Stereoscope requires training two latent variable models (LVMs): one for the single-cell reference dataset and one for the spatial transcriptomics dataset, which incorporates the learned parameters of the single-cell reference LVM. The first LVM takes in as input a scRNA-seq gene expression matrix of UMI counts with cells and genes, along with a vector of cell type labels. Subsequently, the second LVM takes in the learned parameters of the first LVM, along with a spatial gene expression matrix with spots and genes. This matrix should be uploaded as a csv file with gene names, 3D location, and tissue values in different columns.<br><br><span style=""font-weight: bold"">Example use case: </span>Train a probabilistic model of spatial transcriptomics (measure all the gene activity in a tissue sample and map where the activity is occurring) and an associated method for the deconvoluton of cell type profiles (estimating the proportions of different cell types in samples collected from a tissue) using a single-cell RNA sequencing reference dataset.<br><br><span style=""font-weight: bold"">Limitations:</span> Effectively requires a GPU for fast inference.</p>"
SynthSeg: Contrast-agnostic Segmentation of Brain MRI,Segmentation of MRI brain scans of any contrast and resolution into 60 separate structures,"<p>SynthSeg is the first convolutional neural network for segmentation of brain scans of any contrast and resolution that works out-of-the-box, without retraining or fine-tuning. SynthSeg relies on a single model, which is robust to a wide array of subject populations: from young and healthy to ageing and diseased subjects, white matter lesions, scans with or without preprocessing, including bias field corruption, skull stripping, intensity normalisation, template registration, etc.<br><br><strong>Example use case: </strong>SynthSeg can segment real scans of any target domain, which enables analysis of huge amounts of heterogeneous clinical data.<br><br><strong>Technology: </strong>Convoluional neural network<br><br><strong>Metrics: </strong>Trained on a synthetic dataset. Obtains a dice score of &gt; 0.85 on most availiable brain MRI datasets</p>
"
CITE-seq Analysis with totalVI,totalVI (total Variational Inference) models CITE-seq RNA and protein data,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">totalVI (total Variational Inference) provides a flexible generative model of CITE-seq RNA and protein data that can be used for many common downstream tasks.<br><br>The advantages of totalVI are: (i) Comprehensive in capabilities. (ii) Scalable to very large datasets (>1 million cells).<br><br>Data should include the protein expression matrix, with one row per observation, and one column per protein.</span><br><br><span style=""font-weight: bold"">Example use case: </span>Train a generative model of CITE-seq RNA and protein data that can be used for many common downstream tasks.<br><br><span style=""font-weight: bold"">Limitations:</span> Effectively requires a GPU for fast inference. And, difficult to understand the balance between RNA and protein data in the low-dimensional representation of cells.</p>"
DestVI for Spatial Transcriptomics,DestVI models variation within cell types,"<p>DestVI (Deconvolution of Spatial Transcriptomics profiles using Variational Inference) posits a conditional generative model of spatial transcriptomics down to the sub-cell-type variation level which can be used to explore the spatial organization of a tissue and understanding gene expression variation between tissues and conditions.<br>The advantages of DestVI are: (i) Can stratify cells into discrete cell types and model continuous sub-cell-type variation, (ii) Scalable to very large datasets (>1 million cells).<br><br><span style=""font-weight: bold"">Example use case:</span> Deconvolution of, for example, 10x Visium spatial transcriptomics profiles using an accompanying single-cell RNA sequencing data.<br><br><span style=""font-weight: bold"">Limitations:</span> Effectively requires a GPU for fast inference.</p>"
DiffSBDD: Structure-based Drug Design with Equivariant Diffusion Models,Generate small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets using AI diffusion.,"<p>Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. This app generates small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets using AI diffusion.<br><br><strong>Example use case:</strong> Generate ligands for a binding pocket inside a target of interest to elcit a desired therapeutic effect<br> <br><strong>Technology: </strong>E(3)-equivariant 3D-conditional diffusion</p>
"
DeepFRI:Structure-Based Function Prediction using Graph Convolutional Networks,DeepFRI is a Graph Convolutional Networks (GCN)-based method for predicting the functions of protein sequences and structures.,"<p>One of the most significant biological challenges in the post-genomic era is understanding the functional roles and investigating the mechanisms of newly found proteins. A deep learning technique called DeepFRI uses both sequences and contact map representations of 3D structures to predict protein function. The protein structures from the PDB and SWISS-MODEL are used to train DeepFRI. LSTM-LM(Long Short-Term Memory Language Model) was used to learn features from protein sequences and GCN was used to discover features from contact maps.<br><br><strong>Example use case:</strong>  Predicting protein functions<br><br><strong>Technology:</strong> Graph Convolutional Networks (GCN), LSTM-LM<br><br><strong>Limitation: </strong>Some of the options to predict protein functions are currently not available. Please check this <a href=""https://github.com/flatironinstitute/DeepFRI"" target=""_self"">page</a> for more information.<br><br><strong>Metrics:</strong> Some of the metrics related to work can be found <a href=""https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-021-23303-9/MediaObjects/41467_2021_23303_MOESM1_ESM.pdf"" target=""_self"">here</a></p>
"
Tangram for Spatial Transcriptomics,For mapping single-cell gene expression data onto spatial gene expression data.,"<p>Tangram is for mapping single-cell (or single-nucleus) gene expression data onto spatial gene expression data. The single-cell dataset and the spatial dataset should be collected from the same anatomical region/tissue type, ideally from a biological replicate, and need to share a set of genes. Tangram aligns the single-cell data in space by fitting gene expression on the shared genes. Spatial data need to be organized as a voxel-by-gene matrix. The voxel coordinates are saved in the fields obs.x and obs.y which we can use to visualize the spatial ROI. Each ""dot"" is the center of a 10um voxel.<br><br><span style=""font-weight: bold"">Example use case: </span>The most common application of Tangram is to resolve cell types in space. Another usage is to correct gene expression from spatial data: as scRNA-seq data are less prone to dropout than (e.g.) Visium or Slide-seq, the ""new"" spatial data generated by Tangram resolve many more genes. As a result, we can visualize program usage in space, which can be used for ligand-receptor pair discovery or, more generally, cell-cell communication mechanisms. If cell segmentation is available, Tangram can be also used for deconvolution of spatial data. If your single cell are multimodal, Tangram can be used to spatially resolve other modalities, such as chromatin accessibility.</p>"
Superbio AutoML: Classification,AutoML pipeline by Superbio for classification (binary and multiclass).,"<p>Creates a series of models for tabular data and picks the best one. You can save the best model for later use at the end of the training.<br><br><span style=""font-weight: bold"">Limitations</span>: Data should not have leakage and be as clean as possible.<br><br><span style=""font-weight: bold"">Technology</span>: Classical ML models including XgBoost, Ensamble, and Bagging.<br><br><span style=""font-weight: bold"">Use cases</span>: Create a classification model (binary or multiclass) from tabular data.</p>"
Superbio AutoML: Regression,AutoML pipeline by Superbio for regression.,"<p>Creates a series of models for tabular data and picks the best one. You can save the best model for later use at the end of the training.<br><br><span style=""font-weight: bold"">Limitations:</span> Data should not have leakage and be as clean as possible.<br><br><span style=""font-weight: bold"">Technology:</span> Classical ML models including XgBoost, Ensamble, and Bagging.<br><br><span style=""font-weight: bold"">Use cases:</span> Create a regression model from tabular data.</p>"
ChemBERTa: Predict Binding of Inhibitors to BACE-1,Predicts inhibition for SMILES-molecules to human beta-secretase 1 using ChemBERTa.,"<p>Predicts binding and inhibition of molecules, in SMILES format, to human beta-secretace1 (BACE-1). BACE-1 has been implicated as a central player in the pathogenesis of Alzheimer's disease. Our model was fine-tuned with the BACE dataset and uses the ChemBERTa transformer.<br><br><strong>Example use case</strong>: Alzheimer's research.<br><br><strong>Technology</strong>: ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.845&nbsp;</p>
"
ChemBERTa: Molecule Side Effect - Skin and Tissue,Predicts if a SMILES-molecule will cause skin and subcutaneous tissue disorders using ChemBERTa.,"<p>Predicts possible undesirable side effects on the skin and subcutaneous tissue of molecules (SMILES format). Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.73</p>
"
SpliceAI: A deep learning-based tool to identify splice variants,SpliceAI can precisely predict splice junctions from any pre-mRNA transcript sequence by using a deep neural network.,"<p>Pre-mRNAs are spliced into mature transcripts with extraordinary precision, but it is still unclear how the cellular machinery manages to be so particular. SpliceAI is a deep residual neural network that just requires the genomic sequence of the pre-mRNA transcript as input to predict whether each point in a pre-mRNA transcript is a splice donor, acceptor, or neither.<br><br><strong>Example use case:</strong>  Predicting splice variants<br><br><strong>Technology:</strong> Deep Neural Network (DNN)<br><br><strong>Limitation: </strong>Some of the parameters are kept as default. Please check this <a href=""https://github.com/Illumina/SpliceAI"" target=""_self"">page</a> for more information.<br><br><strong>Metrics:</strong> Some of the metrics related to work can be found in the <a href=""https://www.cell.com/cell/fulltext/S0092-8674(18)31629-5?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867418316295%3Fshowall%3Dtrue#secsectitle0035"" target=""_self"">article</a>.</p>
"
ChemBERTa: Molecule Side Effect - Product Issues,Predicts if a SMILES-molecule will encounter Product Issues using ChemBERTa.,"<p>Predicts possible undesirable product issues of molecules (SMILES format). Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.66</p>
"
ChemBERTa: Molecule Side Effect - Investigations,Predicts if a SMILES-molecule had Investigations issues using ChemBERTa.,"<p>Predicts possible Investigations issues of molecules (SMILES format). The issues include laboratory tests and other medical investigations that gave an unusual reading. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.67</p>
"
ChemBERTa: Molecule Side Effect - General Disorders and Administration Site Conditions,Predicts if a SMILES-molecule will have General disorders and administration site conditions.,"<p>Predicts possible undesirable General disorders and administration site conditions of molecules (SMILES format). These are a class of disorders that encompasses conditions of a general kind that result from a disease, the treatment of disease or administration of treatment at a particular site and are manifested by a characteristic set of symptoms and signs. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.71</p>
"
ChemBERTa: Molecule Side Effect - Eye disorders,"Predicts if a SMILES-molecule will cause eye disorders, using ChemBERTa.","<p>Predicts if a molecule may produce undesirable eye disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.65</p>
"
ChemBERTa: Molecule Side Effect - Endocrine disorders,"Predicts if a SMILES-molecule may cause Endocrine disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Endocrine disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><strong>Example use case</strong>: Drug interactions and side effects.<br><br><strong>Technology</strong>: ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics</strong></p>
<p>Test-AUC 0.67</p>
"
ChemBERTa: Molecule Side Effect - Blood and lymphatic system disorders,"Predicts if a SMILES-molecule may cause Blood and lymphatic system disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Blood and lymphatic system disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature.&nbsp;</p>
<p><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.67</p>
"
ChemBERTa: Molecule Side Effect -  Musculoskeletal and connective tissue disorders,"Predicts if a SMILES-molecule may cause Musculoskeletal and connective disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Musculoskeletal and connective tissue disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.72</p>
"
ChemBERTa: Molecule Side Effect - Gastrointestinal disorders,"Predicts if a SMILES-molecule may cause Gastrointestinal disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Gastrointestinal disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.78</p>
"
ChemBERTa: Molecule Side Effect - Renal and urinary disorders,"Predicts if a SMILES-molecule may cause Renal and urinary disorders, using ChemBERTa.","<p>Predicts if a molecule may cause  Renal and urinary disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.69</p>
"
"ChemBERTa: Molecule Side Effect - Respiratory, thoracic and mediastinal disorders","Predicts if a SMILES-molecule may cause Respiratory and mediastinal disorders, using ChemBERTa.","<p>Predicts if a molecule may cause  Respiratory, thoracic and mediastinal disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case</strong>: Drug interactions and side effects.<br><br><strong>Technology</strong>: ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics</strong><br>Test-AUC 0.67</p>
"
ChemBERTa: Molecule Side Effect - Infections and infestations,"Predicts if a SMILES-molecule may contribute to Infections and infestations, using ChemBERTa.","<p>Predicts if a molecule may contribute to Infections and infestations caused by pathogens. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology: </strong>ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.67</p>
"
DeepConsensus: Correct Errors in PacBio CSS Data,DeepConsensus uses gap-aware sequence transformers to correct errors in PacBio data.,"<p>DeepConsensus (v1.2) uses gap-aware sequence transformers to correct errors in Pacific Biosciences (PacBio) Circular Consensus Sequencing (CCS) data.Â This results in greater yield of high-quality reads.<br><br><span style=""font-weight: bold"">Example use case: </span>Correct errors in Pacific Biosciences (PacBio) Circular Consensus Sequencing (CCS) data.<br><br><span style=""font-weight: bold"">Technology: </span>Gap-aware sequence transformers<br><br><span style=""font-weight: bold"">Limitation: </span>This is not an official Google product. The content of this research code repository (i) is not intended to be a medical device; and (ii) is not intended for clinical use of any kind, including but not limited to diagnosis or prognosis.<br><br><span style=""font-weight: bold"">Metrics: </span>Some of the metrics related to work can be found <span style=""color: #0088FF""><a href=""https://github.com/google/deepconsensus/blob/r1.2/docs/assembly_metrics.md"" target=""_blank"" rel=""noreferrer"">here</a></span></p>"
Auto3D: Generating Low-Energy Conformers from SMILES,Auto3D generates low-energy 3D structures with ANI Neural Network Potentials using SMILES as the input.,"<p>Computational programs speed up the processes of chemical discovery, but they frequently require accurate three-dimensional molecular data as part of the input. Obtaining optimal molecular structures is difficult because it necessitates the enumeration and optimization of a vast space of stereoisomers and conformers. Auto3D allows you to obtain favorable 3D conformations of organic molecules from an automatically generated stereoisomeric conformational space that has been optimized by atomistic neural network potentials (NNPs) like ANI or AIMNet.<br><br><span style=""font-weight: bold"">Example use case:</span> Generating 3D structures from SMILES<br><br><span style=""font-weight: bold"">Technology:</span> Neural Network Potentials (NNPs)<br><br><span style=""font-weight: bold"">Limitation:</span><br>- The current approach does not take into account the physical environment, and all calculations were done in the gas phase.<br>- In real-world applications, some chiral molecules are used in racemic form or have poorly defined stereo centers, so assigning specific stereo information may result in over-curation.<br>- The current NNPs of Auto3D optimize geometries in a vacuum condition.<br>- Only AIMNET and ANI2x models are currently available.<br>- Currently, twenty 3D structures of SMILES can be generated.<br><br><span style=""font-weight: bold"">Metrics:</span> Some of the metrics related to work can be found in the <span style=""color: #0088FF; text-decoration: underline""><a href=""https://chemrxiv.org/engage/chemrxiv/article-details/631b69105351a3bdb1f4a2c1"" target=""_blank"" rel=""noreferrer"">article</a></span>.</p>"
PeakVI for scATAC-seq Analysis,peakVI for scTAC-seq data can be used for differential accessibility analysis among other tasks,"<p>peakVI (Python class PEAKVI) is a generative model of scATAC-seq data that can subsequently be used for many common downstream tasks. The advantages of peakVI are: (i) Comprehensive in capabilities. (ii) Scalable to very large datasets (>1 million cells).<span style=""font-size: 14px""><br><br></span><span style=""font-weight: bold"">Example use case:</span> Analyze and visualize scATACseq data<br><span style=""font-size: 14px""><br></span><span style=""font-weight: bold"">Limitations:</span><br>-Effectively requires a GPU for fast inference.<br>-Latent space is not interpretable, unlike that of a linear method.</p>"
MultiVI for Multiomic Data Analysis,For the analysis of scRNA and scATAC-seq datasets that were jointly profiled (multiomic/ paired),"<p>MultiVI multimodal generative model capable of integrating multiome, scRNA-seq and scATAC-seq data. After training, it can be used for many common downstream tasks, and also for imputation of a missing modality.<br>The advantages of multiVI are: (i) Comprehensive in capabilities. Able to perform DE gene, DA region analysis. (ii) Scalable to very large datasets (&gt;1 million cells). (iii) Once trained with sufficient multimodal data, able to accurately input missing modalities.<br><br>Important: MultiVI requires the datasets to use shared features. scATAC-seq datasets need to be processed to use a shared set of peaks. This features dataset must be included in the inputs<br><br><strong>Example use case:</strong>  MultiVI can be used for many common downstream tasks, and also for imputation of a missing modality<br><br><strong>Limitations:</strong>  Effectively requires a GPU for fast inference.</p>
"
"DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking",Predict the binding structure of a small molecule ligand to a protein using AI diffusion.,"<p>Predict the binding structure of a small molecule ligand to a protein. Here, molecular docking is framed as a generative modeling problem over the non-Euclidean manifold of ligand poses. This manifold is mapped to the product space of the degrees of freedom (translational, rotational, and torsional) involved in docking.<br><br><span style=""font-weight: bold"">Example use case: </span>Predict binding structure of a ligand to a protein for the sake of drug discovery<br><br><span style=""font-weight: bold"">Technology: </span>Diffusion<br><br><span style=""font-weight: bold"">Metrics: </span>38% top-1 success rate (RMSD<2Ã) on PDB-Bind</p>"
PBMC scATAC-seq analysis with PeakVI,Pretrained PBMC model for analysis of differential accessibility,"<p style=""text-align:start;""><span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 14px;font-family: Poppins, sans-serif;"">peakVI (Python class PEAKVI) is a generative model of scATAC-seq data that can subsequently be used for many common downstream tasks. Here we present a pretrained PBMC (white blood cell) dataset which can be used for differential accessibility analysis.</span></p>
"
FoldingDiff: Diffusion Model for Protein Backbone generation,A new diffusion-based generative model that designs protein backbone structures via a procedure that mirrors the native folding process.,"<p>Since they are involved in practically every biological activity, proteins are essential for life. The capacity to create innovative, physically foldable protein structures using computation may result in new biological understandings and therapeutic developments for diseases without cures. In this study, inter-residue angles in protein backbones are used rather than cartesian atom coordinates. Training a denoising diffusion probabilistic model with a basic transformer backbone shows that the model produces very realistic protein structures with complexity and structural patterns that are similar to those of naturally occurring proteins.</p>
<p><span style=""font-weight: bold"">Example Use Case: </span>Generating 3D protein backbone structuresÂ from the <span style=""text-decoration: underline; color: #0088FF""><a href=""https://huggingface.co/wukevin/foldingdiff_cath"" target=""_blank"" rel=""noreferrer"">pre-trained model</a></span>.</p>
<p><span style=""font-weight: bold"">Technology: </span>Diffusion Model</p>
<p><span style=""font-weight: bold"">Limitations:</span></p>
<ul>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">Compared to <span style=""font-style: italic"">natural </span>proteins, the lengths of the produced structures are still quite small</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">When a protein is formulated as a series of angles, errors that occur early in the chain dramatically change the overall generated structure</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">The tool is incapable of handling multi-chain complexes or ligand interactions</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">Only capable of producing static structures</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">Evaluating and visualizing (PyMOL) part is not included in this version. Please see the code page.</li>
</ul>
<p><span style=""font-weight: bold"">Metrics: </span>Some metricsÂ related to TM-Scores can be found in the <span style=""text-decoration: underline; color: #0088FF""><a href=""https://arxiv.org/abs/2209.15611"" target=""_blank"" rel=""noreferrer"">article</a></span>.</p>"
BioGPT: Text Generation,"BioGPT is a language model trained for biomedical tasks, it is trained on the PubMed dataset which contains 15 million abstracts.","<div class=""public-DraftStyleDefault-ltr public-DraftStyleDefault-block"" style=""box-sizing: border-box; font-family: Poppins, sans-serif !important; text-align: inherit; position: relative; margin: 1em 0px; padding: 0px; direction: ltr""><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">BioGPT is a language model trained for biomedical tasks, it is trained on the PubMed dataset which contains 15 million abstracts. BioGPT outperforms larger, more general language models in biomedical language benchmarks.</span></div>
<div class=""public-DraftStyleDefault-ltr public-DraftStyleDefault-block"" style=""box-sizing: border-box; font-family: Poppins, sans-serif !important; text-align: inherit; position: relative; margin: 1em 0px; padding: 0px; direction: ltr""><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Example use case: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">Generate text within the biomedical domain. See examples below.<br><br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Technology: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">GPT-2 backbone<br></span><br><span style=""font-weight: bold"">Limitations: </span>Sometimes produces false information</div>"
BioGPT: Question and Answer - PubMed,BioGPT: Question and Answer - PubMed is a language model fine-tuned to answer yes/no/maybe questions for biomedical tasks.,"<p>BioGPT: Question and Answer - PubMed is a language model fine-tuned on the expert annotated PubMedQA dataset which is a biomedical question-answering dataset, to answer yes/no/maybe questions for biomedical tasks. BioGPT outperforms larger, more general language models in biomedical language benchmarks.<br><br><span style=""font-weight: bold"">Example use case:&nbsp;&nbsp;</span>Answering academic questions. See examples below.<br><br><span style=""font-weight: bold"">Technology:&nbsp;&nbsp;</span>GPT-2 Backbone<br><br><span style=""font-weight: bold"">Metrics: </span>78.2% Accuracy<br>&nbsp;&nbsp;<br><span style=""font-style: italic; font-weight: bold"">Note:</span><span style=""font-style: italic"">Â For better results, queries are separated into a question and a context for the question. See examples below.</span></p>"
"BioGPT: Relation Extraction - DDI, DTI, BC5CDR",BioGPT: Relation Extraction is a language model fine-tuned to find a relation between entities.,"<p>BioGPT: Relation Extraction is a language model fine-tuned to find a relation between entities.</p>
<p>Included in this app are three models finetuned on different datasets each with a different use case.</p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Finding the interaction between two drugs, finetuned on <span style=""color: #0088FF""><a href=""https://www.sciencedirect.com/science/article/pii/S1532046413001123"" target=""_blank"" rel=""noreferrer"">DDI</a></span></li>
<li style=""list-style-type: disc"">Finding the interaction between a drug and its target, fine-tuned on <span style=""color: #0088FF""><a href=""https://academic.oup.com/bioinformatics/article/38/22/5100/6751771"" target=""_blank"" rel=""noreferrer"">DTI</a></span></li>
<li style=""list-style-type: disc"">Finding the interaction between a chemical and a disease, finetuned on <span style=""color: #0088FF""><a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/"" target=""_blank"" rel=""noreferrer"">BC5CDR</a></span></li></ul>


<div><span style=""font-weight: bold"">Example use case:Â </span><span style=""display: inline !important; font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span>See examples below.<br><br><span style=""font-weight: bold"">Technology: </span>GPT-2 Backbone<br><br><span style=""font-weight: bold"">Metrics: </span>(Precision/Recall/F1) - DDI: (41.70/44.75/40.76), DTI: (40.00/39.72/38.42), BC5CDR: (49.52/43.25/46.17)<br><br><span style=""font-weight: bold; font-style: italic"">Note:</span><span style=""font-style: italic""> Input queries should be in the form of an abstract regarding the entities you wish to find the relation between.</span></div>"
BioGPT: Document Classification - Hallmarks of Cancer,BioGPT: Document Classification is a language model fine-tuned to classify snipped of documents into 10 categories of cancer hallmarks.,"<p>BioGPT: Document Classification is a language model fine-tuned to classify snipped of documents into 10 categories of cancer hallmarks. It is trained on the Hallmarks of Cancers corpus which consists of 1580 PubMed abstracts that have been manually annotated.<br><br><span style=""font-weight: bold"">Example use case: </span>Classify what hallmark of cancer a document is reporting on.<br>&nbsp;&nbsp;<br><span style=""font-weight: bold"">Technology: </span>GPT-2 backbone<br><br><span style=""font-weight: bold"">Metrics: </span>F1 score: 85.12<br><br><span style=""font-weight: bold; font-style: italic"">Note:</span><span style=""display: inline !important; font-style: italic; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: bold; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span><span style=""font-style: italic"">Input queries should be in the form of an abstract. See examples below.</span></p>"
CXR: Tuberculosis Detection,TB Detection using CXR and Superbio Neural Networks,"<div>This app processes data in two stages, using two different models, <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/CXR-Tuberculosis-Detection-c5390a5098fd473981879c28fc6634d1"" target=""_blank"" rel=""noreferrer"">details of which can be found here.</a></span></div>
<div><br></div>
<div>Files should be provided in either .png or .dcm format, with multiple files provided in a .zip compressed folder.</div>
<div><br></div>
<div><span style=""font-weight: bold"">Limitations</span>:</div>
<div><br></div>
<div>Should be used for research purposes only.</div>
<div><br></div>
<div>This is not a clinically validated tool. Do not use CXR for self-diagnosis and seek help from your local health authorities.</div>
<div><br></div>
<div>Results may not generalize well to other patient populations or manufacturers not used in training.</div>
<div><br></div>
<div><span style=""font-weight: bold"">Risks</span>: Although neither Google nor Superbio permanently store any data processed by these models, it is the data owner's responsibility to ensure that Personally identifiable information (PII) and Protected Health Information (PHI) are removed prior to data upload.</div>"
CXR: Chest X-Ray Image Classification,Image classification using CXR and Superbio Neural Networks,"<p>This app allows users to train models to predict clinical condition (e.g., Covid-19), or patient outcome (e.g., hospitalization), based on Chest X-Ray images. The user provides the images they want to train the model on, along with labels of the actual classification for each image. Once trained the model can then be applied to new datasets. <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/CXR-Chest-X-Ray-Image-Classification-634e765ebf1e4a98bb39b3492d201065"" target=""_blank"" rel=""noreferrer"">Further details on how this app works can be found here.</a></span>&nbsp;</p>
<p>Files should be provided in either .png or .dcm format, with multiple files provided in a .zip compressed folder. We recommend that at least 200 images should be used for training new models. Using more images for training will likely improve results. Labels should also be provided in .csv format: with 1 indicating the presence of a condition, and 0 indicating the control group. If multiple labels are provided instead, in string format, in a single column, then a multilabel model will be trained instead.</p>
<p><span style=""font-weight: bold"">Limitations:</span></p>
<p>Should be used for research purposes only.</p>
<p>This is not a clinically validated tool. Do not use CXR for self-diagnosis and seek help from your local health authorities.</p>
<p>Results may not generalize well to other patient populations or manufacturers not used in training.</p>
<p><span style=""font-weight: bold"">Risks</span>: Although neither Google nor Superbio permanently store any data processed by these models, it is the data owner's responsibility to ensure that Personally identifiable information (PII) and Protected Health Information (PHI) are removed prior to data upload.</p>"
CXR: Covid-19 Detection,Covid-19 Detection using CXR and Superbio Neural Networks,"<p>This app processes data in two stages, using two different models, <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/CXR-Covid-19-Detection-9f7e8b99393840ddaf8c2a4cee2702a3"" target=""_blank"" rel=""noreferrer"">details of which can be found here.</a></span></p>
<p>Files should be provided in either .png or .dcm format, with multiple files provided in a .zip compressed folder.</p>
<p><span style=""font-weight: bold"">Limitations:</span></p>
<p>Should be used for research purposes only.</p>
<p>This is not a clinically validated tool. Do not use CXR for self-diagnosis and seek help from your local health authorities.</p>
<p>Results may not generalize well to other patient populations or manufacturers not used in training.</p>
<p><span style=""font-weight: bold"">Risks</span>: Although neither Google nor Superbio permanently store any data processed by these models, it is the data owner's responsibility to ensure that Personally identifiable information (PII) and Protected Health Information (PHI) are removed prior to data upload.</p>"
DeepVariant: Deep Learning-based Variant Caller,DeepVariant (v1.5) is an analysis pipeline that treats the task of identifying genetic variants as an image classification problem from next-generation DNA sequencing data.,"<p>DeepVariant (v1.5) is a deep learning-based variant caller that analyzes and identifies variants associated with a specific trait, disease, or population.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Disease research and precision medicine</p>
<p><span style=""font-weight: bold"">Technology:</span> Convolutional neural network</p>
<p><span style=""font-weight: bold"">Metrics:</span> As <span style=""color: #0088FF""><a href=""https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md"" >reported</a></span><span style=""color: #0088FF"">&nbsp;</span>by the Genomics team in Google Health, ""DeepVariant maintains high accuracy across data from different sequencing technologies, prep methods, and species.""</p>"
ChatGPT for Genetics,Natural Language queries for the Open Targets platform,"<p>Query the Open Targets Platform using natural language. The Open Targets Platform (platform.opentargets.org) integrates evidence from genetics, genomics, transcriptomics, drugs, animal models, and scientific literature to score and rank target-disease associations for drug-target identification. The model accepts queries in the form of "" What are the top [k] diseases associated with [GENE NAME]?"" and "" What are the top [k] genes related to [DISEASE NAME]?"" Alternatively, for improved precision, you can use the ENSG of the gene or the EFO id for the diseases.</p>
<p><span style=""font-weight: bold"">Example use case</span>: Querying Open Targets Platform with Natural Language. If you want to know the top 8 diseases associated with the APOE gene: ""What are the top 8 diseases associated with APOE?"" or the top 3 genes associated with Alzheimer's disease: ""Find the top 3 genes related to Alzheimer disease.""</p>
<p><span style=""font-weight: bold"">Technology</span>: Open Targets Platform and GPT3</p>
<p><span style=""font-weight: bold"">Limitations</span>: It does not produce any novelty or new-knowledge that is not available in the Open Targets Platform. We are currently improving the types of queries it accepts.</p>"
Deeptrio: Deep learning-based trio variant caller,DeepTrio is a variant calling algorithm developed by the Google Brain team that extends the functionality of DeepVariant to identify genetic variants in trios or duos.,"<p>DeepTrio builds on DeepVariant's deep learning-based approach to variant calling and applies it to trio sequencing data. It uses a neural network to analyze the sequencing data from the child and both parents simultaneously, allowing it to more accurately identify de novo mutations and other genetic variants.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Identify genetic variants in trios or duos</p>
<p><span style=""font-weight: bold"">Technology:</span> Neural Network</p>
<p><span style=""font-weight: bold"">Limitations:</span> Currently, the app is only working only with trios<span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px""><br></span><br></p>"
BOLT-LMM: Mixed Model Association Testing,BOLT-LMM is used for performing genome-wide association studies (GWAS) to identify genetic variants associated with complex traits or diseases.,"<p>The BOLT-LMM (v2.4.1) algorithm employs a linear mixed model (LMM) to calculate statistical measures for examining the relationship between a phenotype (observable trait) and genotypes (genetic information). BOLT-LMM assumes a Bayesian mixture of normals before the random impact attributed to SNPs other than the one being tested by default. This model generalizes the traditional ""infinitesimal"" mixed model employed by prior mixed-model association approaches (e.g., EMMAX, FaST-LMM, GEMMA, GRAMMAR-Gamma, GCTA-LOCO), allowing for enhanced detection power while reducing false positives.<br><br><span style=""font-weight: bold"">Example use case: </span>GWAS (Genome-Wide Association Study)<span style=""font-weight: bold""><br></span><br><span style=""font-weight: bold"">Technology: </span>Linear mixed model<br><br><span style=""font-weight: bold"">Limitations:<br></span>- Currently, bgen format option is not available.<br>- BOLT-LMM is recommended for analyses of human genetic datasets with more than 5,000 samples.<br>- It is also noted that association test statistics obtained from BOLT-LMM are valid for quantitative traits as well as (reasonably) balanced case-control traits.<br>- The BOLT-LMM method, similar to other mixed-model approaches, can experience reduced effectiveness when applied to the analysis of large sets of case-control data in rare diseases, which may result in decreased statistical power.<br>- The research conducted does not aim to determine how much population structure or relatedness may affect the heritability parameter (h2g) estimated by BOLT-LMM, nor does it carry out or assess genetic prediction using external validation samples from a separate group.<br>- The performance of mixed-model techniques has not been examined in datasets where family structure plays a significant role.<br>- BOLT-LMM has only been evaluated on datasets consisting of human genetic data, which exhibit distinct genetic architectures and patterns of linkage disequilibrium compared to plant and animal data.<br><br><span style=""font-weight: bold"">Metrics: </span>Some of the metrics related to the study can be found in the <span style=""text-decoration: underline; color: #0088FF""><a href=""https://www.nature.com/articles/ng.3190"" target=""_blank"" rel=""noreferrer"">article</a></span>.</p>"
maxATAC: Transcription-Factor Binding Prediction From ATAC-seq with Deep Neural Networks,maxATAC is a user-friendly software suite that uses deep neural network models to predict transcription factor binding sites from ATAC-seq data.,"<p>Transcription factors play a critical role in connecting the DNA sequence to gene expression in different types of cells. By understanding how, where, and when these factors bind to chromatin, we can gain insights into the gene regulatory networks that control cellular behavior. This knowledge can help us unravel the complex mechanisms behind gene expression, potentially leading to new therapies for various diseases. maxATAC is the most extensive collection of state-of-the-art TFBS models available to date, with models available for 127 human TFs. Additionally, MaxATAC can perform well on primary cells and single-cell ATAC-seq data, making it a valuable tool for predicting TFBS in vivo.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Predicting TFs' binding locations can significantly aid biological research by supplying reference materials for experimental validation.</p>
<p><span style=""font-weight: bold"">Technology:</span> Deep Neural Network</p>
<p><span style=""font-weight: bold"">Limitation:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Currently, only the bulk ATAC-seq option is available.</li>
<li style=""list-style-type: disc"">Parameters in the <span style=""font-style: italic; color: #0088FF; text-decoration: underline""><a href=""https://github.com/MiraldiLab/maxATAC/blob/main/docs/readme/prepare.md"" target=""_blank"" rel=""noreferrer"">prepare</a></span> and <span style=""font-style: italic; color: #0088FF; text-decoration: underline""><a href=""https://github.com/MiraldiLab/maxATAC/blob/main/docs/readme/predict.md"" target=""_blank"" rel=""noreferrer"">predict</a></span> steps are kept default.</li>
<li style=""list-style-type: disc"">The batch size parameter is set to 512.</li>
<li style=""list-style-type: disc"">Currently, only human organism models are applicable. (HG38 reference genome only)</li></ul>"
Bonito: Deep learning-based basecaller for Oxford Nanopore Reads,Bonito is an open-source basecaller for ONT reads.,"<p>A deep learning-based basecaller by Oxford Nanopore Technologies (ONT)</p>
<p><span style=""font-weight: bold"">Example use case: </span>Sequencing</p>
<p><span style=""font-weight: bold"">Technology: </span>A neural network architecture that consists of a single convolutional layer followed by three stacked bidirectional gated recurrent unit layers</p>
<p><span style=""font-weight: bold"">Limitations: </span>Works only with reads from ONT devices - does not work well with modified mRNA reads</p>"
nf-encyclopedia: A NextFlow pipeline for chromatogram library DIA proteomics workflows,"nf-encyclopedia is a NextFlow pipeline that analyzes DIA proteomics experiments, including those with or without chromatogram libraries. It integrates MSconvert, EncyclopeDIA, and MSstats to process mass spectra and generate quantified peptides and proteins.","<p>Data-independent acquisition (DIA) mass spectrometry techniques are highly valuable for comprehensive and systematic quantification of the proteome. However, the current landscape of open-source tools dedicated to analyzing DIA proteomics experiments remains limited. Moreover, the effective utilization of gas phase fractionated (GPF) chromatogram libraries for improved peptide detection and quantification in DIA experiments is lacking.</p>
<p>To bridge this gap, a novel open-source NextFlow pipeline called nf-encyclopedia was developed. This pipeline seamlessly integrates three open-source tools, namely MSConvert, EncyclopeDIA, and MSstats, forming a comprehensive solution for analyzing DIA proteomics experiments, regardless of the use of chromatogram libraries. <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/nf-encylopedia-6ccbda70600a4ced9e2a47b41bd60f58"" target=""_blank"" rel=""noreferrer"">Further information on this app can be found here.</a></span></p>
<p><span style=""font-weight: bold"">Example use case:</span> DIA mass spectrometry data analysis</p>
<p><span style=""font-weight: bold"">Technology:</span> Nextflow</p>
<p><span style=""font-weight: bold"">Limitation:</span> Some of the parameters were kept default. Please see this <span style=""text-decoration: underline; color: #0088FF""><a href=""https://talusbio.github.io/nf-encyclopedia/parameters/"" >page</a></span> for more detail.</p>"
Single Cell RNA-Seq Annotation: Custom Model,"Train a customized single cell annotation model, using scVI-Tools.","<p><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Train a customized single cell annotation model, using scVI-Tools. Data should be in .h5ad, .h5, mtx, or .csv format. Uses the Anndata python package, which natively supports .h5ad meaning that file format is most suitable. The target should be the feature you want to label: most commonly this will be cell type. Please ensure that the column with these values is selected. A model will be trained to predict cell type from input data, which can then be saved and used for other data sets, even where cell type is not known.<br><br></span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: bold; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Example use case: </span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Train a model that can annotate cell types after clustering single-cell RNA sequencing (scRNA-seq) data</span></p>"
Heart Cell Annotation: Single Cell Inference & Retraining,scANVI model trained on Heart Atlas dataset,"<p><span style=""display: inline !important; font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">scANVI model trained on Heart Atlas dataset from The Heart Cell Atlas Database. Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations.</span></p>"
Liver Cell Annotation: Single Cell Inference,scANVI model trained on human liver cell dataset,"<p><span style=""font-style: normal; color: rgb(0, 0, 0); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">scANVI model trained on human liver cell dataset from: ""Single-cell and bulk transcriptomics of the liver reveals potential targets of NASH with fibrosis.""</span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span></p>"
Mouse Retina Cell Annotation: Single Cell Inference,scANVI model trained on Mouse retinal bipolar neuron drop seq dataset,"<p><span style=""font-style: normal; color: rgb(0, 0, 0); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">scANVI model trained on Mouse retinal bipolar neuron drop seq dataset from: ""Comprehensive classification of retinal bipolar neurons by single-cell transcriptomics.""</span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span></p>"
Single Cell RNA-Seq Annotation: Auto Train Model,Train a single cell annotation model using Auto ML and scVI-Tools,"<div><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Automatically train a single cell annotation model, using scVI-Tools. Data should be in .h5ad, .h5, mtx, or .csv format. Uses the Anndata python package, which natively supports .h5ad meaning that file format is most suitable. The target should be the feature you want to label: most commonly this will be cell type. Please ensure that the column with these values is selected. A model will be trained to predict cell type from input data, which can then be saved and used for other data sets, even where cell type is not known.<br><br></span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: bold; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Example use case: </span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Train a model that can annotate cell types after clustering single-cell RNA sequencing (scRNA-seq) data</span></div>"
Paper QA,Question and answering from PDFs with no hallucinations and with in-text citations.,"<p>Paper QA answers questions from documents with citations. Upload PDF files you wish to ask questions about. You can upload as many files as needed as long as the sum of the file sizes is less than 7 MB. You can upload more files later, even after submitting a question. Our engineers may review questions and responses to improve our systems and bug fixes. Please don't share any sensitive information.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Summarize findings of biomedical research papers</p>
<p><span style=""font-weight: bold"">Limitations</span>: You are limited to 5000 tokens per day. Tokens are refilled daily at 00:00UTC. Can cite a maximum of 3 sources. Contact us at help@superbio.ai to upgrade to premium to increase your token limit.</p>"
SATURN: Uniting Single-cell Gene Expressions with Protein Sequences for Cross-Species Integration,"SATURN is a deep learning method that uses protein language models to learn universal cell embeddings, enabling joint analysis of cross-species single-cell datasets. It integrates RNA expression with protein embeddings, allowing the detection of functionally related genes across species.","<p>Cell mapping consortia have generated large-scale single-cell datasets to understand cellular processes. However, analyzing datasets from different species together remains challenging. SATURN is a deep learning approach that integrates cross-species single-cell RNA expression data by combining gene expression with protein embeddings from language models. SATURN introduces the concept of macrogenes, functionally related gene groups, based on protein representations.</p>
<p>It enables multi-species differential expression analysis and facilitates the mapping of datasets to a universal embedding space. SATURN is applied to integrate diverse datasets like the Human Cell Atlas, Mouse Cell Atlas, and Fly Cell Atlas, resulting in a comprehensive mammalian cell atlas. It also integrates frog and zebrafish embryogenesis datasets.</p>
<p>SATURN successfully transfers annotations across species, identifies homologous and species-specific cell types, and reveals potential functional differences in glaucoma-associated genes. By leveraging protein language models, SATURN improves cross-species analysis, enhancing our understanding of evolutionary processes and the link between cellular diversity and anatomical/physiological variation.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Performing multi-species single-cell differential expression analysis.</p>
<p><span style=""font-weight: bold"">Technology:</span> Embeddings, Large Protein Language Models</p>
<p><span style=""font-weight: bold"">Limitation:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Some of the parameters were kept default. Please see this <span style=""text-decoration: underline; color: #0088FF""><a href=""https://github.com/snap-stanford/SATURN/blob/main/Vignettes/frog_zebrafish_embryogenesis/Train%20SATURN.ipynb"" >page</a></span> for more details.</li>
<li style=""list-style-type: disc"">The training part for protein embeddings is not accessible in this version. However, pre-trained protein embeddings are available, limited explicitly to ESM-2.</li>
<li style=""list-style-type: disc"">The 'cell_type' information for cell types must be provided in the 'obs' section of the .h5ad datasets.</li></ul>"
scGPT: Gene Regulatory Network Inference on Pre-trained Models,scGPT is a generative pre-trained transformer model explicitly designed for single-cell biology research and analysis.,"<p>scGPT is a foundation model for single-cell biology, based on generative pre-trained transformers trained on a vast repository of over 33 million cells. The scGPT model demonstrates the ability to extract valuable biological insights and can be further optimized through transfer learning for various downstream applications, including cell-type annotation, multi-batch integration, genetic perturbation prediction, and gene network inference.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Gene regulatory network inference</p>
<p><span style=""font-weight: bold"">Technology:</span> Transformers</p>
<p><span style=""font-weight: bold"">Limitation:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Some of the parameters were kept default. Please see this <span style=""color: #0088FF""><a href=""https://scgpt.readthedocs.io/en/latest/tutorial_grn.html"" >page</a></span> for more details.</li></ul>"
DeepLIIF Inference,Segment cells by positive versus negative protein expression levels,