name,description,long_description,author,tags,id,input_parameters,upload_options
RNA-seq: Differential Gene Expression (DGE) Analysis for RNA-seq Data,Differential Gene Expression analysis for high throughput RNA sequencing data.,"DGE analysis is a very common method for RNA-Seq data. This method allows for the investigation of expressed genes between two or more conditions. Tools included in this app are SRA Toolkit, FastQC, STAR, featureCounts, and DESeq2.",Superbio,"['DGE Analysis', 'fastq', 'fastq.gz', 'fastq.tar.gz', 'fastq.zip', 'Transcriptomics']",6257532cc7304ed85441d137,"[{'input_type': 'dropdown', 'title': 'REFERENCE GENOME', 'name': 'ref_genome', 'default_value': 'homo_sapiens_grch38', 'options': [{'label': 'Homo sapiens', 'value': 'homo_sapiens_grch38'}, {'label': 'Saccharomyces cerevisiae', 'value': 'saccharomyces_cerevisiae'}, {'label': 'Mus musculus', 'value': 'mus_musculus'}, {'label': 'Danio rerio', 'value': 'danio_rerio'}], 'tooltip': 'Please select a reference genome of organism that matched your accession ID. When you submit the job, It will download automatically reference genome from ENSEMBL database to use in downstream analysis.'}, {'input_type': 'dropdown', 'title': 'LIBRARY OUTPUT', 'name': 'single_or_paired', 'default_value': 'SINGLE', 'options': [{'label': 'Single-end', 'value': 'SINGLE'}, {'label': 'Paired-end', 'value': 'PAIRED'}], 'tooltip': 'If your experimental design, single-end please select single-end otherwise choose paired-end.'}, {'input_type': 'dropdown', 'title': 'CONTROL GROUP', 'name': 'control_level', 'default_value': 'undefined', 'options': [], 'tooltip': 'Algorithm will choose a reference level for factors based on alphabetical order. Then, if you never tell the DESeq2 functions which level you want to compare against (e.g. which level represents the control group), the comparisons will be based on the alphabetical order of the levels. So please specify here this information.'}, {'input_type': 'user_input', 'type': 'integer', 'title': 'GENOMESAINDEXNBASES', 'name': 'index_n_bases_val', 'default_value': 14, 'min_value': 1, 'max_value': 30, 'tooltip': 'Length (bases) of the SA pre-indexing string. Typically between 10 and 15.\nLonger strings will use much more memory, but allow faster searches. For small\ngenomes, the parameter {genomeSAindexNbases must be scaled down to\nmin(14, log2(GenomeLength)/2 - 1).'}, {'input_type': 'user_input', 'type': 'integer', 'title': 'ALIGNINTRONMIN', 'name': 'align_intron_min', 'default_value': 21, 'min_value': 1, 'max_value': 9999, 'tooltip': 'Minimum intron size: genomic gap is considered intron if its\nlength>=alignIntronMin, otherwise it is considered Deletion'}, {'input_type': 'user_input', 'type': 'integer', 'title': 'ALIGNINTRONMAX', 'name': 'align_intron_max', 'default_value': 0, 'min_value': 0, 'max_value': 9999, 'tooltip': 'Maximum gap between two mates, if 0, max intron gap will be determined by\n(2^winBinNbits)*winAnchorDistNbins'}, {'input_type': 'user_input', 'type': 'integer', 'title': 'FILTER LOW GENE COUNTS', 'name': 'filter_low_gene_counts', 'default_value': 10, 'min_value': 0, 'min_value_inclusive': True, 'max_value': 9999, 'max_value_included': True, 'increment': 1, 'tooltip': 'While it is not necessary to pre-filter low count genes before running the DESeq2 functions, there are two reasons which make pre-filtering useful: by removing rows in which there are very few reads and we increase the speed of the transformation and testing functions within DESeq2.'}, {'input_type': 'user_input', 'type': 'float', 'title': 'FDR - ADJUSTED P-VALUE CUTOFF', 'name': 'adjusted_p_value_threshold', 'default_value': 0.05, 'min_value': 1e-05, 'max_value': 0.99, 'tooltip': 'The p-adjusted values generally used to determine significant genes. The important genes can be output for visualization and/or functional analysis.\nWe are saying that the proportion of false positives we expect amongst our differentially expressed genes is 5%. For example, if you call 1000 genes as differentially expressed with an FDR cutoff of 0.05, you expect 50 of them to be false positives.'}]",
scDeepCluster: Deep Clustering for Single Cell RNA-Seq Data,Model-based deep embedding clustering for Single Cell RNA-seq data.,"<p><span style=""color: rgb(34,34,34); background-color: rgb(255,255,255)"">scDeepCluster, is a single-cell model-based deep embedded clustering method, which simultaneously learns feature representation and clustering via explicit modelling of scRNA-seq data generation. Based on testing extensive simulated data and real datasets from four representative single-cell sequencing platforms, scDeepCluster outperformed state-of-the-art methods under various clustering performance metrics and exhibited improved scalability, with running time increasing linearly with sample size. Its accuracy and efficiency make scDeepCluster a promising algorithm for clustering large-scale scRNA-seq data.</span><span style=""font-size: 14px""><br><br></span><span style=""font-weight: bold"">Example use case: </span>exploring cell heterogeneity and diversity in cancer research<span style=""font-weight: bold; font-size: 14px""><br></span><span style=""font-size: 14px""><br></span><span style=""font-weight: bold"">Technology: </span>Autoencoders</p>",Tian et al.,"['Dimensionality Reduction', 'h5', 'Single-Cell Bioinformatics']",62712ec148139943a4273ae1,"[{'default_value': 20, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 2, 'min_value_inclusive': True, 'name': 'knn', 'title': 'Number of Neighbors', 'tooltip': 'Parameter for KNN. Number of neighbors used to cluster cells together.', 'type': 'integer'}, {'default_value': 0, 'input_type': 'user_input', 'min_value': 0, 'name': 'select_genes', 'title': 'Filter genes', 'tooltip': 'Filters on the top N most important genes. Leave blank to include all genes.', 'type': 'integer'}, {'default_value': 100, 'increment': 10, 'input_type': 'slider', 'max_value': 300, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'pretrain_epochs', 'title': 'Pretraining epochs ', 'tooltip': 'Parameter for Variational Auto Encoder. Number of epochs used to pretrain deep cluster model', 'type': 'integer'}, {'default_value': 0.8, 'increment': 0.05, 'input_type': 'slider', 'max_value': 0.9, 'max_value_included': True, 'min_value': 0.1, 'min_value_inclusive': True, 'name': 'resolution', 'title': 'Resolution', 'tooltip': 'Parameter for Louvain community detection. Effects the size of the recovered clusters.', 'type': 'float'}]","[{'allowedFormats': {'fileExtensions': ['h5'], 'title': '.h5', 'value': ''}, 'dataStructure': 'scRNA-seq data in .h5 format', 'demoDataDetails': {'description': 'An example dataset comprising approximately 5000 worm neuron cells', 'fileName': 'worm_neuron_cell.h5', 'filePath': 'apps/scDeepCluster/resources/worm_neuron_cell.h5', 'fileSource': [{'title': 'Data Source', 'url': 'https://figshare.com/articles/dataset/scDeepCluster_supporting_data/17158025'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Select Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Prostate Region Segmentation: Medical Image-nnUnet,Prostate transitional zone and peripheral zone segmentation,"<p>Prostate multiparametric MRI (mpMRI) studies comprising T2-weighted, Diffusion-weighted and T1-weighted contrast enhanced series.Â </p>","Division of Medical Image Computing, German Cancer Research Center (DKFZ)","['Image Segmentation', 'Anatomy', 'nii.gz', 'Biomedical Image Analysis and Interpretation']",627146e448139943a4273ae3,,"[{'allowedFormats': {'title': '.nii.gz', 'value': 'application/gzip', 'fileExtensions': ['nii', 'gz']}, 'dataStructure': 'dataStructure', 'demoDataDetails': {'description': 'Prostate multiparametric MRI (mpMRI) studies comprising T2-weighted, Diffusion-weighted and T1-weighted contrast enhanced series.', 'fileName': 'prostate_03.nii.gz', 'filePath': 'apps/image_segmentation_prostate/resources/demo_data/prostate_03.nii.gz', 'fileSource': [{'title': 'Data Source', 'url': 'http://medicaldecathlon.com'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Select Images to Segment', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Brain Tumor Segmentation: Medical Image-nnUnet,Gliomas segmentation tumour and oedema in on brain images,"<p>Segmentation of possible glioma tumours and edemas on brain MRI scans using a pre-trained nnU-Net architecture. Given an MRI scan in .NIfTI format, this app will return your MRI scans with glioma and edema regions highlighted, available for download.</p>
<p>Data requirements: Brain tumor MRI scans, with four MRI modalities as T1w, t1gd, T2w, and FLAIR.</p>
","Division of Medical Image Computing, German Cancer Research Center (DKFZ)","['Image Segmentation', 'Anatomy', 'nii.gz', 'Biomedical Image Analysis and Interpretation']",627146f148139943a4273ae4,,"[{'allowedFormats': {'title': '.nii.gz', 'value': 'application/gzip', 'fileExtensions': ['nii', 'gz']}, 'dataStructure': 'dataStructure', 'demoDataDetails': {'description': 'Brain tumor MRI scans, with four MRI modalities as T1w, t1gd, T2w, and FLAIR.', 'fileName': 'BRATS_485.nii.gz', 'filePath': 'apps/image_segmentation_brain/resources/demo_data/BRATS_485.nii.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.med.upenn.edu/sbia/brats2017.html/'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Select Images to Segment', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Clipper: Find Discoveries in High-Throughput Data,Statistical method for controlling false positive rates in high-throughput biological data with two conditions of diverse types.,"<p>Identifying ""interesting"" features with false discovery rate (FDR) control where ""interesting"" means ""enriched"" or ""differential"", without using <span style=""font-style: italic"">p</span>-values<br><br><span style=""font-weight: bold"">Example use case: </span>identification of differentially expressed genes from genome-wide gene expression data or peak-calling from ChIP-seq data, peptide-identification from mass spectrometry data<br><br><span style=""font-weight: bold"">Limitations: </span>Works best with two conditions</p>",JSB-UCLA,"['Data Analysis', 'Enrichment', 'Gene Expression', 'csv', 'Computational Biology and Bioinformatics']",627320c048139943a4273ae5,"[{'default_value': {'label': 'Differential', 'value': 'differential'}, 'input_type': 'dropdown', 'name': 'analysis', 'options': [{'label': 'Differential', 'value': 'differential'}, {'label': 'Enrichment', 'value': 'enrichment'}], 'title': 'Analysis', 'tooltip': 'Enriched features are defined as those that have higher expected measurements under the experimental/treatment condition than the\nbackground condition, i.e., the negative control. The detection of such enriched features is called enrichment analysis. Chromatin immunoprecipitation sequencing (ChIP-seq) data and identifying peptides from mass spectrometry (MS) data can be shown as examples. On the other hand, differential features are defined as those that have different expected measurements (without measurement errors) between two conditions, and the detection of such differential features is called\ndifferential analysis. Most popular differential analysis can be differentially\nexpressed genes (DEGs) from genome-wide gene expression data and differentially chromosomal interaction regions (DIRs) from Hi-C data.'}, {'default_value': True, 'input_type': 'checkbox', 'name': 'index_column', 'optional': True, 'title': 'First column is Index/Feature Name', 'tooltip': 'Select if the first column of your uploaded data is the feature name. If you use demo data, please keep it as default. Default: Selected'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': ' Each column should be a sample, and each row a variable of interest. If the first column contains the âFeature Nameâ or âIndexâ (e.g. Gene name), check âFirst column is Index/Feature Nameâ (this will tell Clipper to not include this column in the analysis). If no âFeature Nameâ is provided, then both data sets should have the same size and each row represent the same variable of interest.', 'demoDataDetails': {'description': 'Check the ""FIRST COLUMN IS INDEX/FEATURE NAME"" box if using this data. \nRNA-seq data of classical and non-classical human monocytes were used in demo data. Only, 3 classical and 3 non-classical samples are used as in the article. In this dataset, expected gene expression changes are related to be immune response process. SRA Accession ID: SRP082682', 'fileName': 'deg_background_preprocessed.csv', 'filePath': 'apps/clipper/resources/demo_data/deg_background_preprocessed.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.biorxiv.org/content/10.1101/2020.11.19.390773v7/'}], 'previewFileName': 'apps/clipper/resources/demo_data/deg_background_preprocessed.csv'}, 'supportsPreview': True, 'disabled': False, 'name': 'control', 'title': 'Upload Background/Control', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Same as described above', 'demoDataDetails': {'description': 'RNA-seq data of classical and non-classical human monocytes were used in demo data. Only, 3 classical and 3 non-classical samples are used as in the article. In this dataset, expected gene expression changes are related to be immune response process. SRA Accession ID: SRP082682', 'fileName': 'deg_experimental_preprocessed.csv', 'filePath': 'apps/clipper/resources/demo_data/deg_experimental_preprocessed.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.biorxiv.org/content/10.1101/2020.11.19.390773v7'}], 'previewFileName': 'apps/clipper/resources/demo_data/deg_experimental_preprocessed.csv'}, 'supportsPreview': True, 'disabled': False, 'name': 'experiment', 'title': 'Upload Experimental/Treatment', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
PathfindR: Enrichment Analysis for Omics Data,"pathfindR is a tool for enrichment analysis via active subnetworks. The package also offers functionalities to cluster the enriched terms and identify representative terms in each cluster, score the enriched terms per sample, and visualize analysis results.","<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">The active-subnetwork-oriented enrichment analysis approach of pathfindR involves mapping input genes onto a protein interaction network, identifying active subnetworks based on their scores and significant gene content, and then performing enrichment analyses to identify significantly enriched terms. The results are reported in a data frame and an HTML report with visualizations.<br></span><br><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Example use case: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">Analyzing gene expression data to identify enriched pathways or gene sets associated with differentially expressed genes<br><br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Technology: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">A software tool for enrichment analysis of gene expression data. Input data should be in .csv, .txt, or .tsv format, and should include 3 columns only: (i) gene names, symbols or pseudonyms, (ii) log fold change (logFC), and (iii) p-values, in this order.</span><span style=""display: inline !important; font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px""><br></span>&nbsp;<span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box""><br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Limitations:<br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">-</span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">&nbsp;</span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">Reliance on protein interaction network data for mapping input genes.</span></div>
<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">- Need for appropriate thresholding of adjusted p-values for enrichment analysis.</span></div>
<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">- Potential for false positives or false negatives in the identification of active subnetworks and enriched terms.</span></div>
<div><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">- May not be suitable for datasets with small sample sizes or low statistical power.</span></div>
<div style=""--tw-invert: ; --tw-skew-y: 0; box-sizing: border-box; display: block; padding-left: 0.375em; --tw-slashed-zero: ; --tw-backdrop-invert: ; --tw-rotate: 0; list-style-type: disc; --tw-ring-offset-shadow: 0 0 transparent; --tw-ordinal: ; --tw-backdrop-sepia: ; position: relative; --tw-shadow: 0 0 transparent; --tw-ring-inset: ; --tw-scale-x: 1; border: 0px solid rgb(217, 217, 227); --tw-scale-y: 1; --tw-numeric-fraction: ; --tw-contrast: ; --tw-sepia: ; --tw-scroll-snap-strictness: proximity; --tw-numeric-figure: ; margin: 0px; --tw-translate-x: 0; --tw-backdrop-contrast: ; --tw-pinch-zoom: ; --tw-translate-y: 0; --tw-ring-color: rgba(59,130,246,0.5); --tw-blur: ; --tw-ring-shadow: 0 0 transparent; --tw-drop-shadow: ; --tw-backdrop-blur: ; --tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-saturate: ; --tw-numeric-spacing: ; --tw-backdrop-grayscale: ; --tw-hue-rotate: ; --tw-brightness: ; --tw-ring-offset-color: #fff; --tw-backdrop-saturate: ; --tw-backdrop-hue-rotate: ; --tw-grayscale: ; --tw-pan-x: ; --tw-backdrop-brightness: ; --tw-backdrop-opacity: ; --tw-pan-y: ; --tw-skew-x: 0; --tw-ring-offset-width: 0px; --tw-shadow-colored: 0 0 transparent""><br></div>",Ege Ulgen,"['DGE Analysis', 'Enrichment', 'txt', 'tsv', 'csv', 'Biomarker Discovery and Identification', 'Transcriptomics']",62b464ea76a7c8ca2ebd327b,"[{'default_value': {'label': 'KEGG', 'value': 'KEGG'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'gene_set_db', 'options': [{'label': 'KEGG', 'value': 'KEGG'}, {'label': 'Reactome', 'value': 'Reactome'}, {'label': 'BioCarta', 'value': 'BioCarta'}, {'label': 'GO-All', 'value': 'GO-All'}, {'label': 'GO-BP', 'value': 'GO-BP'}, {'label': 'GO-CC', 'value': 'GO-CC'}, {'label': 'GO-MF', 'value': 'GO-MF'}, {'label': 'cell_markers', 'value': 'cell_markers'}, {'label': 'mmu_KEGG', 'value': 'mmu_KEGG'}], 'title': 'Gene Set', 'tooltip': 'Name of the gene sets to be used for enrichment analysis.'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 5, 'min_value_inclusive': True, 'name': 'gset', 'title': 'Minimum Gene Set Size', 'tooltip': 'minimum number of genes a term must contain.', 'type': 'integer'}, {'default_value': 0.05, 'increment': 0.01, 'input_type': 'slider', 'max_value': 0.25, 'max_value_included': True, 'min_value': 0.01, 'min_value_inclusive': True, 'name': 'pvalue', 'title': 'P-Value Threshold', 'tooltip': 'the p value threshold to use when filtering the input data frame.', 'type': 'float'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'txt', 'tsv'], 'title': '.txt, .csv, .tsv etc', 'value': 'text/csv,text/plain,text/tsv'}, 'dataStructure': 'Input data should be in .csv, .txt, or .tsv format, and should include gene names, symbols or pseudonyms, log fold change (logFC), and p-values, in this order', 'demoDataDetails': {'description': 'Data taken from GEO accession ID GSE171177: a dataset focused on comparing cancer proteostasis versus control samples', 'fileName': 'GSE171177-diff-gene-exp.-table.txt', 'filePath': 'apps/pathfindr/GSE171177-diff-gene-exp.-table.txt', 'fileSource': [{'title': 'Data Source', 'url': 'https://www-ncbi-nlm-nih-gov.ezproxy.u-pec.fr/geo/query/acc.cgi?acc=GSE171177'}], 'previewFileName': 'apps/pathfindr/GSE171177-diff-gene-exp.-table.txt'}, 'disabled': False, 'name': 'diff_file', 'title': 'Upload Differential Expression Table', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
scJoint: Transfer Learning for Combined Annotated CITE-seq and ASAP-seq Data,"scJoint is a transfer learning method to integrate atlas-scale, heterogeneous collections of scRNA-seq and scATAC-seq data.","<p><span style=""font-size: 12px"">scJoint leverages information from annotated scRNA-seq data in a semisupervised framework and uses a neural network to simultaneously train labeled and unlabeled data, allowing label transfer and joint visualization in an integrative framework. Using atlas data as well as multimodal datasets generated with ASAP-seq and CITE-seq, we demonstrate that scJoint is computationally efficient and consistently achieves substantially higher cell-type label accuracy than existing methods while providing meaningful joint visualizations. Thus, scJoint overcomes the heterogeneity of different data modalities to enable a more comprehensive understanding of cellular phenotypes.</span></p>","Lin, Yingxin, et al.","['Classification', 'Proteomics', 'rds', 'Single-Cell Bioinformatics']",62bb86b823181fc4793a92bc,"[{'default_value': 20, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'How many epochs to train neural network. n.b. training occurs in two stages, so total epochs is double this number.', 'type': 'integer'}, {'default_value': 0.01, 'increment': 0.001, 'input_type': 'slider', 'max_value': 0.02, 'max_value_included': True, 'min_value': 0.001, 'min_value_inclusive': True, 'name': 'lr', 'title': 'Learning Rate', 'tooltip': 'Determines how quickly the neural network converges.', 'type': 'float'}, {'default_value': 30, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 2, 'min_value_inclusive': True, 'name': 'neighbors', 'title': 'K- Nearest Neighbors', 'tooltip': 'How many neighbors to use for KNN calculations.', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['rds'], 'title': '.rds', 'value': ''}, 'dataStructure': 'Input data should be in .rds format (obtained using R). Both ASAP-seq and CITE-seq data is required.', 'demoDataDetails': {'description': 'CITE-seq and ASAP-seq data is from 10x Genomics (https://www.10xgenomics.com/resources/datasets). See https://www.biorxiv.org/content/10.1101/2020.12.31.424916v3 for more details. ', 'fileName': 'sce_10xPBMC_rna.rds', 'filePath': 'apps/scjoint/resources/sce_10xPBMC_rna.rds', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/SydneyBioX/scJoint/blob/main/data.zip'}]}, 'disabled': False, 'name': 'sce_rna', 'title': 'CITE-seq Single Cell Experiment Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['rds'], 'title': '.rds', 'value': ''}, 'dataStructure': 'Input data should be in .rds format (obtained using R). Both ASAP-seq and CITE-seq data is required.', 'demoDataDetails': {'description': 'CITE-seq and ASAP-seq data is from 10x Genomics (https://www.10xgenomics.com/resources/datasets). See https://www.biorxiv.org/content/10.1101/2020.12.31.424916v3 for more details. ', 'fileName': 'sce_10xPBMC_atac.rds', 'filePath': 'apps/scjoint/resources/sce_10xPBMC_atac.rds', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/SydneyBioX/scJoint/blob/main/data.zip'}]}, 'disabled': False, 'name': 'sce_atac', 'title': 'ASAP-seq Single Cell Experiment File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Liver Cancer Segmentation: Medical Image-nnUnet,Liver cancer segmentation,"<p>Automatic segmentation of liver and liver tumor in contrast-enhanced abdominal CT scans using a pre-trained nnU-Net architecture.</p>
","Division of Medical Image Computing, German Cancer Research Center (DKFZ)","['Image Segmentation', 'Anatomy', 'nii.gz', 'Biomedical Image Analysis and Interpretation']",62bb8db923181fc4793a92bd,,"[{'allowedFormats': {'title': '.nii.gz', 'value': 'application/gzip', 'fileExtensions': ['gz']}, 'dataStructure': 'dataStructure', 'demoDataDetails': {'description': 'Liver MRI scans, with one MRI modalities as T1w, t1gd, T2w, and FLAIR.', 'fileName': 'liver_demo.nii.gz', 'filePath': 'apps/image_segmentation_liver/resources/demo_data/liver_demo.nii.gz', 'fileSource': [{'title': 'Data Source', 'url': 'http://medicaldecathlon.com/'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Select Images to Segment', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Hippocampus Anterior & Posterior Segmentation: Medical Image-nnUnet,Hippocampus identification and segmentation,"<p>Segments the hippocampus into anterior and posterior regions</p>
","Division of Medical Image Computing, German Cancer Research Center (DKFZ)","['Image Segmentation', 'Anatomy', 'nii.gz', 'Biomedical Image Analysis and Interpretation']",62bcdc56dd9ecc514ae82877,,"[{'allowedFormats': {'title': '.nii.gz', 'value': 'application/gzip', 'fileExtensions': ['nii', 'gz']}, 'dataStructure': 'dataStructure', 'demoDataDetails': {'description': 'Heart MRI scans, with MRI modality', 'fileName': 'hippocampus_demo.nii.gz', 'filePath': 'apps/image_segmentation_hippocampus/resources/demo_data/hippocampus_demo.nii.gz', 'fileSource': [{'title': 'Data Source', 'url': 'http://medicaldecathlon.com/'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Select Images to Segment', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
AlphaFold2: 3D Protein Structure Prediction,AlphaFold predicts 3D models of protein structures and has the potential to accelerate research in every field of biology. and the authors are tagada group,"<p>Revolutionary 3D protein structure prediction model with high accuracy that allows for a close study of proteins without an expensive X-ray crystallography process<br><br><span style=""font-weight: bold"">Example use case: </span>Prediction of protein disorders, studying enzymes, and developing novel protein-based drugs<br><br><span style=""font-weight: bold"">Technology: </span>Novel neural network architectures and training procedures</p>",DeepMind,"['3D Protein Structure Prediction', 'Protein', 'fasta', 'Structural Bioinformatics']",62bf442025b09dead5853d24,"[{'input_type': 'user_input', 'name': 'protein_header', 'placeholder': 'protein_name', 'title': 'Protein Name', 'tooltip': 'Please provide a protein header name', 'type': 'text', 'validation': '.'}, {'input_type': 'user_input', 'name': 'sequence', 'placeholder': 'PIAQIHILEGRSDEQKETLIREVSE', 'title': 'Amino Acid Sequence', 'tooltip': 'Please provide a amino acid sequence', 'type': 'text', 'validation': '^[A-Z]+$'}, {'input_type': 'user_input', 'name': 'max_template_date', 'placeholder': 'YYYY-MM-DD', 'title': 'Max Template Date', 'tooltip': 'If you are predicting the structure of a protein that is already in PDB and you wish to avoid using it as a template, then\xa0max_template_date must be set to be before the release date of the structure. If you use example sample, use <2001-05-15> as date.', 'type': 'text', 'validation': '^\\d{4}\\-(0[1-9]|1[012])\\-(0[1-9]|[12][0-9]|3[01])$'}, {'default_value': {'label': 'reduced_dbs', 'value': 'reduced_dbs'}, 'disabled': True, 'hidden': False, 'input_type': 'dropdown', 'name': 'db_preset', 'options': [{'label': 'reduced_dbs', 'value': 'reduced_dbs'}, {'label': 'full_dbs', 'value': 'full_dbs'}], 'title': 'Database Preset', 'tooltip': 'To control MSA speed/quality tradeoff you can use db_preset flag. In beta version, only  âreduced_dbs flag selectable.'}, {'default_value': {'label': 'monomer', 'value': 'monomer'}, 'disabled': True, 'hidden': False, 'input_type': 'dropdown', 'name': 'model_preset', 'options': [{'label': 'monomer', 'value': 'monomer'}, {'label': 'monomer_casp14', 'value': 'monomer_casp14'}, {'label': 'monomer_ptm', 'value': 'monomer_ptm'}, {'label': 'multimer', 'value': 'multimer'}], 'title': 'Model Preset', 'tooltip': 'In beta version only monomer model preset available.\n\nmonomer: This is the original model used at CASP14 with no ensembling.\nmonomer_casp14 :This is the original model used at CASP14 with\xa0num_ensemble=8, matching our CASP14 configuration. This is largely provided for reproducibility as it is 8x more computationally expensive for limited accuracy gain (+0.1 average GDT gain on CASP14 domains).\nmonomer_ptm: This is the original CASP14 model fine tuned with the pTM head, providing a pairwise confidence measure. It is slightly less accurate than the normal monomer model.\nmultimer: This is the\xa0AlphaFold-Multimer\xa0model. To use this model, provide a multi-sequence FASTA file. In addition, the UniProt database should have been downloaded.\n'}]",
Molecule Toxicity Prediction: ChemBERTa with Clintox Dataset,Toxicity prediction for molecules in SMILES-format using ChemBERTa and the ClinTox dataset.,<p>Toxicity prediction for molecules in SMILES-format using ChemBERTa and the ClinTox dataset.</p>,"Seyone Chithrananda, Gabriel Grand, Bharath Ramsundar","['Drug Target Interaction Prediction', 'Classification', 'Drug Discovery', 'csv', 'Cheminformatics']",62c5237aea2929365d027ee5,,"[{'allowedFormats': {'title': '.csv', 'value': 'text/csv', 'fileExtensions': ['csv']}, 'dataStructure': 'dataStructure', 'demoDataDetails': {'description': 'Test data from the ClinTox dataset. Contains drugs approved by the FDA and drugs that have failed clinical trials for toxicity reasons.', 'fileName': 'clintox_test.csv', 'filePath': 'apps/chemberta_clintox/resources/demo_data/clintox_test.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://moleculenet.org/datasets-1'}]}, 'disabled': False, 'name': 'smiles_data', 'title': 'Molecular SMILES data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Pancreas Tumor Segmentation: Medical Image-nnUnet,Tumor identification and segmentation in pancreas based on the automated analysis of CT pancreas scans (3D volumes),"<p>Tumor identification and segmentation in pancreas based on the automated analysis of CT pancreas scans (3D volumes)</p>
","Division of Medical Image Computing, German Cancer Research Center (DKFZ)","['nii.gz', 'Biomedical Image Analysis and Interpretation']",62d06c17e35ad66addc86ad5,,"[{'allowedFormats': {'title': '.nii.gz', 'value': 'application/gzip', 'fileExtensions': ['gz']}, 'dataStructure': 'dataStructure', 'demoDataDetails': {'description': 'Prostate multiparametric MRI (mpMRI) studies comprising T2-weighted, Diffusion-weighted and T1-weighted contrast enhanced series.', 'fileName': 'pancreas_demo.nii.gz', 'filePath': 'apps/image_segmentation_pancreas/resources/demo_data/pancreas_demo.nii.gz', 'fileSource': [{'title': 'Data Source', 'url': 'http://medicaldecathlon.com/'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Select Images to Segment', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepPurpose-DTI: Deep Learning-based Drug Target Interaction Prediction Tool,DeepPurpose is a pytorch-based deep learning framework that is initiated to provide a simple but powerful toolkit for drug-target interaction (DTI) prediction and its related applications.,"<p>Measures the binding strength of drug molecules to the protein targets<br><br><strong>Example use case: </strong>fundamental for drug discovery supporting drug screening and repurposing<br><br><strong>Technology: </strong>Message passing neural network &amp; Convolutional neural network</p>
","Huang, Kexin and Fu, Tianfan and Glass, Lucas M and Zitnik, Marinka and Xiao, Cao and Sun, Jimeng","['3D Protein Structure Prediction', 'Drug Discovery', 'txt', 'tab', 'csv', 'Drug Discovery and Design']",62d66daef86d46f6cf1e80a0,"[{'default_value': {'label': 'Morgan_CNN_BindingDB', 'value': 'Morgan_CNN_BindingDB'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'model', 'options': [{'label': 'CNN_CNN_BindingDB_IC50', 'value': 'CNN_CNN_BindingDB_IC50'}, {'label': 'Morgan_CNN_BindingDB_IC50', 'value': 'Morgan_CNN_BindingDB_IC50'}, {'label': 'Morgan_AAC_BindingDB_IC50', 'value': 'Morgan_AAC_BindingDB_IC50'}, {'label': 'MPNN_CNN_BindingDB_IC50', 'value': 'MPNN_CNN_BindingDB_IC50'}, {'label': 'Daylight_AAC_BindingDB_IC50', 'value': 'Daylight_AAC_BindingDB_IC50'}, {'label': 'CNN_CNN_DAVIS', 'value': 'CNN_CNN_DAVIS'}, {'label': 'CNN_CNN_BindingDB', 'value': 'CNN_CNN_BindingDB'}, {'label': 'Morgan_CNN_BindingDB', 'value': 'Morgan_CNN_BindingDB'}, {'label': 'Morgan_CNN_KIBA', 'value': 'Morgan_CNN_KIBA'}, {'label': 'Morgan_CNN_DAVIS', 'value': 'Morgan_CNN_DAVIS'}, {'label': 'MPNN_CNN_BindingDB', 'value': 'MPNN_CNN_BindingDB'}, {'label': 'MPNN_CNN_KIBA', 'value': 'MPNN_CNN_KIBA'}, {'label': 'MPNN_CNN_DAVIS', 'value': 'MPNN_CNN_DAVIS'}, {'label': 'Transformer_CNN_BindingDB', 'value': 'Transformer_CNN_BindingDB'}, {'label': 'Daylight_AAC_DAVIS', 'value': 'Daylight_AAC_DAVIS'}, {'label': 'Daylight_AAC_KIBA', 'value': 'Daylight_AAC_KIBA'}, {'label': 'Daylight_AAC_BindingDB', 'value': 'Daylight_AAC_BindingDB'}, {'label': 'Morgan_AAC_BindingDB', 'value': 'Morgan_AAC_BindingDB'}, {'label': 'Morgan_AAC_KIBA', 'value': 'Morgan_AAC_KIBA'}, {'label': 'Morgan_AAC_DAVIS', 'value': 'Morgan_AAC_DAVIS'}], 'title': 'MODEL', 'tooltip': 'The list of avaiable pretrained models: Model name consists of first the drug encoding, then the target encoding and then the trained dataset.'}]","[{'allowedFormats': {'fileExtensions': ['txt'], 'title': '.txt  ', 'value': 'text/plain'}, 'dataStructure': ""File should contain protein name and it's sequence. Please define the protein name on the first line and the protein sequence on the second line.\nExample:\n>SARS-CoV 3CL Protease\nSGFKKLVSPSSAVEKCIVSVSYRGNNLNGL"", 'demoDataDetails': {'description': 'Demo target amino acid sequence of SARS_CoV_Protease_3CL.', 'fileName': 'demo_target.txt', 'filePath': 'apps/deeppurpose/resources/demo_target.txt', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/kexinhuang12345/DeepPurpose/blob/master/DeepPurpose/dataset.py'}]}, 'disabled': False, 'name': 'target_file_input', 'title': 'Upload Protein Target File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tab'], 'title': '.tab  ', 'value': ''}, 'dataStructure': ""File should contain three different columns in .tab format. Column headers are: \n1. 'Name': drug name,\n2. 'Pubchem CID': compound identifier number,\n3. 'SMILES': drug molecules in SMILES format\nExample:\nName\tPubchem CID\tSMILES\nAbacavir\t441300\tC1CC1NC2=C3C(="", 'demoDataDetails': {'description': 'Demo antiviral drugs information file from tool code.', 'fileName': 'antiviral_drugs.tab', 'filePath': 'apps/deeppurpose/resources/antiviral_drugs.tab', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/kexinhuang12345/DeepPurpose/blob/master/DeepPurpose/dataset.py'}]}, 'disabled': False, 'name': 'drug_file_input', 'title': 'Upload Repurposing Drugs File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': ""There should be two columns in the file:  'SMILES' and 'Target Sequence' respectively.\nExample:\nSMILES\tTarget Sequence\nCC(C)C(=O)Nc1ccc(\tMNPNQKILCTSATALVIGTIA"", 'demoDataDetails': {'description': 'Sample virtual screening information (IC50) file from tool code.', 'fileName': 'IC50_samples.csv', 'filePath': 'apps/deeppurpose/resources/IC50_samples.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://dataverse.harvard.edu/api/access/datafile/4159681'}]}, 'disabled': False, 'name': 'vs_file_input', 'title': 'Upload Virtual Screening File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Stardist2D: Cell detection and segmentation,Automatic detection and segmentation of cells and nuclei in microscopy using Stardistâs algorithms. Works well with fluorescent nuclei images.,"<p>Detection and segmentation of cells and nuclei in microscopy. Works well with fluorescent images.<br><br><strong>Example use case: </strong>image-based cellular research &amp; disease<br><br><strong>Technology: </strong>Convolutional neural network<br><br><strong>Limitations: </strong>Currently only accepts black &amp; white images</p>
","Uwe Schmidt, Martin Weigert, Coleman Broaddus, and Gene Myers","['Image Segmentation', 'Histology', 'zip', 'Biomedical Image Analysis and Interpretation']",62df09226c93b06e5c0739ad,"[{'default_value': {'label': 'Versatile', 'value': '2D_versatile_fluo'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'model', 'options': [{'label': 'Versatile', 'value': '2D_versatile_fluo'}, {'label': 'Original Model', 'value': '2D_paper_dsb2018'}], 'title': 'MODEL', 'tooltip': 'The Versatile model works well with most datasets. Choose Original Model to replicate results from the paper of the DSB2018 competion'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip  ', 'value': 'application/zip'}, 'dataStructure': 'A zipped file (.zip) of black-and-white images (no extra directories or files). The maximum size of the images should be 1500x1500 pixels. Images can be in .tif, .jpg, .jpeg, or .png formats.', 'demoDataDetails': {'description': 'Test data from the DBS 2018 nuclei segmentation challenge. ', 'fileName': 'dsb2018.zip', 'filePath': 'apps/stardist_2d/resources/demo_data/dsb2018.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/stardist/stardist/releases/download/0.1.0/dsb2018.zip'}, {'title': 'Description', 'url': 'https://bbbc.broadinstitute.org/BBBC038'}]}, 'disabled': False, 'name': 'images_zipped', 'title': 'Zipped Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Neural Forecast: Deep Learning for Time Series Forecasting,"NeuralForecast is a Python library for time series forecasting with deep learning models. It includes benchmark datasets, data-loading utilities, evaluation functions, statistical tests, univariate model benchmarks and SOTA models implemented in PyTorch and PyTorchLightning.","<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Nixtla's neuralforecast is a python library for time series forecasting with deep learning models. This app provides AutoRNN functionality, implemented using PyTorch, PyTorchLightning and Ray. This package automatically tests different settings, identifying over multiple iterations which parameters perform the best. The results for the champion model are then provided. If trained using CPU, then a maximum of 32 time series will be processed, while if trained using GPU a maximum of 128 will be processed instead. Models are trained using all series, meaning that with more series included, performance is likely to improve. Models can be saved, and then applied to similar time series, or trained further.</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""><br><br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Please provide data in three columns, in the following order:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc""><span style=""background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">unique_id for each time series (up to 16 time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series)</span></li>
<li style=""list-style-type: disc""><span style=""background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">date-time column can be in any format (date, time, number, other), but must be in ascending order.</span></li>
<li style=""list-style-type: disc""><span style=""background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">value. The value of the time series at each timeÂ </span></li></ul>",Nixtla,"['Data Analysis', 'General Use', 'csv', 'Forecasting']",62f28902cfd06816d3a6eb66,"[{'default_value': 1, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'seasonality', 'title': 'Seasonality', 'tooltip': 'Indicates whether seasonality or cycles are present in the data. For example, a seasonality of 24 for hourly data would indicate a daily cycle, or a seasonality of 7 for daily data would indicate a weekly cycle. The default value of 1 indicates no seasonality.', 'type': 'integer'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'horizon', 'title': 'Forecast Horizon', 'tooltip': 'How many time points into the future to forecast', 'type': 'integer'}, {'default_value': 'train', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'NA', 'type': 'object'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'txt', 'tsv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide data in three columns, in the following order:\nâ¢ unique_id for each time series (up to 32 time series can be provided if using CPU, or 128 if using GPU--if unique_id is not included it is assumed that the file contains only one time series).\nâ¢ date-time column can be in any format (date, time, number, other), but must be in ascending order.\nâ¢ value. The value of the time series at each time', 'demoDataDetails': {'description': 'description', 'fileName': 'M4-Hourly.csv', 'filePath': 'apps/nixtla_apps/resources/M4-Hourly.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}], 'previewFileName': 'apps/nixtla_apps/resources/M4-Hourly.csv'}, 'disabled': False, 'name': 'train_data', 'title': 'Training Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'txt', 'tsv'], 'title': '.csv, .tsv, .txt', 'value': 'text/csv/ tsv'}, 'dataStructure': 'Please provide data in three columns, in the following order:\nâ¢ unique_id for each time series (up to 32 time series can be provided if using CPU, or 128 if using GPU--if unique_id is not included it is assumed that the file contains only one time series).\nâ¢ date-time column can be in any format (date, time, number, other), but must be in ascending order.\nâ¢ value. The value of the time series at each time', 'demoDataDetails': {'description': 'description', 'fileName': 'M4-Hourly-test.csv', 'filePath': 'apps/nixtla_apps/resources/M4-Hourly-test.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}], 'previewFileName': 'apps/nixtla_apps/resources/M4-Hourly-test.csv'}, 'disabled': False, 'name': 'test_data', 'optional': True, 'title': 'Test Data (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Stats Forecast: ARIMA Modelling for Time Series Forecasting,"StatsForecast offers a collection of widely used univariate time series forecasting models, including automatic ARIMA and ETS modeling optimized for high performance using numba. It also includes a large battery of benchmarking models.","<p>StatsForecast offers a collection of widely used univariate time series forecasting models, including automatic ARIMA and ETS modeling optimized for high performance using numba. It also includes a large battery of benchmarking models.</p>",Nixtla,"['General Use', 'csv', 'Forecasting']",62f2b4bdcfd06816d3a6eb67,"[{'default_value': 1, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'seasonality', 'title': 'Seasonality', 'tooltip': 'Indicates whether seasonality or cycles are present in the data. For example, a seasonality of 24 for hourly data would indicate a daily cycle, or a seasonality of 7 for daily data would indicate a weekly cycle. The default value of 1 indicates no seasonality.', 'type': 'integer'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'horizon', 'title': 'Forecast Horizon', 'tooltip': 'How many time points into the future to forecast', 'type': 'integer'}, {'default_value': {'label': 'AutoARIMA', 'value': 'AutoARIMA'}, 'disabled': True, 'input_type': 'dropdown', 'name': 'model', 'options': [{'label': 'AutoARIMA', 'value': 'AutoARIMA'}], 'title': 'MODEL', 'tooltip': 'Type of model to train'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide data in three columns, in the following order:\nâ¢ unique_id for each time series (up to eight time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series).\nâ¢ date-time column can be in any format (date, time, number, other), but must be in ascending order.\nâ¢ value. The value of the time series at each time', 'demoDataDetails': {'description': 'description', 'fileName': 'M4-Hourly.csv', 'filePath': 'apps/nixtla_apps/resources/M4-Hourly.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}], 'previewFileName': 'apps/nixtla_apps/resources/M4-Hourly.csv'}, 'disabled': False, 'name': 'train_data', 'title': 'Training Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'tsv', 'txt'], 'title': '.csv, .tsv, .txt', 'value': 'text/csv/ tsv'}, 'dataStructure': 'Please provide data in three columns, in the following order:\nâ¢ unique_id for each time series (up to eight time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series).\nâ¢ date-time column can be in any format (date, time, number, other), but must be in ascending order.\nâ¢ value. The value of the time series at each time', 'demoDataDetails': {'description': 'description', 'fileName': 'M4-Hourly-test.csv', 'filePath': 'apps/nixtla_apps/resources/M4-Hourly-test.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}], 'previewFileName': 'apps/nixtla_apps/resources/M4-Hourly-test.csv'}, 'disabled': False, 'name': 'test_data', 'optional': True, 'title': 'Test Data (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ML Forecast: Machine Learning for Time Series Forecasting,"mlForecast allows users to apply scikit-learn models, such as random forests or gradient boosting to time series data. Distributed implementations of xgBoost and LightGBM are also available.","<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">mlForecast allows users to apply scikit-learn models, such as random forests or gradient boosting to time series data. This particular implementation uses the hyperopt python package, automatically training numerous sklearn random forest, XGBoost, and LightGBM models, identifying over multiple iterations which parameters perform the best. The results for the champion model are then provided. If trained using CPU, then a maximum of 32 time series will be processed, while if trained using GPU a maximum of 128 will be processed instead, and the maximum iterations used to identify the best models will be higher. Models are trained using all series, meaning that with more series included performance is likely to improve. The seasonality parameter can be altered to reflect known cycles in the data (for example, if hourly data that is expected to vary in a regular pattern over a 24 hour period, then a seasonality of 24 may be suitable).A seasonality of 1 implies that no seasonality is included in the mode</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif"">l.<br><br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Please provide data in three columns, in the following order:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">unique_id for each time series (up to 32 time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series).</span></li>
<li style=""list-style-type: disc""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">date-time column can be in any format (date, time, number, other), but must be in ascending order.</span></li>
<li style=""list-style-type: disc""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">value. The value of the time series at each time</span></li></ul>",Nixtla,"['Structure Prediction', 'General Use', 'csv', 'Forecasting']",62f361f9cfd06816d3a6eb72,"[{'default_value': 1, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'seasonality', 'title': 'Seasonality', 'tooltip': 'Indicates whether seasonality or cycles are present in the data. For example, a seasonality of 24 for hourly data would indicate a daily cycle, or a seasonality of 7 for daily data would indicate a weekly cycle. The default value of 1 indicates no seasonality.', 'type': 'integer'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'horizon', 'title': 'Forecast Horizon', 'tooltip': 'How many time points into the future to forecast', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['.csv', '.txt', '.tsv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide data in three columns, in the following order:\nâ¢ unique_id for each time series (up to 32 time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series).\nâ¢ date-time column can be in any format (date, time, number, other), but must be in ascending order.\nâ¢ value. The value of the time series at each time', 'demoDataDetails': {'description': 'description', 'fileName': 'M4-Hourly.csv', 'filePath': 'apps/nixtla_apps/resources/M4-Hourly.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}], 'previewFileName': 'apps/nixtla_apps/resources/M4-Hourly.csv'}, 'disabled': False, 'name': 'train_data', 'title': 'Training Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'txt', 'tsv'], 'title': '.csv, .txt, .tsv', 'value': 'text/csv/ tsv'}, 'dataStructure': 'Please provide data in three columns, in the following order:\nâ¢ unique_id for each time series (up to 32 time series can be provided in one file, and trained simultaneously--if unique_id is not included it is assumed that the file contains only one time series).\nâ¢ date-time column can be in any format (date, time, number, other), but must be in ascending order.\nâ¢ value. The value of the time series at each time', 'demoDataDetails': {'description': 'description', 'fileName': 'M4-Hourly-test.csv', 'filePath': 'apps/nixtla_apps/resources/M4-Hourly-test.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}], 'previewFileName': 'apps/nixtla_apps/resources/M4-Hourly-test.csv'}, 'disabled': False, 'name': 'test_data', 'optional': True, 'title': 'Test Data (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Deep Molecule Property Optimiser,"Deep Molecular Optimization aims to replicate a chemistâs intuition to produce molecules with desirable properties from a given starting molecule. Here, three ADMET properties are optimized simultaneously (logD, solubility, and clearance) from a given starting molecule in SMILES representation. This is achieved with graph-to-graph translation model HierG2G which has state-of-the-art performance in molecular optimization.","<p>Generates new molecules with desirable properties given a starting molecule, essentially replicating a chemist's intuition to optimize molecular properties, accelerating drug discovery<br><br><span style=""font-weight: bold"">Example use case: </span>molecular optimization for finding drug candidates<br><br><span style=""font-weight: bold"">Limitations: </span>works with 3 ADMET properties: logD, solubility and clearance<br><br><span style=""font-weight: bold"">Technology: </span>Message passing neural network<br><br><span style=""font-weight: bold"">Metrics: </span><span style=""text-decoration: underline; color: #0088FF""><a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7980633/table/Tab1/?report=objectonly"" target=""_blank"" rel=""noreferrer"">As reported by He et al.</a></span>&nbsp;</p>",AstraZeneca - MAI,"['Generation', 'NLP', 'Drug', 'Drug Discovery', 'csv', 'Cheminformatics']",630e761f005a3551c588e5d9,"[{'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'num_samples', 'title': 'Number of molecules to generate', 'tooltip': 'How many molecules do you want to generate for each of your provided molecules', 'type': 'integer'}, {'default_value': False, 'input_type': 'checkbox', 'name': 'generate_ims', 'title': 'Draw generated molecules', 'optional': True, 'tooltip': 'Select this if you want to have images of the generated molecules included in your results'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Your input data should be .csv or .txt and comma-separated. And, your input data must have the following column headings:\n1. ""Source_Mol"" (Your source molecule in SMILES format),\n2. ""Source_Mol_LogD"" (Your source moleculeâs logD e.g. 2.52340477180304),\n3. ""Target_Mol_LogD"" (The LogD you want your molecule to have),\n4. ""Source_Mol_Solubility"" (Your source moleculeâs solubility e.g. 1.86827115391515),\n5. ""Target_Mol_Solubility"" (The solubility you want your molecule to have),\n6. ""Source_Mol_Clint"" (Your source moleculeâs clearance e.g. 2.075152704),\n7. ""Target_Mol_Clint"" (The clearance you want your molecule to have). ', 'demoDataDetails': {'description': 'A subset of 20 molecules from the data provided in âmmp_prop.csvâ from the codeâs source repository.', 'fileName': 'input_molecules.csv', 'filePath': 'apps/deep_molecular_optimisation/resources/input_molecules.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/deep-molecular-optimization/blob/main/data/chembl_02/mmp_prop.csv'}], 'previewFileName': 'apps/deep_molecular_optimisation/resources/input_molecules.csv'}, 'disabled': False, 'name': 'input_file', 'requireValidation': True, 'supportsPreview': True, 'title': 'Upload Source Molecules', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}], 'validationRules': {'columns': {'columnsList': [{'allowedTypes': ['str'], 'name': 'Source_Mol'}, {'allowedTypes': ['float'], 'name': 'Source_Mol_LogD'}, {'allowedTypes': ['float'], 'name': 'Target_Mol_LogD'}, {'allowedTypes': ['float'], 'name': 'Source_Mol_Solubility'}, {'allowedTypes': ['float'], 'name': 'Target_Mol_Solubility'}, {'allowedTypes': ['float'], 'name': 'Source_Mol_Clint'}, {'allowedTypes': ['float'], 'name': 'Target_Mol_Clint'}]}}}]"
GenNet: Interpretable Neural Network Framework for Genetics,"Framework for Interpretable Neural Networks for Genetics.
","<p><span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 19.2;font-family: Poppins, sans-serif;"">You can use GenNet to create neural networks specifically for genetics. GenNet gives you the ability to decide what knowledge should be connected to what.</span>&nbsp;</p>
","van Hilten, A., Kushner, S.A., Kayser, M.Â et al.","['bim', 'bed', 'fam', 'Genomics']",630f70889d02186b18f3af18,"[{'default_value': 50, 'increment': 1, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epoch', 'tooltip': 'Epoch means one complete pass of the training dataset through the algorithm.', 'type': 'integer'}, {'default_value': 0.001, 'increment': 0.0001, 'input_type': 'slider', 'max_value': 0.01, 'max_value_included': True, 'min_value': 0.0001, 'min_value_inclusive': True, 'name': 'learning_rate', 'title': 'Learning Rate', 'tooltip': 'Learning rate parameter controls the weights of neural network with respect to the loss gradient.', 'type': 'float'}, {'default_value': 0.01, 'increment': 0.01, 'input_type': 'slider', 'max_value': 0.99, 'max_value_included': True, 'min_value': 0.01, 'min_value_inclusive': True, 'name': 'L1_value', 'title': 'L1 Value', 'tooltip': 'L1 regularization is a method that penalizes the weight of individual parameters in the model.', 'type': 'float'}, {'default_value': 50, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'patience', 'title': 'Patience Value', 'tooltip': 'The patience value specify that how many epochs it should continue after the loss stopped from decreasing', 'type': 'integer'}, {'default_value': {'label': 'GRCh37', 'value': 'GRCh37'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'assmbly_vep_version', 'options': [{'label': 'GRCh38', 'value': 'GRCh38'}, {'label': 'GRCh37', 'value': 'GRCh37'}], 'title': 'Assembly Version', 'tooltip': 'Please specify the assembly version of Homo Sapiens genome that is used in experiment'}]","[{'allowedFormats': {'title': '.bim', 'value': '', 'fileExtensions': ['bim']}, 'dataStructure': 'Extended variant information file. A text file with no header line, and one line per variant with the following six fields:\nChromosome code\nVariant identifier\nBase-pair coordinate\nAllele 1\nAllele 2\nExample:\n16\t16:60686_C_A\t60686\t60686\tC\tA\n<strong>Reference:</strong>\nhttps://www.cog-genomics.org/plink/1.9/formats', 'demoDataDetails': {'description': 'Demo .bim file from GenNet GitHub repository page.', 'fileName': 'GenNet_simulation.bim', 'filePath': 'apps/gennet/resources/GenNet_simulation.bim', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/ArnovanHilten/GenNet/tree/master/examples/A_to_Z/plink'}]}, 'disabled': False, 'name': 'bim_file', 'title': 'Upload .bim file', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'title': '.bed', 'value': '', 'fileExtensions': ['bed']}, 'dataStructure': ""(PLINK binary biallelic genotype table). Primary representation of genotype calls at biallelic variants. Must be accompanied by .bim and .fam files. Do not confuse this with the UCSC Genome Browser's BED format, which is totally different.\n<strong>Reference:</strong>\nhttps://www.cog-genomics.org/plink/1.9/formats"", 'demoDataDetails': {'description': 'Demo .bed file from GenNet GitHub repository page.', 'fileName': 'GenNet_simulation.bed', 'filePath': 'apps/gennet/resources/GenNet_simulation.bed', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/ArnovanHilten/GenNet/tree/master/examples/A_to_Z/plink'}]}, 'disabled': False, 'name': 'bed_file', 'title': 'Upload .bed file', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'title': '.fam', 'value': '', 'fileExtensions': ['fam']}, 'dataStructure': ""(PLINK sample information file).Sample information file accompanying a .bed binary genotype table.A text file with no header line, and one line per sample with the following six fields:\nFamily ID\nWithin-family ID ('IID'; cannot be '0')\nWithin-family ID of father ('0' if father isn't in dataset)\nWithin-family ID of mother ('0' if mother isn't in dataset)\nSex code ('1' = male, '2' = female, '0' = unknown)\nPhenotype value ('1' = control, '2' = case, '-9'/'0'/non-numeric = missing data if case/control)\nExample:\nfamily_1\tsample_1\t0\t0\t0\t1\n<strong>Reference:</strong>\nhttps://www.cog-genomics.org/plink/1.9/formats"", 'demoDataDetails': {'description': 'Demo .fam file from GenNet GitHub repository page.', 'fileName': 'GenNet_simulation.fam', 'filePath': 'apps/gennet/resources/GenNet_simulation.fam', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/ArnovanHilten/GenNet/tree/master/examples/A_to_Z/plink'}]}, 'disabled': False, 'name': 'fam_file', 'title': 'Upload .fam file', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Enformer: Gene Expression Prediction tool from DNA Sequence (Variant Scoring),Enformer is a gene expression prediction tool from DNA sequence through the use of a deep learning architecture.,"<p>There is a significant unsolved problem about how non-coding DNA regulates gene expression in many cell types, and important downstream applications in human genetics rely on improved solutions. Enformer is a deep learning architecture that can incorporate data from long-distance interactions (up to 100 kb apart) in the genome. Predicting the impact of genetic variations on cell-type-specific gene expression is a key objective of this app.</p>
<p><span style=""font-weight: bold"">Example use case: </span>Variant effect prediction</p>
<p><span style=""font-weight: bold"">Technology: </span>Neural Network, Transformers</p>
<p><span style=""font-weight: bold"">Limitation: </span>Pretrained models created based on human and mouse genomes only.</p>
<p><span style=""font-weight: bold"">Metrics: </span>Some metrics related to research can be foundÂ <span style=""text-decoration: underline; color: #0088FF""><a href=""https://www.nature.com/articles/s41592-021-01252-x#Sec8"" target=""_blank"" rel=""noreferrer"">here</a></span>.</p>
<p><span style=""font-weight: bold; font-style: italic; text-decoration: underline"">Note:</span><span style=""font-weight: bold; font-style: italic""> ""Select Targets"" </span>section below is optional!</p>",DeepMind,['Transcriptomics'],62f0df20c9e6995b5152666e,,"[{'allowedFormats': {'fileExtensions': ['vcf.gz, vcf'], 'title': '.vcf.gz/.vcf', 'value': ''}, 'dataStructure': 'VCF stands for Variant Call Format. It is a text file format that is used to represent SNP, indel, and structural variation calls. If REF or ALT columns contain <.> in the VCF file, program will automatically skip these variant lines.', 'demoDataDetails': {'description': 'Demo data is used for representation as in the original notebook.', 'fileName': 'clinvar.vcf.gz', 'filePath': 'apps/enformer/resources/clinvar.vcf.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/deepmind/deepmind-research/blob/master/enformer/enformer-usage.ipynb'}]}, 'disabled': False, 'name': 'vcf_file', 'title': 'Upload VCF File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepCRISPR: Off Target sgRNA Cleavage Profile Prediction,"DeepCRISPR, is an efficient and extendable computational model for prediction of CRISPR sgRNA off-target profile which would facilitate the optimized design of sgRNAs with high
sensitivity and specificity. DeepCRISPR was trained on two different cell types: 293-related cell lines (18 sgRNAs) and K562 t (12sgRNAs)","<p>An efficient and extendable computational model for prediction of CRISPR sgRNA off-target profile, facilitating optimized sgRNA design with high sensitivity and specificity<br><br><strong>Example use case: </strong>Epigenetics research<br><br><strong>Limitations: </strong>Different off-target assays may have different sensitivities<br><br><strong>Technology: </strong>Convolutional neural network-based deep learning network, trained on two different cell types: 293-related cell lines (18 sgRNAs) and K562 t (12 sgRNAs)<br><br><strong>Metrics: </strong><a href=""https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1459-4/figures/3"" target=""_blank"">As reported by Chuai et al.</a>&nbsp;</p>
","Guohui Chuai, Qi Liu et al.","['Classification', 'Regression', 'CRISPR', 'Synthetic Biology']",63221a9e6a20e3ac924a7b80,"[{'default_value': {'label': 'Both', 'value': 'Both'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'model', 'options': [{'label': 'Both', 'value': 'Both'}, {'label': 'Regression', 'value': 'Regression'}, {'label': 'Classification', 'value': 'Classification'}], 'title': 'Prediction Method', 'tooltip': 'Selecting regression will return a value between 0 and 1 for each efficacy prediction. Selecting classification will return either 1 or 0 for each efficacy prediction. Selecting both will return both classification and regression predictions.'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Your data requires the following column headings: \n\n1. target_seq\n2. target_ctcf\n3. target_dnase\n4. target_h3k4me3\n5. target_rrbs\n6. off_target_seq\n7. off_target_ctcf\n8. off_target_dnase\n9. off_target_h3k4me3\n10. off_target_rrbs\nEpigenetic features are represented by sequences of As and Ns where A represents 1 meaning a signal located and N represents 0 meaning no signal. For example:\n+------------+------+------+\n | target_seq    | ctcf      | rrbs     |\n+------------+------+------+\n | CTTâ¦                | AAAâ¦   | NNNâ¦   |\n+------------+------+------+', 'demoDataDetails': {'description': 'Example data containing a list of sgRNAs with epigenetic features taken from the source codeâs github. However, we have removed the label column from the original and added appropriate column headings for clarity.', 'fileName': 'eg_reg_off_target.csv', 'filePath': 'apps/deepcrispr_offtarget/eg_reg_off_target.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/bm2-lab/DeepCRISPR/tree/master/examples'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Upload Source Molecules', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepCRISPR: On Target sgRNA Knockout Efficacy Prediction,"DeepCRISPR, is an efficient and extendable computational model for prediction of CRISPR sgRNA on-target knockout efficacy which would facilitate the optimized design of sgRNAs with high
sensitivity and specificity","<p>An efficient and extendable computational model for prediction of CRISPR sgRNA on-target knockout efficacy, facilitating optimized sgRNA with high sensitivity and specificity<br><br><strong>Example use case: </strong>Epigenetics research<br><br><strong>Limitations: </strong>Focuses on conventional NGG-based sgRNA design for SpCas9 in humans<br><br><strong>Technology: </strong><a href=""https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1459-4/figures/1"" target=""_blank"">Convolutional neural network-based deep learning network</a>, trained on ~15,000 sgRNAs containing 1071 genes from <br>four different cell lines (hct116, hek293t, hela, and hl60) with redundancy removed and can generalise well in new cell types for <br>sgRNA on-target knockout efficacy prediction<br><br><strong>Metrics: </strong><a href=""https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1459-4/figures/2"" target=""_blank"">As reported by Chuai et al. </a>&nbsp;</p>
","Guohui Chuai, Qi Liu et al.","['Classification', 'Regression', 'CRISPR', 'Synthetic Biology']",63225c416a20e3ac924a7b90,"[{'default_value': {'label': 'Both', 'value': 'Both'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'model', 'options': [{'label': 'Both', 'value': 'Both'}, {'label': 'Regression', 'value': 'Regression'}, {'label': 'Classification', 'value': 'Classification'}], 'title': 'Prediction Method', 'tooltip': 'Selecting regression will return a value between 0 and 1 for each efficacy prediction. Selecting classification will return either 1 or 0 for each efficacy prediction. Selecting both will return both classification and regression predictions.'}]","[{'allowedFormats': {'title': '.csv', 'value': 'text/csv', 'fileExtensions': ['csv']}, 'dataStructure': 'This app allows for sequence-only prediction or full-featured prediction. Data for full featured prediction contains epigenetic features and is structured as follows where A represents 1 meaning a signal located and N represents 0 meaning no signal:\n\n+------------+------+-------+---------+------+\n | target_seq    | ctcf      | dnase   | h3k4me3  | rrbs     |\n+------------+------+-------+---------+------+\n | CTTâ¦                | AAAâ¦   | AAAâ¦     | AAAâ¦         | NNNâ¦   |\n+------------+------+-------+---------+------+\nYou must have the exact column headings as above for the app to work. However, they can be in any order.\n\nData for sequence only predictions only requires the âtarget_seqâ column. Note, sequence-only prediction is only available for regression.', 'demoDataDetails': {'description': 'Example data containing a list of sgRNAs with epigenetic features taken from the source codeâs github. However, we have removed the label column from the original and added appropriate column headings for clarity.', 'fileName': 'eg_reg_on_target.csv', 'filePath': 'apps/deepcrispr_ontarget/resources/eg_reg_on_target.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/bm2-lab/DeepCRISPR/tree/master/examples'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Upload Source Molecules', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Single Cell RNA-Seq Differential Expression,Deep generative modeling for single-cell transcriptomics,"<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Trains an scVI variational auto encoder to identify differential expression in genes between observations. Data should be in .h5ad, .h5, or .csv format. Uses the Anndata python package, which natively supports .h5ad meaning that file format is most suitable.</span></p>
<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif; font-weight: bold"">Example use case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Differential expression analysis is one of the primary downstream analyses of single cell RNA-seq data to identify gene markers for cell type detection and also provide inputs to other secondary analyses.Â </span></p>",scVI-Tools,"['DGE Analysis', 'Single-Cell Bioinformatics']",632483dc4994b305333ba772,"[{'default_value': 1500, 'increment': 100, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1000, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 'diff_exp', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'object'}, {'default_value': 'diff_exp', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 400, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Number of epochs used to train deep cluster model', 'type': 'integer'}, {'default_value': {'label': 'cell_type', 'value': 'cell_type'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'group_by', 'options': [], 'title': 'Group by for differential expression', 'tooltip': 'Choose variable to group by for differential expression. If not set then differential expression will not be performed.'}, {'default_value': {'label': 'cell_source', 'value': 'cell_source'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'options': [], 'title': 'Batch effect correction', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv (multiple files)', 'value': ''}, 'dataStructure': 'Data should be in .h5ad format. Columns for covariate comparisons should be included in the dataset.', 'demoDataDetails': {'description': 'Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations. Dataset was filtered down randomly to 20k cells.', 'fileName': 'heart_atlas.h5ad', 'filePath': 'apps/scvi_tools/resources/heart_atlas.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.heartcellatlas.org/#DataSources'}], 'previewFileName': 'apps/scvi_tools/resources/heart_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemProp: Solubility Prediction of Small Molecules,"App uses ChemProp machine learning library to calculate solubilities of a list of SMILES strings. The output is a .CSV file with the predicted log(S) solubility values.

The app was trained on the AqSolDB database of aqueous solubility.","<p>Solubility model trained on AqSolDB using ChemProp<br><br><strong>Example use case: </strong>Filtering out drug candidates based on solubility<br><br><strong>Limitations: </strong>Applicable for organic molecules only, as the training dataset consisted only of organic molecules<br><br><strong>Technology: </strong>Message passing neural networks<br><br><strong>Metrics: </strong>On test data; Mean average error = 0.66; RMSE = 0.99; R<sup>2</sup>= 0.82</p>
",ChemProp,"['Drug Discovery', 'csv', 'Cheminformatics']",63358e696b12ad0623bb6abb,,"[{'allowedFormats': {'title': '.csv', 'value': 'text/csv', 'fileExtensions': ['csv']}, 'dataStructure': ""File should contain only one column with header('smiles'), rows represents small molecules in SMILES format."", 'demoDataDetails': {'description': 'Demo SMILES in .CSV format from AqSolDB paper. File consists of only one column, rows represents small molecules in SMILES format.', 'fileName': 'input_smiles.csv', 'filePath': 'apps/solubility_prediction/resources/input_smiles.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OVHAW8'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Upload SMILES File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemProp: Molecular Property Prediction Training App,"This app provides an interface for training models on ChemProp. The user inputs are the .CSV file that contains SMILES and molecular property columns, a .CSV with only SMILES column on which to predict the molecular property.","<p>Classification model training for molecular property prediction by analyzing learned molecular representations<br><br><strong>Example use case: </strong>drug toxicity prediction during lead generation<br><br><strong>Technology: </strong>Message passing neural networks</p>
",ChemProp,"['Classification', 'Drug Discovery', 'csv', 'Cheminformatics']",6335e2096b12ad0623bb6ae1,"[{'default_value': 0.2, 'increment': 1, 'input_type': 'slider', 'max_value': 0.9, 'max_value_included': True, 'min_value': 0.1, 'min_value_inclusive': True, 'name': 'test_size', 'title': 'Test Ratio', 'tooltip': 'Test ratio of the dataset. By default, 20% of the dataset will split for the test dataset', 'type': 'float'}, {'default_value': {'label': 'rdkit_2d_normalized', 'value': 'rdkit_2d_normalized'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'featurizer', 'options': [{'label': 'None', 'value': 'None'}, {'label': 'rdkit_2d_normalized', 'value': 'rdkit_2d_normalized'}], 'title': 'Featurizer', 'tooltip': 'Generates pre-normalised molecular features using RDKit'}, {'default_value': {'label': 'Classification', 'value': 'classification'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'type', 'options': [{'label': 'Regression', 'value': 'regression'}, {'label': 'Classification', 'value': 'classification'}], 'title': 'Type of the Model', 'tooltip': 'Please specify the type of the model to be built in your experiment'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epoch', 'tooltip': 'Epoch means one complete pass of the training dataset through the algorithm. Please specify epoch number for your experiment.', 'type': 'integer'}, {'default_value': 1, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'folds', 'title': 'Cross Validation Folds', 'tooltip': 'Please specify a number that splits your dataset K number of groups.', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': ""File must contain 'SMILES' and 'Molecular Property' columns respectively. Rows in first column represents molecules in SMILES format and rows in second column represent property: 0 (False) or 1 (True)."", 'demoDataDetails': {'description': 'Demo training file in .CSV format from ChemProp repository with toxicity property.', 'fileName': 'dataset_train.csv', 'filePath': 'apps/chemprop_training/resources/input.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/code/mmelahi/physiology-clintox/notebook'}]}, 'disabled': False, 'name': 'train_file', 'title': 'Upload a training dataset file', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': ""File should contain only 'SMILES' column. Rows represents molecules in SMILES format that will be used in prediction phase."", 'demoDataDetails': {'description': 'Demo prediction file in .CSV format includes molecules in SMILES format from various sources.', 'fileName': 'pred.csv', 'filePath': 'apps/chemprop_training/resources/pred.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/chemprop/chemprop'}]}, 'disabled': False, 'name': 'pred_file', 'title': 'Upload a File for Prediction', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
C. Elegans Cell Annotation: Single Cell Inference & Retraining,scANVI model trained on C. Elegans dataset,<p>scANVI model trained on C. Elegans dataset from: âA lineage-resolved molecular atlas of C. elegans embryogenesis at single-cell resolutionâ. Transcriptomes covering 89701 cells and 20222 genes</p>,scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",633c3df9eaafa791a6c10dfd,"[{'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task_flag', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Retrain', 'value': 'retraining'}], 'title': 'Infer Only or Retrain Model', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': '63388ad43502af80d4c8fe5e', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 100, 'disabled': True, 'increment': 10, 'input_type': 'slider', 'max_value': 400, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Max Epochs', 'tooltip': 'Maximum Epochs for Retraining', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Input data should be in .h5ad format. Gene names, along with the name of the target feature, should be same as those used in training dataset.', 'demoDataDetails': {'description': 'C. Elegans transcriptomes covering 89701 cells and 20222 genes.', 'fileName': 'elegans.h5ad', 'filePath': 'apps/scvi_tools/resources/elegans.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/Munfred'}], 'previewFileName': 'apps/scvi_tools/resources/elegans_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
PBMC Annotation: Single Cell Inference & Retraining,scANVI model trained on Purified PBMC dataset,<p>scANVI model trained on Purified PBMC dataset from: âMassively parallel digital transcriptional profiling of single cellsâ. Transcriptomes covering 68k peripheral blood mononuclear cells.</p>,scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",633c3ecaeaafa791a6c10dff,"[{'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task_flag', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Retrain', 'value': 'retraining'}], 'title': 'Infer Only or Retrain Model', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': '633adc6bb4406eaddfb36c7f', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 100, 'disabled': True, 'increment': 10, 'input_type': 'slider', 'max_value': 400, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Max Epochs', 'tooltip': 'Maximum Epochs for Retraining', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Input data should be in .h5ad format. Gene names, along with the name of the target feature, should be same as those used in training dataset.', 'demoDataDetails': {'description': 'scANVI model trained on Purified PBMC dataset from: âMassively parallel digital transcriptional profiling of single cellsâ.', 'fileName': 'pbmc_seurat_v4.h5ad', 'filePath': 'apps/scvi_tools/resources/pbmc_seurat_v4_sample.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/10XGenomics/single-cell-3prime-paper'}], 'previewFileName': 'apps/scvi_tools/resources/pbmc_seurat_v4_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Mouse Spleen & Lymph Cell Annotation: Single Cell Inference & Retraining,scANVI model trained on Mouse Spleen and Lymph Nodes Cite Seq dataset,<p>scANVI model trained on Mouse Spleen and Lymph Nodes Cite Seq dataset from: âJoint probabilistic modeling of single-cell multi-omic data with totalVIâ. Immune cells from murine spleen and lymph nodes</p>,scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",633c3f59eaafa791a6c10e00,"[{'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task_flag', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Retrain', 'value': 'retraining'}], 'title': 'Infer Only or Retrain Model', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': '63388a953502af80d4c8fe5c', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 100, 'disabled': True, 'increment': 10, 'input_type': 'slider', 'max_value': 400, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Max Epochs', 'tooltip': 'Maximum Epochs for Retraining', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Input data should be in .h5ad format. Gene names, along with the name of the target feature, should be same as those used in training dataset.', 'demoDataDetails': {'description': 'scANVI model trained on Mouse Spleen and Lymph Nodes Cite Seq dataset from: âJoint probabilistic modeling of single-cell multi-omic data with totalVIâ.', 'fileName': 'spleen_lymph_cite_seq.h5ad', 'filePath': 'apps/scvi_tools/resources/spleen_lymph_cite_seq.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/YosefLab/totalVI_reproducibility'}], 'previewFileName': 'apps/scvi_tools/resources/spleen_lymph_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Drug Repurposing Knowledge Graph,"DRKG is a biological knowledge graph relating genes, compounds, diseases, side effects and more.","Drug Repurposing Knowledge Graph (DRKG) is a comprehensive biological knowledge graph relating genes, compounds, diseases, biological processes, side effects and symptoms. DRKG includes information from six existing databases including DrugBank, Hetionet, GNBR, String, IntAct and DGIdb, and more. It includes 97,238 entities belonging to 13 entity-types; and 5,874,261 triplets belonging to 107 edge-types. These 107 edge-types show a type of interaction between one of the 17 entity-type pairs (multiple types of interactions are possible between the same entity-pair). See information on how to use DRKG here: https://bit.ly/3CcQCB5","Vassilis N. Ioannidis, Xiang Song, Saurav Manchanda, George Karypis, et al.","['Graph', 'Drug Discovery', 'Drug', 'csv', 'Drug Discovery and Design']",633d7ed6f58e323c39c95df4,,"[{'allowedFormats': {'title': '.csv', 'value': '', 'fileExtensions': ['csv']}, 'dataStructure': 'For more information on how to use DRKG: https://bit.ly/3CcQCB5', 'demoDataDetails': {'description': 'The same head input data as in âCOVID-19_drug_repurposing_via_genes.ipynbâ from the source repository. The file contains a list of candidate drugs.', 'fileName': 'input_heads.csv', 'filePath': 'apps/drkg/resources/input_heads.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/gnn4dr/DRKG'}]}, 'disabled': False, 'name': 'heads', 'title': 'Upload Head Entities', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'title': '.csv', 'value': '', 'fileExtensions': ['csv']}, 'dataStructure': 'For more information on how to use DRKG: https://bit.ly/3CcQCB5', 'demoDataDetails': {'description': 'The same tail input data as in âCOVID-19_drug_repurposing_via_genes.ipynbâ from the source repository. The file contains a list of genes.', 'fileName': 'input_tails.csv', 'filePath': 'apps/drkg/resources/input_tails.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/gnn4dr/DRKG'}]}, 'disabled': False, 'name': 'tails', 'title': 'Upload Tail Entities', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'title': '.csv', 'value': '', 'fileExtensions': ['csv']}, 'dataStructure': 'For more information on how to use DRKG: https://bit.ly/3CcQCB5', 'demoDataDetails': {'description': 'The same tail input data as in âCOVID-19_drug_repurposing_via_genes.ipynbâ from the source repository. The file contains the following relations: DRUGBANK::target::Compound:Gene, GNBR::N::Compound:Gene', 'fileName': 'input_relations.csv', 'filePath': 'apps/drkg/resources/input_relations.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/gnn4dr/DRKG'}]}, 'disabled': False, 'name': 'relations', 'title': 'Upload Relations', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: DRD2 Use Case,This app explores new compounds for the DRD2 receptor by using reinforcement learning.,"<p>Reinvent library consists of jupyter notebooks related to in silico drug discovery applications including data preparation and training steps. The aim of this app is to show the use case for finding new molecules for the DRD2 receptor with Reinforcement Learning. Inputs are two .csv files that SMILES strings should be provided. Please see the data structure below for more information. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br> <br><strong>Example Use Case: </strong>Finding new molecules for DRD2 receptor<br><br><strong>Limitation: </strong>Some of the parameters are kept default like in the demo notebook.<br><br><strong>Technology:</strong> Reinforcement Learning<br><br><strong>Metrics: </strong>Some of the metrics shown in the <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Complete_Use-Case-DRD2_Demo.ipynb"" target=""_blank"">demo notebook</a>&nbsp;</p>
",AstraZeneca,"['De novo Drug Design', 'Reinforcement Learning', 'Drug Discovery', 'csv', 'Drug Discovery and Design']",634419f6af675a84bede652b,"[{'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epoch', 'tooltip': 'Epoch means one complete pass of the training dataset through the algorithm. In the notebook default value is 300 and here is 100. Please specify epoch number for your experiment.', 'type': 'integer'}, {'default_value': 0.0001, 'increment': 0.0001, 'input_type': 'slider', 'max_value': 0.1, 'max_value_included': True, 'min_value': 0.0001, 'min_value_inclusive': True, 'name': 'learning_rate', 'title': 'Learning Rate', 'tooltip': 'Sets how strongly agent is influenced by each epoch. Default value is 0.0001', 'type': 'float', 'decimalPlace': 4}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMILES in CSV format. SMILES should be in the first column without a header. The purpose of providing these SMILES in the RL process is to follow in the footsteps of well-scored small molecules previously identified.', 'demoDataDetails': {'description': 'Start point ideas to consider for target. If these molecules score well, during the job they might be picked the trail and generate molecules around those initial ideas scoring ever more highly.SMILES in .CSV format derived from the DRD2 use-case notebook in the ReinventCommunity repository.', 'fileName': 'inception_smiles.csv', 'filePath': 'apps/reinvent_drd2_case/resources/inception_smiles.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Complete_Use-Case-DRD2_Demo.ipynb'}]}, 'disabled': False, 'name': 'inception_smiles_file', 'title': 'Upload Inception SMILES File ', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMARTS in CSV format. SMARTS should be in the first column without a header. They can be used to enforce the match to a given substructure. It penalizes the total score if desired substructures are not seen in the generated compound. It produces a score of either 1 or 0.5 in the result depending on whether the desired scaffold is present or not.', 'demoDataDetails': {'description': 'Sometimes compounds associated with toxicity or unstable chemistry.In order to avoid in research, we define some chemical moeities. SMARTS are in .CSV format derived from the DRD2 use-case notebook in the ReinventCommunity repository. If you want to upload your own data.', 'fileName': 'avoid_smiles.csv', 'filePath': 'apps/reinvent_drd2_case/resources/avoid_smiles.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Complete_Use-Case-DRD2_Demo.ipynb'}]}, 'disabled': False, 'name': 'avoid_smiles_file', 'title': 'Upload Matching Substructure SMARTS', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
UNet2D Segmentation Training Pipeline,This pipeline will train a UNet2D segmentation model that produces image masks that to represent the segmentations.,"<p>This pipeline will train a UNet2D segmentation model that produces image masks that to represent the segmentations. The pipeline can augment the training dataset to increase model performance if you wish. To train a model you will need a set of source images and a set of target segmentation images. The target segmentation images will be binary images that are segmentation masks of the source images, each source image must have an associated target image.  <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case:</strong> Highlight blood vessels in a retinal image.<br><br><strong>Technology: </strong>UNet2D is an encoder-decoder network architecture.<br><br><strong>Limitations: </strong>The maximum image input size UNet2D can take is 512x512, your images will be converted to patches if they are bigger than 512x512. Currently only greyscale images are supported.</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Image Segmentation', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",635a96ac91fc6571422e9757,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 500, 'min_value': 100, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': 'The training data are the images that train UNet2D, 10% of these will be used for validation over training. This zip folder must be named ""train"" before zipping and contain 2 sub-folders named \'source\' and \'target\'. \'source\' will contain your regular images. \'target\' will contain your binary image segmentation masks of the source images. Each source image must have an associated target image with the same file name. We recommend naming each file with a number e.g. 0.tiff, 1.tiff, 2.tiff. We recommend using .tiff files but other file formats may work.', 'demoDataDetails': {'description': ""Greyscale microscopy images of cells and images of each image's segmentation mask"", 'fileName': 'train.zip', 'filePath': 'apps/unet2dtraining/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/zhixuhao/unet'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The test data are the images that will test your trained UNet2D. This zip folder must be named 'test' before being zipped and contain 2 sub-folders named 'source' and 'target'. 'source' will contain your regular images. 'target' will contain your binary image segmentation masks of the source images. Each source image must have an associated target image with the same file name. We recommend naming each file with a number e.g. 0.tiff, 1.tiff, 2.tiff. We recommend using .tiff files but other file formats may work."", 'demoDataDetails': {'description': ""Greyscale microscopy images of cells and images of each image's segmentation mask"", 'fileName': 'test.zip', 'filePath': 'apps/unet2dtraining/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/zhixuhao/unet'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Unet2D Multilabel Segmentation Training Pipeline,This pipeline will train a UNet2D multilabel segmentation model that produces image masks that represent the segmentations.,"<p>This pipeline will train a UNet2D multilabel segmentation model that produces image masks that represent the segmentations. The pipeline can augment the training dataset to increase model performance if you wish. To train a model you will need a set of source images and a set of target segmentation images. The target segmentation images will be that are segmentation masks of the source images where each pixel value is a label, each source image must have an associated target image.  <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case: </strong>Highlight various parts of cells<br><br><strong>Technology: </strong>U-Net Encoder-decoder<br><br><strong>Limitations:</strong> The maximum image input size UNet2D can take is 512x512, your images will be converted to patches if they are bigger than 512x512. Currently only greyscale images are supported&nbsp;</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Image Segmentation', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",636121909c2c44f0b26d4729,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'decimalPlace': 0, 'default_value': 3, 'increment': 1, 'input_type': 'slider', 'max_value': 30, 'min_value': 1, 'name': 'labels_no', 'title': 'Number of Labels', 'tooltip': 'The number of labels in your segmentation masks'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 300, 'min_value': 50, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that train the UNet2D multilabel segmentation network, 10% of these will be used for validation over training. This zip folder must be named 'train' before it is zipped and contain 2 sub-folders named 'source' and 'target'. 'source' will contain your regular images. 'target' will contain your segmented masks of the source images. Each source image must have an associated target image with the same file name. We recommend naming each file with a number e.g. 0.tiff, 1.tiff, 2.tiff. We recommend using .tiff files but other file formats may work."", 'demoDataDetails': {'description': 'The example shows the fluorescence widefield image of live B. subtilis cells expressing FtsZ-GFP and the corresponding 2-label semantic segmentation mask used for model training.', 'fileName': 'train.zip', 'filePath': 'apps/unet2dmulti_training/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/5639253'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The test data are the images that will test your trained UNet2D multilabel segmentation network. This zip folder must be named 'test' before it is zipped and contain 2 sub-folders named 'source' and 'target'. 'source' will contain your regular images. 'target' will contain your segmented masks of the source images. Each source image must have an associated target image with the same file name. We recommend naming each file with a number e.g. 0.tiff, 1.tiff, 2.tiff. We recommend using .tiff files but other file formats may work"", 'demoDataDetails': {'description': 'The example shows the fluorescence widefield image of live B. subtilis cells expressing FtsZ-GFP and the corresponding 2-label semantic segmentation mask used for model training.""', 'fileName': 'test.zip', 'filePath': 'apps/unet2dmulti_training/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/5639253'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
COVID-Net: COVID-19 Detection from Chest X-ray,Covid19 detection from X-ray,"<p>Prediction of COVID-19 diagnosis, pneumonia probability, airspace severity, and disease severity from chest x-ray images<br><br><strong>Example use case: </strong>COVID-19 research<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use COVID-Net for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/lindawangg/COVID-Net#results"" target=""_blank"">As reported by the COVID-Net Open Source Initiative</a>&nbsp;</p>
","Wang, Linda and Lin, Zhong Qiu and Wong, Alexander, et al.","['Image Classification', 'Image Segmentation', 'Medical Diagnosis', 'jpeg', 'png', 'zip', 'Biomedical Image Analysis and Interpretation']",636201fc9c2c44f0b26d4796,,"[{'allowedFormats': {'fileExtensions': ['jpeg', 'png', 'zip'], 'title': '.jpeg, .png, zip', 'value': ''}, 'dataStructure': 'Data should be in .jpeg, or .png format. It can be a zip file with images.', 'demoDataDetails': {'description': 'Chest X-ray image for detection', 'fileName': 'ex-covid.jpeg', 'filePath': 'apps/covidnet/resources/ex-covid.jpeg', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/lindawangg/COVID-Net'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Chest X-ray Image', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Noise2Void: 2D Image Denoising Training Pipeline,Train a model to denoise your medical images in a self-supervised manner.,"<p>Train a model to denoise your medical images. Noise2Void is a deep-learning method that can be used to denoise many types of images, including microscopy images. It allows denoising of image data in a self-supervised manner, therefore high-quality, low noise equivalent images are not necessary to train this network. This is performed by ""masking"" a random subset of pixels in the noisy image and training the network to predict the values in these pixels. <span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Model saving and GPU access available soon.</span><br><br><span style=""font-weight: bold"">Example use case:</span> Train a model to take noisey images and remove noise to make the image clearer without needing examples of the clear images to train the model<br><br><span style=""font-weight: bold"">Technology:</span> U-Net<br><br><span style=""font-weight: bold"">Limitations:</span> Currently only gray scale images are supported</p>",Ricardo Henriques and Guillaume Jacquemet et al.,"['Image Denoising', 'Medical Image', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",6363c3519c2c44f0b26d4819,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 300, 'min_value': 50, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that train Noise2Void, 10% of these will be used for validation over training. The image folder must be named 'train' before being zipped. As this app is self supervised the training zip folder will contain only contain noise-y images of the kind you wish to denoise. We recommend using .tif files but other file formats may work."", 'demoDataDetails': {'description': 'Fluorescence microscopy (SiR-DNA) images of DCIS.COM Lifeact-RFP cells cells. This zip file contains the images under Training/low from the dataset in the link below', 'fileName': 'train.zip', 'filePath': 'apps/n2v_train/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/5750174#.Y0BMDdJBxkg'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The test data are the images that will test how well your trained model performs. This zip folder must be named 'test' and contain 2 sub-folders named 'source' and 'target'. 'source' will contain your regular noise-y images. 'target' will contain high resolution versions of your noise-y images. Each source image must have an associated target image with the same file name. We recommend using .tif files but other file formats may work. If you do not have test data, you can use ours by clicking the 'Need Data?' button below."", 'demoDataDetails': {'description': ""Fluorescence microscopy (SiR-DNA) images of DCIS.COM Lifeact-RFP cells cells. This zip file contains the images under 'test' from the dataset in the link below; sorted into 'source' and 'target' folders."", 'fileName': 'test.zip', 'filePath': 'apps/n2v_train/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/5750174#.Y0BMDdJBxkg'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Data Preparation Module,"This app provides how to process, analyze, and filter data from ChEMBL or other sources.","<p>This app provides how to process, analyze, and filter data from ChEMBL or other sources. There are several reasons why data used to train a generative model should be pre-processed. Invalid or duplicate entries need to be removed. Unusual compounds that are clearly not drug-like need to be excluded (too big, reactive groups and etc.) and rare tokens can be removed. There are some rare compounds that can be considered outliers and excluding them frees up space in the vocabulary, making it smaller. Input is SMILES strings in <strong><em>.smi</em></strong> format. Output is filtered SMILES in <strong><em>.csv</em></strong> format that can be used in other Reinvent apps. (e.g. <a href=""https://app.superbio.ai/apps/167?id=636ada2f7d6789757197927a"" target=""_blank"">Reinvent: Create Initial Prior/Agent Generative Model</a>). For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps. <br><br><strong>Example Use Case:</strong> Pre-processing SMILES strings from big sources for downstream analysis.<br><br><strong>Limitation: </strong>Filtering options are kept like in the demo notebook. Other options will be added next versions.</p>
",AstraZeneca,"['Reinforcement Learning', 'De novo Drug Design', 'Drug Discovery', 'Drug Discovery and Design']",6364d7049c2c44f0b26d486a,"[{'default_value': 6, 'input_type': 'user_input', 'name': 'num_atoms_bigger', 'title': 'Number of Atoms â¥', 'tooltip': 'Please specify specific atom number that you want to filter in the SMILES.', 'type': 'integer'}, {'default_value': 70, 'input_type': 'user_input', 'name': 'num_atoms_smaller', 'title': 'Number of Atoms â¤', 'tooltip': 'Please specify specific atom number that you want to filter in the SMILES', 'type': 'integer'}, {'default_value': 10, 'input_type': 'user_input', 'name': 'num_rings', 'title': 'Number of Rings <', 'tooltip': 'Please specify the specific ring number that you want to filter in the SMILES.', 'type': 'integer'}, {'default_value': 9, 'input_type': 'user_input', 'name': 'largest_ring', 'title': 'Number of Largest Ring <', 'tooltip': 'Please specify the specific largest ring number that you want to filter in the SMILES.', 'type': 'integer'}, {'default_value': 5, 'input_type': 'user_input', 'name': 'longest_alip_c_chain', 'title': 'Number of Longest Aliphatic Carbon Chain <', 'tooltip': 'Please specify the specific longest carbon chain number that you want to filter in the SMILES.', 'type': 'integer'}, {'default_value': 0.5, 'input_type': 'user_input', 'name': 'c_atom_ratio', 'title': 'Carbon Atom Ratio â¥', 'tooltip': 'Please specify the specific carbon atom ratio that you want to filter in the SMILES', 'type': 'float'}, {'default_value': 91, 'input_type': 'user_input', 'name': 'num_tokens', 'title': 'Number of Tokens â¤', 'tooltip': 'Please specify the specific number of tokens that you want to filter in the SMILES.', 'type': 'integer'}, {'default_value': 2, 'input_type': 'user_input', 'name': 'tokens_ratio', 'title': 'Tokens Ratio â¤', 'tooltip': 'Please specify the specific tokens ratio that you want to filter in the SMILES.', 'type': 'float'}, {'default_value': 0.05, 'input_type': 'user_input', 'name': 'token_dist_percent', 'title': 'Token/Molecule Distribution Percentage <', 'tooltip': 'Please specify the specific percentage of tokens that you want to filter in the SMILES.', 'type': 'float'}, {'default_value': '[', 'input_type': 'user_input', 'name': 'token_dist_startswith', 'title': 'Remove Tokens Startswith', 'tooltip': 'Please specify the specific token a string that you want to remove in the SMILES.', 'type': 'string'}, {'default_value': '[S+],[s+]', 'input_type': 'user_input', 'name': 'token_dist_isin', 'title': 'Remove Token(s) Contains', 'tooltip': 'Please specify the specific token(s) string(s) that you want to remove in the SMILES. You can add more than one input by seperating with comma.', 'type': 'string'}]","[{'allowedFormats': {'fileExtensions': ['smi'], 'title': '.smi', 'value': 'text/csv'}, 'dataStructure': 'SMILES strings should be in the first column of the .smi file without a header.\nExample:\nCc1cc(S(=O)(=O)NC(C)c2nnc3ccccn23)ccc1Br\nCc1cc(=NC(=O)c2ccc3c(-c4nc5ccccc5[nH]4)[nH]nc3c2)[nH][nH]1\nO=C1CC(c2ccc(Br)cc2)Nc2c(Br)cc(Br)cc21', 'demoDataDetails': {'description': 'SMILES in .smi format from the ReinventCommunity repository. If you want to upload your own data please put all SMILES strings in the first column without a header.', 'fileName': 'chembl.mini.smi', 'filePath': 'apps/reinvent_data_prep/resources/chembl.mini.smi', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/data'}]}, 'disabled': False, 'name': 'smi_file', 'title': 'Upload SMILES Dataset', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Noise2Void: 3D Image Denoising Training Pipeline,Train a model to denoise your 3D medical images in a self-supervised manner.,"<p>Train a model to denoise your 3D medical images. Noise2Void is a deep-learning method that can be used to denoise many types of images, including microscopy images. It allows denoising of image data in a self-supervised manner, therefore high-quality, low noise equivalent images are not necessary to train this network. This is performed by ""masking"" a random subset of pixels in the noisy image and training the network to predict the values in these pixels. The resulting output is a denoised version of the image. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case:</strong> Train a model to take noisey images and remove noise to make the image clearer without needing examples of the clear images to train the model<br><br><strong>Technology:</strong> U-Net</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Image Denoising', 'Medical Image', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",636594197d678975719791d7,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 300, 'min_value': 50, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that train Noise2Void, 10% of these will be used for validation over training. The image folder must be named 'train' before being zipped. As this app is self supervised the training zip folder will contain only contain noise-y images of the kind you wish to denoise. We recommend using .tiff files but other file formats may work."", 'demoDataDetails': {'description': '3D microscopy images (fluorescence). A2780 ovarian carcinoma cells, transiently expressing Lifeact-RFP. Actin dataset.\n\n', 'fileName': 'train.zip', 'filePath': 'apps/noise2void3d/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3713326#.XnEJjy2cZQI'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The test data are the images that will test how well your trained model performs. This zip folder must contain 2 sub-folders named 'source' and 'target'. 'source' will contain your regular noise-y images. 'target' will contain high resolution versions of your noise-y images. Each source image must have an associated target image with the same file name. We recommend using .tiff files but other file formats may work. If you do not have test data, you can use ours by clicking the 'Need Data?' button below."", 'demoDataDetails': {'description': '3D microscopy images (fluorescence). A2780 ovarian carcinoma cells, transiently expressing Lifeact-RFP. Actin dataset.', 'fileName': 'test.zip', 'filePath': 'apps/noise2void3d/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3713326#.XnEJjy2cZQI'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepStorm: High-density Single-molecule Localization Microscopy Image Reconstruction Training,Train Deep Storm for image reconstruction of high-density single-molecule localization microscopy.,"<p>Ultrafast, precise, and parameter-free image reconstruction from high-density single-molecule localization microscopy (SMLM). <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 13.66;font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case: </strong>Research with single-molecule localization microscopy<br><br><strong>Technology: </strong>U-Net based network without skip connections&nbsp;</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Data Enhancement', 'General Use', 'Medical Image', 'zip', 'Biomedical Image Analysis and Interpretation']",636a75f37d6789757197923c,"[{'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 300, 'min_value': 50, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': 'This is the data that will train the DeepStorm model. It should be a folder named train that has been zipped. The folder should contain a tif image and its corresponding csv localization file. The tif image should contain multiple frames.', 'demoDataDetails': {'description': 'yeet', 'fileName': 'train.zip', 'filePath': 'apps/deepstorm/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3959089#.XyrZgi2ZM1I'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': 'This is the data that your trained DeepStorm model will be tested on. It should be a folder named test that has been zipped. The folder should contain a tif image and its corresponding csv localization file. The tif image can contain multiple frames.', 'demoDataDetails': {'description': 'yeet', 'fileName': 'test.zip', 'filePath': 'apps/deepstorm/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3959089#.XyrZgi2ZM1I'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Create Initial Prior/Agent Generative Model,This application builds an initial generative model for prior/agent based on SMILES data.,"<p>Based on the Create_Model_Demo notebook from the ReinventCommunity repo. If you are planning to train a new model from scratch, this app is the first step of the process. This module creates an initial generative model of prior/agents for the next step (<a href=""https://app.superbio.ai/apps/170?id=636e0620614bfa9ffd879d75"" target=""_blank"">Reinvent: Train Initial Generative Model for Prior/Agent</a> ) by generating a vocabulary based on your SMILES training data. The vocabulary defines what tokens the model can propose, which directly controls the possible atom types in the SMILES output. The output of this app (empty_model.ckpt) will be the input for the next app (<a href=""https://app.superbio.ai/apps/170?id=636e0620614bfa9ffd879d75"" target=""_blank"">Reinvent: Train Initial Generative Model for Prior/Agent</a> ) that trains the generative model. Finally, the output file of the second app is what you can use in <a href=""https://app.superbio.ai/apps/181?id=637b69712ffa50c6deecda32"" target=""_blank"">Reinvent: Reinforcement Learning.</a> For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br><br><strong>Example Use Case</strong>: Generate generative model of prior/agents<br><br><strong>Limitation:</strong> At least 100.000 SMILES are recommended for creating a generative model</p>
",AstraZeneca,"['De novo Drug Design', 'Drug Discovery', 'csv', 'Drug Discovery and Design']",636ada2f7d6789757197927a,"[{'default_value': 3, 'input_type': 'slider', 'max_value': 32, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'num_layers', 'title': 'Number of Layers', 'tooltip': 'Default: 3. \nNumber of recurrent layers. E.g., setting num_layers=2 would mean stacking two Recurrent Neural Networks (RNNs) together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results.', 'type': 'integer'}, {'default_value': 512, 'input_type': 'user_input', 'name': 'layer_size', 'title': 'Layer Size', 'tooltip': 'The number of neurons to include in each layer', 'type': 'integer'}, {'default_value': {'label': 'lstm', 'value': 'lstm'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'cell_type', 'options': [{'label': 'lstm', 'value': 'lstm'}, {'label': 'gru', 'value': 'gru'}], 'title': 'RNN Model Type', 'tooltip': 'Default: LSTM. Select type of Recurrent Neural Network (RNN): a multi-layer long short-term memory (LSTM) or a gated recurrent unit (GRU). LSTMs and GRUs use memory cells to store the activation of the previous words in long sequences.'}, {'default_value': 256, 'input_type': 'user_input', 'name': 'embedding_layer_size', 'title': 'Embedding Layer Size', 'tooltip': 'The number of neurons to include in each layer. The size of the embedding layer should be lower than the following LSTM/GRU cells.', 'type': 'integer'}, {'default_value': 0, 'input_type': 'user_input', 'name': 'dropout', 'title': 'Dropout', 'tooltip': 'Default:0. A simple and robust regularization method for neural networks and deep learning models is a dropout. This technique decreases overfitting in neural networks by preventing complex co-adaptations on training data.', 'type': 'float'}, {'default_value': 256, 'input_type': 'user_input', 'name': 'max_sequence_length', 'title': 'Max Sequence Length', 'tooltip': 'Default: 256. The maximum length of the sequence of input data.', 'type': 'integer'}, {'default_value': {'label': 'False', 'value': 'False'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'layer_normalization', 'options': [{'label': 'False', 'value': 'False'}, {'label': 'True', 'value': 'True'}], 'title': 'Layer Normalization', 'tooltip': 'Default: False. Layer normalization estimates normalization statistics directly from the cumulative input to neurons in the hidden layer, so normalization does not introduce new dependencies between training conditions.'}, {'default_value': {'label': 'False', 'value': 'False'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'standardize', 'options': [{'label': 'False', 'value': 'False'}, {'label': 'True', 'value': 'True'}], 'title': 'Standardize', 'tooltip': 'Default: False. We assume the data is being standardized during Reinvent: Data Preparation Module.'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'SMILES strings should be in the first column of the .csv file without a header. If you used the Reinvent: Data Preparation Module, you can directly upload its output file here.\nExample:\nCc1cc(S(=O)(=O)NC(C)c2nnc3ccccn23)ccc1Br\nCc1cc(=NC(=O)c2ccc3c(-c4nc5ccccc5[nH]4)[nH]nc3c2)[nH][nH]1\nO=C1CC(c2ccc(Br)cc2)Nc2c(Br)cc(Br)cc21', 'demoDataDetails': {'description': 'SMILES in .csv format from the Reinvent: Data Preparation Module app. The output of the demo result file (final.filtered.csv) is used as the demo input file of this app.', 'fileName': 'final.filtered.csv', 'filePath': 'apps/reinvent_create_model/resources/final.filtered.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://app.superbio.ai/apps/162?id=6364d7049c2c44f0b26d486a'}]}, 'disabled': False, 'name': 'filtered_smiles', 'title': 'Upload Pre-processed SMILES File ', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DFCAN: 2D Image Up-sampling Training Pipeline,DFCAN transforms low-resolution images to super-resolved images.,"<p>DFCAN transforms low-resolution (LR) images to super-resolved (SR) images. The training is done using LR-SR image pairs, taking the LR images as input and obtaining an output as close to SR as possible. DFCAN achieves comparable image quality to SIM over a tenfold longer duration in multicolor live-cell imaging experiments, which reveal the detailed structures of mitochondrial cristae and nucleoids and the interaction dynamics of organelles and cytoskeleton. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br><br><strong>Example use case: </strong>Take low-resolution microscapy images and increase the resoution of them to reveal clearer structures in the images<br><br><strong>Technology: </strong>Deep Fourier channel attention network&nbsp;</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Data Enhancement', 'Image Denoising', 'Medical Image', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",636d6954614bfa9ffd879d46,"[{'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 300, 'min_value': 50, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}, {'decimalPlace': 0, 'default_value': 2, 'increment': 1, 'input_type': 'slider', 'max_value': 8, 'min_value': 2, 'name': 'down_factor', 'title': 'Down sampling factor', 'tooltip': 'Scaling factor by which every dimension of the standard resolution images is reduced. For example, if a standard resolution image dimension is 256x256, and its low resolution counterpart is 128x128, the down_factor is 2. '}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that train DFCAN. The training data should consist of a zipped folder named 'train' containing 2 folders named 'source' and 'target'. Images in the source folder are the low resolution images, images in the target folder are the high resolution counterparts. Each low resolution and high resolution pair of images must have the same file name. Images must be .tif files."", 'demoDataDetails': {'description': 'Pairs of high resolution and low resolution images', 'fileName': 'train.zip', 'filePath': 'apps/dfcan/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.dropbox.com/s/9f9xat4jbgkdchh/F-actin-small.zip?dl=0'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that test your trained DFCAN model. The training data should consist of a zipped folder named 'test' containing 2 folders named 'source' and 'target'. Images in the source folder are the low resolution images, images in the target folder are the high resolution counterparts. Each low resolution and high resolution pair of images must have the same file name. Images must be .tif files."", 'demoDataDetails': {'description': 'Pairs of high resolution and low resolution images', 'fileName': 'test.zip', 'filePath': 'apps/dfcan/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.dropbox.com/s/9f9xat4jbgkdchh/F-actin-small.zip?dl=0'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Train Initial Generative Model for Prior/Agent,Train model created by the Reinvent: Create Initial Prior/Agent Generative Model app,"<p>This app was originally created based on notebook (Transfer Learning Mode) from the ReinventCommunity repo. The purpose of this app is to train an empty model created from the previous <a href=""https://app.superbio.ai/apps/167?id=636ada2f7d6789757197927a"" target=""_blank"">Reinvent: Create Initial prior/agent Generative Model.</a>  In this scenario, inputs are an empty model (.ckpt file) and a processed dataset (.csv file) generated by <a href=""https://app.superbio.ai/apps/162?id=6364d7049c2c44f0b26d486a"" target=""_blank"">Reinvent: Data Preparation Module</a>. The output will be the Prior that can be used afterward forÂ other apps of Reinvent such as reinforcement learning. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br><br><strong>Example Use Case:</strong> Train generative model with Transfer Learning<br><br><strong>Limitations: </strong>Some of the parameters are kept the same as in the original notebook.<br><br><strong>Technology: </strong>Transfer Learning (TL)<br></p>
",AstraZeneca,"['De novo Drug Design', 'Transfer Learning', 'Drug Discovery', 'csv', 'Drug Discovery and Design']",636e0620614bfa9ffd879d75,"[{'default_value': 3, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'num_epoch', 'title': 'Epoch', 'tooltip': 'Number of epoch to train prior', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'SMILES strings should be in the first column of the .csv file without a header. If you used the Reinvent: Data Preparation Module, you can directly upload its output file here.\nExample:\nCc1cc(S(=O)(=O)NC(C)c2nnc3ccccn23)ccc1Br\nCc1cc(=NC(=O)c2ccc3c(-c4nc5ccccc5[nH]4)[nH]nc3c2)[nH][nH]1\nO=C1CC(c2ccc(Br)cc2)Nc2c(Br)cc(Br)cc21', 'demoDataDetails': {'description': 'SMILES in .csv format from the Reinvent: Data Preparation Module app. The output of the demo result file (final.filtered.csv) is used as the demo input file of this app.', 'fileName': 'final.filtered.csv', 'filePath': 'apps/reinvent_transfer_learning/resources/final.filtered.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://app.superbio.ai/apps/162?id=6364d7049c2c44f0b26d486a'}]}, 'disabled': False, 'name': 'filtered_smiles', 'title': 'Upload Pre-processed SMILES File ', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['ckpt'], 'title': '.ckpt', 'value': ''}, 'dataStructure': 'The checkpoint file (.ckpt) contains all available tokens that are in the training set. So it acts as a vocabulary. In order to create a suitable .ckpt file, (Reinvent: Create Initial prior/agent Generative Model) app needs to be used.', 'demoDataDetails': {'description': 'Demo empty model file (.ckpt) produced by (Reinvent: Create Initial prior/agent Generative Model).', 'fileName': 'empty_model.ckpt', 'filePath': 'apps/reinvent_transfer_learning/resources/empty_model.ckpt', 'fileSource': [{'title': 'Data Source', 'url': 'https://app.superbio.ai/apps/167?id=636ada2f7d6789757197927a'}]}, 'disabled': False, 'name': 'empty_model', 'title': 'Upload Empty Model File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Pix2Pix: Image to Image Translation Training,Train pix2pix to translate one image domain to another image domain.,"<p>Train pix2pix to translate one image domain to another image domain. The image transformation requires paired images for training (supervised learning) to learn information from the input image and obtain the equivalent translated image. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 13.66;font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br> <br><strong>Example use case:</strong> in silico cell painting, semantic segmentation, background removal, style transfer.<br><br><strong>Technology:</strong> Generative Adversarial Network</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Image to Image Translation', 'Cell Painting', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",6372c90c2ffa50c6deecd907,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 20, 'input_type': 'slider', 'max_value': 300, 'min_value': 40, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}, {'default_value': 'RGB', 'input_type': 'dropdown', 'name': 'image_type', 'options': [{'label': 'RGB', 'value': 'RGB'}, {'label': 'Grayscale', 'value': 'Grayscale'}], 'title': 'Image type', 'tooltip': 'Choose RGB for colour images. Choose Grayscale for black and white images.'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that train pix2pix. The training data should consist of a zipped folder named 'train' that contains 2 sub folders named 'source' and 'target'. Images in the source folder are the original images and images in the target folder should contain the source images' corresponding translated images. Each source and corresponding target image must have the same file name. Images should be .png files"", 'demoDataDetails': {'description': 'Paired microscopy images (fluorescence) of lifeact-RFP and sir-DNA', 'fileName': 'train.zip', 'filePath': 'apps/pix2pix/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3941889#.XxrkzWMzaV4'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The test data are the images that test your trained model. The test data should consist of a zipped folder named 'test' that contains 2 sub folders named 'source' and 'target'. Images in the source folder are the original images and images in the target folder should contain the source images' corresponding translated images. Each source and corresponding target image must have the same file name. Images should be .png files"", 'demoDataDetails': {'description': 'Paired microscopy images (fluorescence) of lifeact-RFP and sir-DNA', 'fileName': 'test.zip', 'filePath': 'apps/pix2pix/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3941889#.XxrkzWMzaV4'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
COVID-Net-CT: COVID-19 Detection from CT-scan,Covid19 detection from chest CT images.,"<p>Prediction of COVID-19 diagnosis from chest CT images<br><br><strong>Example use case: </strong>COVID-19 research<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use COVID-Net for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/haydengunraj/COVIDNet-CT#results"" target=""_self"">As reported by the COVID-Net Open Source Initiative</a>&nbsp;</p>
","Gunraj, Hayden and Wang, Linda and Wong, Alexander, et al.","['Image Classification', 'Medical Diagnosis', 'jpeg', 'png', 'zip', 'Biomedical Image Analysis and Interpretation']",637454212ffa50c6deecd937,,"[{'allowedFormats': {'fileExtensions': ['jpeg', 'png', 'zip'], 'title': '.jpeg, .png, zip', 'value': ''}, 'dataStructure': 'Data should be in .jpeg, or .png format. It can be a zip file of full CT volume.', 'demoDataDetails': {'description': 'Chest CT image for detection', 'fileName': 'ex-covid-ct.png', 'filePath': 'apps/covidnet/resources/ex-covid-ct.png', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/haydengunraj/COVIDNet-CT'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Chest CT Image', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Train QSAR Models for Target Proteins,This tool of REINVENT provides you to create QSAR models for your target protein(e.g.DRD2 receptor),"<p>This app derives from a notebook (Model Building Demo) in the ReinventCommunity repo. The aim of this app is to generate a QSAR model for a target protein that you are interested. QSAR modeling is an estimation of the activity/property/toxicity of new chemical entities in the drug discovery process. In the demo, SMILES that known activities on the DRD2 receptor were used. SMILES are transformed into fingerprints and act as the input in the code. Since REINVENT only supports pickled scikit-learn models, the output files are in <strong>(.pkl)</strong> format. The output file either can be used by <a href=""https://app.superbio.ai/apps/181?id=637b69712ffa50c6deecda32"" target=""_blank""><strong>(Reinvent: Reinforcement Learning Module)</strong></a>  or  <a href=""https://app.superbio.ai/apps/182?id=637b6ba22ffa50c6deecda3a"" target=""_blank""><strong>(Reinvent: Scoring Module)</strong></a>  apps. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps. <br><br><strong>Example Use Case:  </strong>Generating QSAR models for target protein<br><br><strong>Limitations: </strong><br>     - Only scikit-learn models <strong>(.pkl)</strong> are accepted by REINVENT<br>     - Since the demo notebook contains only classification methodology for the random forest, the app provides this option currently.<br><br><strong>Technology: </strong>Random Forest, scikit-learn, Quantitative structure-activity relationship<br><br><strong>Metrics: </strong>AUC score metrics from demo data are represented <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Model_Building_Demo.ipynb"" target=""_blank"">here</a>. Also, you can check the Example Output of this app.</p>
",AstraZeneca,"['De novo Drug Design', 'Random Forest', 'scikit-learn', 'Reinforcement Learning', 'Drug Discovery', 'csv', 'Drug Discovery and Design']",6374ae9a2ffa50c6deecd961,"[{'default_value': 20, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'max_depth', 'title': 'Max Depth', 'tooltip': 'The maximum depth of the tree', 'type': 'integer'}, {'default_value': 100, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'n_estimators', 'title': 'Number of Estimators', 'tooltip': 'The number of trees in Random Forest.', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'SMILES file in .CSV format for the training dataset. 2 columns must define in the file. The first columns should contain SMILES with (canonical) header name, the second column must contain activities (0 and 1) with (activity) header name.', 'demoDataDetails': {'description': 'Demo training dataset file from ReinventCommunity repo.', 'fileName': 'drd2.train.csv', 'filePath': 'apps/reinvent_train_qsar_model/resources/drd2.train.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/data'}]}, 'disabled': False, 'name': 'train_dataset', 'title': 'Upload SMILES Train Dataset File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'SMILES file in .CSV format for the test dataset. 2 columns must define in the file. The first columns should contain SMILES with (canonical) header name, the second column must contain activities (0 and 1) with (activity) header name.', 'demoDataDetails': {'description': 'Demo test dataset file from ReinventCommunity repo.', 'fileName': 'drd2.test.csv', 'filePath': 'apps/reinvent_train_qsar_model/resources/drd2.test.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}]}, 'disabled': False, 'name': 'test_dataset', 'title': 'Upload SMILES Test Dataset File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Tuberculosis-Net (TB-Net),Tuberculosis detection from chest X-ray images.,"<p>Prediction of Tuberculosis diagnosis from chest X-ray images</p>
<p><strong>Example use case: </strong> TB case detection<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use TB-Net for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/darwinai/TuberculosisNet#results"" target=""_blank"">As reported by the TB-Net Open Source Initiative</a>&nbsp;</p>
","Alexander Wong and James Ren Hou Lee and Hadi Rahmat-Khah and Ali Sabri and Amer Alaref, et al.","['Image Classification', 'Medical Diagnosis', 'png', 'jpeg', 'zip', 'Biomedical Image Analysis and Interpretation']",63752d342ffa50c6deecd975,,"[{'allowedFormats': {'fileExtensions': ['jpeg', 'png', 'zip'], 'title': '.jpeg, .png, zip', 'value': ''}, 'dataStructure': 'Data should be in .jpeg, or .png format. It can be a zip file of images.', 'demoDataDetails': {'description': 'Chest X-ray image for detection', 'fileName': 'tb-input.zip', 'filePath': 'apps/covidnet/resources/tb-input.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/darwinai/TuberculosisNet'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Chest X-ray Image', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Cancer-Net SCa,Skin cancer detection from dermoscopy images.,"<p>Prediction of skin cancer diagnosis from dermoscopy images</p>
<p><strong>Example use case: </strong> Skin cancer detection research<br><br><strong>Tecnology: </strong>Deep convolutional neural network<br> <br><strong>Limitations: </strong>Do not use Cancer-Net SCa for self-diagnosis and seek help from your local health authorities<br><br><strong>Metrics: </strong><a href=""https://github.com/jamesrenhoulee/CancerNet-SCa#results"" target=""_blank"">As reported by the Cancer-Net SCa Open Source Initiative</a>&nbsp;</p>
","James Lee, Mahmoud Famouri, Maya Pavlova, and Alexander Wong, ","['Image Classification', 'Medical Diagnosis', 'png', 'jpeg', 'zip', 'Biomedical Image Analysis and Interpretation']",637530952ffa50c6deecd976,,"[{'allowedFormats': {'fileExtensions': ['jpeg', 'png', 'zip'], 'title': '.jpeg, .png, zip', 'value': ''}, 'dataStructure': 'Data should be in .jpeg, or .png format. It can be a zip file of images.', 'demoDataDetails': {'description': 'Dermoscopy image for detection', 'fileName': 'ex_malignant.jpg', 'filePath': 'apps/covidnet/resources/ex_malignant.jpg', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/jamesrenhoulee/CancerNet-SCa'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Dermoscopy Image', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
CycleGAN: Unpaired Image to Image Translation Training,CycleGAN captures characteristics of an image domain and learns to translate said characteristics into another image domain,"<p>CycleGAN is a method that can capture the characteristics of one image domain and learn how these characteristics can be translated into another image domain, all in the absence of any paired training examples. <span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 13.66;font-family: Poppins, sans-serif;"">Model saving and GPU access available soon.</span> <br> <br><strong>Example use case:  </strong>In silico cell painting, semantic segmentation, background removal, style transfer.<br><br><strong>Limitations:</strong> If your dataset is paired, use <a href=""https://app.superbio.ai/apps/171?id=6372c90c2ffa50c6deecd907"" target=""_blank"">the pix2pix app</a> instead, paired training generally provides more information to the deep learning model and so can perform more effectively.<br><br><strong>Technology:</strong> Two Generative Adversairal Networks that learn to transform images both from the first domain to the second and vice-versa.</p>
",Ricardo Henriques and Guillaume Jacquemet et al.,"['Image to Image Translation', 'Cell Painting', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",637538982ffa50c6deecd977,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 20, 'input_type': 'slider', 'max_value': 300, 'min_value': 40, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}, {'default_value': 'Grayscale', 'input_type': 'dropdown', 'name': 'data_type', 'options': [{'label': 'RGB', 'value': 'RGB'}, {'label': 'Grayscale', 'value': 'Grayscale'}], 'title': 'Image type', 'tooltip': 'Choose RGB for colour images. Choose Grayscale for black and white images.'}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that train cycleGAN. The training data should consist of a zipped folder named 'train' that contains 2 sub folders named 'source' and 'target'. Images in the source folder are the original images and images in the target folder should contain images within the domain you wish to translate your source images to. This method being unpaired means your source and target images do not have to be corresponding pairs. Images should be .png files"", 'demoDataDetails': {'description': 'Unpaired microscopy images (fluorescence) of U2OS cell microtubules (Spinning-disk and SRRF reconstructed images)', 'fileName': 'train.zip', 'filePath': 'apps/cyclegan/train.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3941889#.XxrkzWMzaV4'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The test data are the images that test your trained model. The training data should consist of a zipped folder named 'train' that contains 2 sub folders named 'source' and 'target'. Images in the source folder are the original images and images in the target folder should contain images within the domain you wish to translate your source images to. This method being unpaired means your source and target images do not have to be corresponding pairs. Images should be .png files"", 'demoDataDetails': {'description': 'Unpaired microscopy images (fluorescence) of U2OS cell microtubules (Spinning-disk and SRRF reconstructed images)', 'fileName': 'test.zip', 'filePath': 'apps/cyclegan/test.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/3941889#.XxrkzWMzaV4'}]}, 'disabled': False, 'name': 'test', 'optional': False, 'title': 'Upload Test Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Image Classification Transfer Learning,Transfer learning shortcuts much of the model training process by taking a piece of a model that has already been trained on a related task and reusing it in a new model.,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">Image classification models have millions of parameters. Training them from scratch requires a lot of labelled training data and a lot of computing power. Transfer learning is a technique that shortcuts much of this by taking a piece of a model that has already been trained on a related task and reusing it in a new model. Model saving and GPU access available soon.</span><br><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Example use case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">Lesion, tumour, bacteria, animal etc. classification<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Technology:</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)""> Pretrained models from </span><span style=""color: #0088FF; background-color: rgb(255,255,255); text-decoration: underline""><a href=""https://www.tensorflow.org/hub"" target=""_blank"" rel=""noreferrer"">TensorFlow Hub</a></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">.<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Metrics:</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)""> All models trained on the </span><span style=""color: #0088FF; background-color: rgb(255,255,255); text-decoration: underline""><a href=""https://www.image-net.org/"" target=""_blank"" rel=""noreferrer"">ImageNet</a></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)""> dataset containing 14,197,122 images labelled under 1000 classes.</span></p>",Tensorflow,"['Image Classification', 'Medical Image', 'General Use', 'zip', 'Biomedical Image Analysis and Interpretation']",63779ce72ffa50c6deecd9c3,"[{'default_value': True, 'input_type': 'checkbox', 'name': 'data_aug', 'title': 'Augment Training Data', 'optional': True, 'tooltip': 'Augmenting your dataset will artificially inflate it by adding rotating, flipping, shearing, and shifting the images. This can improve model performance'}, {'default_value': True, 'input_type': 'checkbox', 'name': 'do_fine_tuning', 'title': 'Include fine-tuning', 'optional': True, 'tooltip': 'Including fine-tuning may increase model accuracy, but will increase training time.'}, {'decimalPlace': 0, 'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 500, 'min_value': 1, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Maximum epochs for training, more epochs can results in better model performance. However, more epochs mean longer training time'}, {'default_value': 'mobilenet_v2_100_224', 'input_type': 'dropdown', 'name': 'model_name', 'options': [{'label': 'efficientnetv2-s', 'value': 'efficientnetv2-s'}, {'label': 'efficientnetv2-m', 'value': 'efficientnetv2-m'}, {'label': 'efficientnetv2-l', 'value': 'efficientnetv2-l'}, {'label': 'efficientnetv2-s-21k', 'value': 'efficientnetv2-s-21k'}, {'label': 'efficientnetv2-m-21k', 'value': 'efficientnetv2-m-21k'}, {'label': 'efficientnetv2-l-21k', 'value': 'efficientnetv2-l-21k'}, {'label': 'efficientnetv2-xl-21k', 'value': 'efficientnetv2-xl-21k'}, {'label': 'efficientnetv2-b0-21k', 'value': 'efficientnetv2-b0-21k'}, {'label': 'efficientnetv2-b1-21k', 'value': 'efficientnetv2-b1-21k'}, {'label': 'efficientnetv2-b2-21k', 'value': 'efficientnetv2-b2-21k'}, {'label': 'efficientnetv2-b3-21k', 'value': 'efficientnetv2-b3-21k'}, {'label': 'efficientnetv2-s-21k-ft1k', 'value': 'efficientnetv2-s-21k-ft1k'}, {'label': 'efficientnetv2-m-21k-ft1k', 'value': 'efficientnetv2-m-21k-ft1k'}, {'label': 'efficientnetv2-l-21k-ft1k', 'value': 'efficientnetv2-l-21k-ft1k'}, {'label': 'efficientnetv2-xl-21k-ft1k', 'value': 'efficientnetv2-xl-21k-ft1k'}, {'label': 'efficientnetv2-b0-21k-ft1k', 'value': 'efficientnetv2-b0-21k-ft1k'}, {'label': 'efficientnetv2-b1-21k-ft1k', 'value': 'efficientnetv2-b1-21k-ft1k'}, {'label': 'efficientnetv2-b2-21k-ft1k', 'value': 'efficientnetv2-b2-21k-ft1k'}, {'label': 'efficientnetv2-b3-21k-ft1k', 'value': 'efficientnetv2-b3-21k-ft1k'}, {'label': 'efficientnetv2-b0', 'value': 'efficientnetv2-b0'}, {'label': 'efficientnetv2-b1', 'value': 'efficientnetv2-b1'}, {'label': 'efficientnetv2-b2', 'value': 'efficientnetv2-b2'}, {'label': 'efficientnetv2-b3', 'value': 'efficientnetv2-b3'}, {'label': 'efficientnet_b0', 'value': 'efficientnet_b0'}, {'label': 'efficientnet_b1', 'value': 'efficientnet_b1'}, {'label': 'efficientnet_b2', 'value': 'efficientnet_b2'}, {'label': 'efficientnet_b3', 'value': 'efficientnet_b3'}, {'label': 'efficientnet_b4', 'value': 'efficientnet_b4'}, {'label': 'efficientnet_b5', 'value': 'efficientnet_b5'}, {'label': 'efficientnet_b6', 'value': 'efficientnet_b6'}, {'label': 'efficientnet_b7', 'value': 'efficientnet_b7'}, {'label': 'bit_s-r50x1', 'value': 'bit_s-r50x1'}, {'label': 'inception_v3', 'value': 'inception_v3'}, {'label': 'inception_resnet_v2', 'value': 'inception_resnet_v2'}, {'label': 'resnet_v1_50', 'value': 'resnet_v1_50'}, {'label': 'resnet_v1_101', 'value': 'resnet_v1_101'}, {'label': 'resnet_v1_152', 'value': 'resnet_v1_152'}, {'label': 'resnet_v2_50', 'value': 'resnet_v2_50'}, {'label': 'resnet_v2_101', 'value': 'resnet_v2_101'}, {'label': 'resnet_v2_152', 'value': 'resnet_v2_152'}, {'label': 'nasnet_large', 'value': 'nasnet_large'}, {'label': 'nasnet_mobile', 'value': 'nasnet_mobile'}, {'label': 'pnasnet_large', 'value': 'pnasnet_large'}, {'label': 'mobilenet_v2_100_224', 'value': 'mobilenet_v2_100_224'}, {'label': 'mobilenet_v2_130_224', 'value': 'mobilenet_v2_130_224'}, {'label': 'mobilenet_v2_140_224', 'value': 'mobilenet_v2_140_224'}, {'label': 'mobilenet_v3_small_100_224', 'value': 'mobilenet_v3_small_100_224'}, {'label': 'mobilenet_v3_small_075_224', 'value': 'mobilenet_v3_small_075_224'}, {'label': 'mobilenet_v3_large_100_224', 'value': 'mobilenet_v3_large_100_224'}, {'label': 'mobilenet_v3_large_075_224', 'value': 'mobilenet_v3_large_075_224'}], 'title': 'Pretrained model', 'tooltip': ""Select a pretrained model, these models have all been pretrained on a huge general dataset. 'efficientnetv2' models are optimised for model size, and training and inference speed. 'bit_s-r50x1' can perform well even a small dataset. 'resnet' networks use supervised contrastive learning leading to state of the art performance in unsupervised training. See the tensorflow website for more details.""}]","[{'allowedFormats': {'fileExtensions': ['zip'], 'title': '.zip', 'value': 'application/zip'}, 'dataStructure': ""The training data are the images that will train your classification model, 20% of this data will be used for validation. The training data should consist of a zipped folder named 'data' that contains a sub folder named after each of your class labels. Each sub folder should contain images of the type corresponding to the subfolder's name. Images should any of '.bmp', '.gif', '.jpeg', '.jpg', '.png' files"", 'demoDataDetails': {'description': 'Images of Amoeba, Euglena, Hydra, Paramecium, Rod bacteria, Spherical bacteria, Spiral bacteria, Yeast', 'fileName': 'train.zip', 'filePath': 'apps/im_class_retraining/data.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/mdwaquarazam/microorganism-image-classification?resource=download'}]}, 'disabled': False, 'name': 'train', 'title': 'Upload Training Images', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Reinforcement Learning Module,This app directs the generative model toward relevant areas in the chemical space with help of RL.,"<p>The reference notebook of this app is ""Reinforcement Learning Demo"" from the ReinventCommunity repository. The purpose of this app decides which molecules are ""good"" or ""bad"" by using RL. Generally, the generative model that was created before must be directed to a relevant region of chemical space that involve compounds of interest. To achieve this, a Reinforcement Learning methodology is used with several scoring functions defined by the user. During the RL, molecules are generated by the <strong><em>agent </em></strong>and receive a score between 0 and 1. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank""><span style=""color: inherit;"">page</span></a> of Reinvent Apps.<br> <br><strong>Example use case:</strong> Generate molecules with RL setup.<br><br><strong>Limitations:</strong><br>-Some of the parameters are kept as default and not shown here (they will be added next versions)<br>-Currently, only the CPU version is available<br><br><strong>Technology:</strong> Reinforcement Learning<br><br><strong>Metrics: </strong>See metrics in the original demo <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Reinforcement_Learning_Demo.ipynb"" target=""_blank"">notebook</a> this app is derived from</p>
",AstraZeneca,"['Reinforcement Learning', 'De novo Drug Design', 'Drug Discovery', 'csv', 'Drug Discovery and Design']",637b69712ffa50c6deecda32,"[{'default_value': 125, 'increment': 1, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 25, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epoch', 'tooltip': 'Please specify number of epochs.', 'type': 'integer'}, {'decimalPlace': 4, 'default_value': 0.0001, 'increment': 0.0001, 'input_type': 'slider', 'max_value': 0.9, 'max_value_included': True, 'min_value': 0.0001, 'min_value_inclusive': True, 'name': 'learning_rate', 'title': 'Learning Rate', 'tooltip': 'Please specify the learning rate ratio', 'type': 'float'}, {'default_value': {'label': 'Regression', 'value': 'regression'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'scikit_model', 'options': [{'label': 'Regression', 'value': 'regression'}, {'label': 'Classification', 'value': 'classification'}], 'title': 'Scikit-Learn Model', 'tooltip': 'Please specify model that you used in random forest.'}]","[{'allowedFormats': {'fileExtensions': ['prior', 'new', 'agent'], 'title': '.prior/.new/.agent', 'value': ''}, 'dataStructure': 'Prior/Agent file produced by (Reinvent: Transfer Learning) app. You can directly use its output here as an input.', 'demoDataDetails': {'description': 'Demo prior/agent file used in original notebook (Reinforcement Reinforcement Learning Demo).', 'fileName': 'random.prior.new', 'filePath': 'apps/reinvent_reinforcement_learning/resources/random.prior.new', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/data'}]}, 'disabled': False, 'name': 'prior_agent_file', 'title': 'Upload Prior/Agent File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['pkl'], 'title': '.pkl', 'value': 'pkl'}, 'dataStructure': 'Pkl file produced by Reinvent: Train QSAR Models for Target Protein. Its output can be used in this app as an input.', 'demoDataDetails': {'description': 'Demo .pkl file used in original notebook from ReinventCommunity repo (Reinforcement Learning Demo).', 'fileName': 'Aurora_model.pkl', 'filePath': 'apps/reinvent_reinforcement_learning/resources/Aurora_model.pkl', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/data'}]}, 'disabled': False, 'name': 'pkl_file', 'title': 'Upload QSAR Model File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMILES in CSV format. SMILES should be in the first column without a header. The purpose of providing these SMILES in the RL process is to follow in the footsteps of well-scored small molecules previously identified.', 'demoDataDetails': {'description': 'Originally SMILES are provided in Python list in the notebook. To easy to use we want from user to provide SMILES in CSV format. As you can see in the notebook, the inception SMILES list is empty so file that we provided here also empty .CSV file.', 'fileName': 'inception_smiles.csv', 'filePath': 'apps/reinvent_reinforcement_learning/resources/inception_smiles.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Reinforcement_Learning_Demo.ipynb'}]}, 'disabled': False, 'name': 'inception_smiles_file', 'optional': True, 'title': 'Upload Inception SMILES File (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMARTS in CSV format. SMARTS should be in the first column without a header. They can be used to enforce the match to a given substructure. It penalizes the total score if desired substructures are not seen in the generated compound. It produces a score of either 1 or 0.5 in the result depending on whether the desired scaffold is present or not.', 'demoDataDetails': {'description': 'Originally SMARTS are provided in Python list in the notebook. o easy to use we want from user to provide SMARTS in CSV format. As you can see in the notebook, there is only one item in the matching_substructure list which is âc1ccccc1CCâ, thus file that provided here contains that SMART string only.', 'fileName': 'matching_substructure.csv', 'filePath': 'apps/reinvent_reinforcement_learning/resources/matching_substructure.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Reinforcement_Learning_Demo.ipynb'}]}, 'disabled': False, 'name': 'match_substructure_file', 'optional': True, 'title': 'Upload Matching Substructure SMARTS (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMARTS in CSV format. SMARTS should be in the first column without a header. These SMARTS can be used enforce to NOT match a given substructure. Those who want aiming novelty and avoid certain molecular substructures can provide their SMARTS structures here.', 'demoDataDetails': {'description': 'Originally SMARTS are provided in Python list in the notebook. o easy to use we want from user to provide SMARTS in CSV format. As you can see in the notebook, there are many moieties that wanted to be avoided so please check the original notebook by clicking link here to see SMARTS strings.', 'fileName': 'avoid_smiles.csv', 'filePath': 'apps/reinvent_reinforcement_learning/resources/avoid_smiles.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Reinforcement_Learning_Demo.ipynb'}]}, 'disabled': False, 'name': 'avoid_smiles_file', 'optional': True, 'title': 'Upload Custom Alerts SMARTS (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Scoring Mode,The scoring mode of Reinvent enables users to use scoring functions to evaluate SMILES directly.,"<p>This app is derived from the <span style=""color: #0088FF""><a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Scoring_Demo.ipynb"" target=""_blank"" rel=""noreferrer"">""Scoring Demo""</a></span> notebook in the ReinventCommunity repository. The purpose of this module is to estimate SMILES scores with the same scoring function as intended for the RL. For example, in the RL process inception, SMILES can be used. In order to evaluate whether these SMILES are good or not for your case independently, they can be used in this app to produce scores for evaluation. For more information, please see the tutorial <span style=""color: #0088FF""><a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank"" rel=""noreferrer"">page</a></span> of Reinvent Apps.<br><br><span style=""font-weight: bold"">Example use case:</span> Evaluation of SMILES strings by utilizing the same scoring function in the RL<br><br><span style=""font-weight: bold"">Limitation:</span><br>- Some of the parameters are kept as default and not shown here (they will be added next versions)<br><br><span style=""font-weight: bold"">Technology:</span> RDkit</p>",AstraZeneca,"['De novo Drug Design', 'Reinforcement Learning', 'Drug Discovery', 'csv', 'Drug Discovery and Design']",637b6ba22ffa50c6deecda3a,"[{'default_value': {'label': 'Regression', 'value': 'regression'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'scikit_model', 'options': [{'label': 'Regression', 'value': 'regression'}, {'label': 'Classification', 'value': 'classification'}], 'title': 'Scikit-Learn Model', 'tooltip': 'Please specify which module used in scikit-learn Random Forest'}]","[{'allowedFormats': {'fileExtensions': ['smi', 'csv'], 'title': '.smi/.csv', 'value': ''}, 'dataStructure': 'Please provide SMILES that you want to evaluate in CSV format. SMILES should be in the first column without a header.', 'demoDataDetails': {'description': 'Demo SMILES strings used in original notebook (Scoring Demo).', 'fileName': 'smiles.smi', 'filePath': 'apps/reinvent_scoring/resources/smiles.smi', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/data'}]}, 'disabled': False, 'name': 'smiles', 'title': 'Upload SMILES File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['pkl'], 'title': '.pkl', 'value': 'pkl'}, 'dataStructure': 'Pkl file produced by Reinvent: Train QSAR Models for Target Protein. Its output can be used in this app as an input.', 'demoDataDetails': {'description': 'Demo data used in original notebook from ReinventCommunity repo (Reinforcement Learning Demo).', 'fileName': 'Aurora_model.pkl', 'filePath': 'apps/reinvent_scoring/resources/Aurora_model.pkl', 'fileSource': [{'title': 'Demo Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/models'}]}, 'disabled': False, 'name': 'pkl_file', 'title': 'Upload QSAR Model File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMARTS in CSV format. SMARTS should be in the first column without a header. They can be used to enforce the match to a given substructure. It penalizes the total score if desired substructures are not seen in the generated compound. It produces a score of either 1 or 0.5 in the result depending on whether the desired scaffold is present or not.', 'demoDataDetails': {'description': 'Originally SMARTS are provided in Python list in the notebook. o easy to use we want from user to provide SMARTS in CSV format. As you can see in the notebook, there is only one item in the matching_substructure list which is âc1ccccc1CCâ, thus file that provided here contains that SMART string only.', 'fileName': 'matching_substructure.csv', 'filePath': 'apps/reinvent_scoring/resources/matching_substructure.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Scoring_Demo.ipynb'}]}, 'disabled': False, 'name': 'match_substructure_file', 'optional': True, 'title': 'Upload Matching Substructure SMILES (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'text/csv'}, 'dataStructure': 'Please provide SMARTS in CSV format. SMARTS should be in the first column without a header. These SMARTS can be used enforce to NOT match a given substructure. Those who want aiming novelty and avoid certain molecular substructures can provide their SMARTS structures here.', 'demoDataDetails': {'description': 'Originally SMARTS are provided in Python list in the notebook. o easy to use we want from user to provide SMARTS in CSV format. As you can see in the notebook, there are many moieties that wanted to be avoided so please check the original notebook by clicking link here to see SMARTS strings.', 'fileName': 'avoid_smiles.csv', 'filePath': 'apps/reinvent_scoring/resources/avoid_smiles.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Scoring_Demo.ipynb'}]}, 'disabled': False, 'name': 'avoid_smiles_file', 'optional': True, 'title': 'Upload Custom Alerts SMARTS (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Reinvent: Sampling Module,This module allows users to sample further SMILES from a given model state(agent).,"<p>This app is based on <a href=""https://github.com/MolecularAI/ReinventCommunity/blob/master/notebooks/Sampling_Demo.ipynb"" target=""_blank"">""Sampling_Demo.ipynb</a>"" from the ReinventCommunity notebook. The purpose of the notebook is to show how to sample further compounds from a given model state (agent). During the RL process, each iteration of the agent produces an output of a number of molecules and stores it inside. If more ideas are necessary for the project afterward, this can be achieved through this module. The sampling module enables you to extract molecules from the trained agent (given model state) to use for more investigation. For more information, please see the tutorial <a href=""https://www.notion.so/superbioai/Tutorials-de96d8a4eaeb4b92901936ef9ceaf876"" target=""_blank"">page</a> of Reinvent Apps.<br> <br><strong>Example Use Case: </strong>A sampling of SMILES from the generative trained agent<br><br><strong>Limitation: </strong><br>- Job only can be submitted in CPU version<br>- Currently, maximum 5 million SMILES can be sampled</p>
",AstraZeneca,"['De novo Drug Design', 'Reinforcement Learning', 'Drug Discovery', 'Drug Discovery and Design']",637b73d92ffa50c6deecda46,"[{'default_value': {'label': 'False', 'value': 'False'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'with_likelihood', 'options': [{'label': 'False', 'value': 'False'}, {'label': 'True', 'value': 'True'}], 'title': 'Add Likelihood Value', 'tooltip': 'For providing log-likelihood metrics in the results'}, {'default_value': 1024, 'input_type': 'user_input', 'max_value': 5000000, 'max_value_included': True, 'min_value': 100, 'min_value_inclusive': True, 'name': 'num_smiles', 'title': 'Number of smiles', 'tooltip': 'Please specify, how many molecules are to be sampled', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['prior', 'new', 'agent'], 'title': '.prior/.new/.agent', 'value': ''}, 'dataStructure': 'Please provide prior/trained agent file. Trained agent file can be obtained from Reinforcement Learning module.', 'demoDataDetails': {'description': 'Demo prior file used in original notebook (Sampling_Demo.ipynb).', 'fileName': 'random.prior.new', 'filePath': 'apps/reinvent_sampling/resources/random.prior.new', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/MolecularAI/ReinventCommunity/tree/master/notebooks/data'}]}, 'disabled': False, 'name': 'prior_agent_model', 'title': 'Upload Prior/Trained Agent File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Cutadapt: Sequence Trimming For High-Throughput Reads,Cutadapt allows you to remove unwanted sequences (e.g. adapters) from your high-throughput reads.,"<p>Data quality can be important for downstream analysis (e.g. alignment) and data cleaning is one of the most important steps to improve data quality. This app eliminates unnecessary reads from your sequence (e.g. adapters, primers, Poly-A tails). Inputs are FASTQ reads and adapters sequences. Output is an info table generated by the Cudatapt algorithm. Based on <a href=""https://cutadapt.readthedocs.io/en/v4.1/"" target=""_blank"">Cutadapt</a> version  <strong><em>v4.1</em></strong>. <br><br><strong>Example Use Case:</strong> Remove unwanted 3' adapters from the FASTQ sequence<br><br><strong>Limitation:</strong> Currently, only 3' adapters are accepted</p>
",Marcel Martin,"['Trimming', 'fasta', 'fastq', 'fastq.gz', 'Computational Biology and Bioinformatics']",637dddb82ffa50c6deecda6f,"[{'default_value': {'label': 'Paired-End', 'value': 'PAIRED'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'paired_or_single', 'options': [{'label': 'Paired-End', 'value': 'PAIRED'}, {'label': 'Single-End', 'value': 'SINGLE'}], 'title': 'Library Output', 'tooltip': 'Please specify library output (paired-end or single-end).'}]","[{'allowedFormats': {'fileExtensions': ['fastq', 'fastq.gz'], 'title': '.fastq/.fastq.gz', 'value': ''}, 'dataStructure': 'FASTQ format is text based, human readable, file that stores nucleotide base sequences with a quality(Phred) score for each base.', 'demoDataDetails': {'description': 'Demo file provided from ENA platform.', 'fileName': 'SRR11273539_1.fastq.gz', 'filePath': 'apps/cutadapt/resources/SRR11273539_1.fastq.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.ebi.ac.uk/ena/browser/view/SRR11273539'}]}, 'disabled': False, 'name': 'fastq_r1', 'title': 'Upload Read-1 FASTQ File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['fastq', 'fastq.gz'], 'title': '.fastq/.fastq.gz', 'value': ''}, 'dataStructure': 'FASTQ format is text based, human readable, file that stores nucleotide base sequences with a quality(Phred) score for each base. If the experimental setup is paired-end sequencing, R2 file must be uploaded as well.', 'demoDataDetails': {'description': 'Demo file provided from ENA platform.', 'fileName': 'SRR11273539_2.fastq.gz', 'filePath': 'apps/cutadapt/resources/SRR11273539_2.fastq.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.ebi.ac.uk/ena/browser/view/SRR11273539'}]}, 'disabled': False, 'name': 'fastq_r2', 'optional': True, 'title': 'Upload Read-2 FASTQ File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['fasta', ''], 'title': '.fasta', 'value': ''}, 'dataStructure': 'Adapter(s) must be provided in .fasta file format. You can add multiple adapter sequences by using same structure below.\nExample:\n>adapter1\nGTTCCAATCTCAAATGGC\n>adapter2\nATTCGGGTCTCAAATGGC', 'demoDataDetails': {'description': 'Adapter sequences were obtained from the information page of the experiment on the NCBI website.', 'fileName': 'R1_adapter.fasta', 'filePath': 'apps/cutadapt/resources/R1_adapter.fasta', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4403960'}]}, 'disabled': False, 'name': 'adapter_3_fasta1', 'title': 'Upload Forward Adapter File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['fasta', ''], 'title': '.fasta', 'value': ''}, 'dataStructure': 'Adapter(s) must be provided in .fasta file format. You can add multiple adapter sequences by using same structure below. If your experimental setup is paired-end sequencing, you need to add reverse adapter file as well.\nExample:\n>adapter1\nGTTCCAATCTCAAATGGC\n>adapter2\nATTCGGGTCTCAAATGGC', 'demoDataDetails': {'description': 'Adapter sequences were obtained from the information page of the experiment on the NCBI website.', 'fileName': 'R2_adapter.fasta', 'filePath': 'apps/cutadapt/resources/R2_adapter.fasta', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM4403960'}]}, 'disabled': False, 'name': 'adapter_3_fasta2', 'optional': True, 'title': 'Upload Reverse Adapter File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepNull: Modeling Non-Linear Covariate Effects,DeepNull determines and rearranges non-linear and interactive covariate effects with a deep neural network to increase power in genome-wide association studies (GWAS).,"<p>A typical strategy for examining the relationship between genotype and phenotype while controlling for a number of factors is genome-wide association studies (GWAS). Covariates that could have non-linear or interaction effects are typically ignored by GWAS. When such non-linearity is detected, DeepNull can model the non-linear impact of variables on phenotypes. It learns this potentially complicated and non-linear relationship using a flexible deep neural network (DNN), and during association testing, makes adjustments for the network's expectation of phenotype (based on covariates only).<br><br><span style=""font-weight: bold"">Example use case:</span> Improve phenotype prediction and association power in GWAS<br><br><span style=""font-weight: bold"">Technology: </span>Deep Neural Network (DNN)<br><br><span style=""font-weight: bold"">Limitation: </span>Some of the DNN parameters were left as default. Please check this <span style=""color: #0088FF""><a href=""https://github.com/Google-Health/genomics-research/blob/main/nonlinear-covariate-gwas/config.py"" target=""_blank"" rel=""noreferrer"">page</a></span> for more information.</p>",Google Research,"['GWAS', 'Deep Neural Network (DNN)', 'tsv', 'Genomics']",6380a2792ffa50c6deecdb2b,"[{'default_value': 100, 'increment': 1, 'input_type': 'slider', 'max_value': 3000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'epoch', 'title': 'Epoch', 'tooltip': 'Epoch means one complete pass of the training dataset through the algorithm. Please specify epoch number for your DNN.', 'type': 'integer'}, {'default_value': 'target_label', 'input_type': 'user_input', 'name': 'target_pheno_col', 'title': 'Target Column', 'tooltip': 'Target phenotype of interest. Please specify the target column you want to be predicted from covariate columns. If you have a column name with any spaces, please remove spaces from target column name.', 'type': 'text', 'validation': '^\\S*$'}, {'default_value': 'cov1,cov2', 'input_type': 'user_input', 'name': 'covar_cols', 'title': 'Covariate Columns', 'tooltip': 'Please specicfy covariates column names that used to predict the phenotype of interest column you can determine more than one by using comma without any spaces.(e.g. age,sex). If you have a column name with any spaces, please remove spaces from each column name.', 'type': 'text', 'validation': '^\\S*$'}]","[{'allowedFormats': {'fileExtensions': ['tsv'], 'title': '.tsv', 'value': 'text/tsv'}, 'dataStructure': 'This file is formatted as a tab-separated file that comprises the phenotype of interest and the covariates used to predict the phenotype. Shortly, the file must contain a header and the first two columns should be FID and IID, and all IID values must be unique.\nExample:\nFID\tIID\tcov1\tcov2\ttarget_label\n0\t0\t0.93553\t0.69545\t1.33245', 'demoDataDetails': {'description': 'Demo file derived from test code in DeepNull repo.', 'fileName': 'test_input.tsv', 'filePath': 'apps/deepnull/resources/test_input.tsv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/Google-Health/genomics-research/tree/main/nonlinear-covariate-gwas'}]}, 'disabled': False, 'name': 'input_tsv', 'title': 'Upload Covariates File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
MetaESM: One Shot Protein Variant Prediction,Predict variant sequences without supervision or additional training,"<p style=""text-align: left""><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255)"">The approach to date has been to fit a model to a family of related sequences. The conventional setting is limited, since a new model must be trained for each prediction task. These </span><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif"">state-of-the-art</span><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""> models </span><span style=""color: rgb(25,25,25); background-color: rgb(255,255,255)"">use only zero-shot inference, without any supervision from experimental data or additional training, capturing the functional effects of sequence variation.</span><br><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Example use case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">Predicting protein sequence variants, along with the effects of these variants on protein function.<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Technology: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">The training mode adjusts the number of models used to generate predictions. Fast uses a single model, standard three, and intensive five. Where multiple models are used their ensemble is used to provide overall metrics.Â </span></p>",Facebook Meta,"['Variant Predictor', 'Proteomics', 'Computational Biology and Bioinformatics']",6384b00f2ffa50c6deecdb63,"[{'default_value': 'oneshot_variant_prediction', 'hidden': True, 'input_type': 'user_input', 'name': 'app', 'title': 'app', 'tooltip': 'NA', 'type': 'object'}, {'default_value': {'label': 'mutant', 'value': 'mutant'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'mutation_col', 'options': [], 'title': 'Mutation column', 'tooltip': ""Column in the deep mutational scan labeling the mutation as 'AiB'""}, {'default_value': {'label': 'HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW', 'value': 'HPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW'}, 'disabled': False, 'input_type': 'user_input', 'name': 'sequence', 'options': [], 'title': 'Sequence', 'tooltip': 'Base sequence to which mutations were applied'}, {'default_value': {'label': 'Wildtype marginals', 'value': 'wt-marginals'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'scoring_strategy', 'options': [{'label': 'Wildtype marginals', 'value': 'wt-marginals'}, {'label': 'Masked marginals', 'value': 'masked-marginals'}, {'label': 'Psuedolikelihood', 'value': 'pseudo-ppl'}], 'title': 'Scoring strategy', 'tooltip': 'Choose scoring strategy for variants'}, {'default_value': {'label': 'ESM-2', 'value': 'esm_2'}, 'disabled': True, 'input_type': 'dropdown', 'name': 'model_name', 'options': [{'label': 'MSA Transformer', 'value': 'msa'}, {'label': 'ESM-2', 'value': 'esm_2'}], 'title': 'Model name', 'tooltip': 'Choose model'}, {'default_value': {'label': 'Fast', 'value': 'fast'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'mode', 'options': [{'label': 'Fast', 'value': 'fast'}, {'label': 'Standard', 'value': 'standard'}, {'label': 'Intensive', 'value': 'intensive'}], 'title': 'Auto Training Mode', 'tooltip': 'Choose âFastâ for quick results or for testing. Other modes should improve performance, but will take longer to train'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'tsv', 'txt'], 'title': '.csv', 'value': 'aligned fasta'}, 'dataStructure': 'CSV file containing the deep mutational scan', 'demoDataDetails': {'description': 'Beta-lactamase data from https://pubmed.ncbi.nlm.nih.gov/25723163/ The first 10 proteins are validation proteins used during method development, and the next 31 are test proteins.', 'fileName': 'BLAT_ECOLX_Ranganathan2015.csv', 'filePath': 'apps/meta_esm/BLAT_ECOLX_Ranganathan2015.csv', 'fileSource': [{'title': 'Data Source', 'url': 'test'}]}, 'disabled': False, 'name': 'train_path', 'title': 'Deep Mutational Scan', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
MetaESM: Protein Contact Prediction,Generate accurate protein contact predictions.,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">ESM-2 outperforms all tested single-sequence protein language models across a range of structure prediction tasks. There are many ways to define a protein contact. Here we're using the definition of 8 angstroms between carbon beta atoms. Note that the position of the carbon beta is imputed from the position of the N, CA, and C atoms for each residue. Inputs required: 1-10 .a3m files (aligned fasta).</span><br><br><span style=""font-weight: bold"">Example Use Case: </span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">predicting where amino acids at different points along a sequence are in close proximity. Contact maps are generated, which provide a 2D representation of the proximity of amino acids in 3D space. This can provide clues about protein function and 3D protein structure.</span></p>
<p><br><span style=""font-weight: bold"">Technology: </span><span style=""color: rgba(0,0,0,0.87); background-color: rgb(255,255,255)"">if CPU is selected when submitting the job, then the esm2_t12_35M_UR50D model will be used (35M parameters), while if GPU is selected, then the more powerful esm2_t33_650M_UR50D model will be used (650M parameters).Â </span></p>",Facebook Meta,"['3D Protein Structure Prediction', 'Structure Prediction', 'Proteomics', 'fasta', 'Computational Biology and Bioinformatics']",6384b0f32ffa50c6deecdb67,"[{'default_value': 'contact_prediction', 'hidden': True, 'input_type': 'user_input', 'name': 'app', 'title': 'app', 'tooltip': 'NA', 'type': 'object'}, {'default_value': {'label': 'Carbon beta atoms', 'value': 'carbon_beta_atoms'}, 'disabled': True, 'input_type': 'dropdown', 'name': 'contact_type', 'options': [{'label': 'Carbon beta atoms', 'value': 'carbon_beta_atoms'}, {'label': 'Calcium atoms', 'value': 'calcium_atoms'}], 'title': 'Contact type', 'tooltip': 'Choose contact type to model'}, {'default_value': {'label': 'ESM-2', 'value': 'esm_2'}, 'disabled': True, 'input_type': 'dropdown', 'name': 'model_name', 'options': [{'label': 'MSA Transformer', 'value': 'msa'}, {'label': 'ESM-2', 'value': 'esm_2'}], 'title': 'Model name', 'tooltip': 'Choose model'}]","[{'allowedFormats': {'fileExtensions': ['a3m'], 'title': '.a3m', 'value': 'aligned fasta'}, 'dataStructure': 'Please provide data in aligned fasta format (.a3m)', 'demoDataDetails': {'description': 'Primary citation for 1A3A: The structure of the Escherichia coli phosphotransferase IIAmannitol reveals a novel fold with two conformations of the active site. (https://pubmed.ncbi.nlm.nih.gov/9551558/). Structure information: https://www.ncbi.nlm.nih.gov/Structure/pdb/1A3A', 'fileName': '1a3a_1_A.a3m', 'filePath': 'apps/meta_esm/1a3a_1_A.a3m', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/facebookresearch/esm/tree/main/examples/data'}]}, 'disabled': False, 'name': 'file_1', 'title': 'File 1', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['a3m'], 'title': '.a3m', 'value': 'aligned fasta'}, 'dataStructure': 'Please provide data in aligned fasta format (.a3m)', 'demoDataDetails': {'description': 'Primary citation for 1XCR: Crystal structure of Homo sapiens PTD012 reveals a zinc-containing hydrolase fold (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2242484/). Structure information: https://www.ncbi.nlm.nih.gov/Structure/pdb/1XCR', 'fileName': '1xcr_1_A.a3m', 'filePath': 'apps/meta_esm/1xcr_1_A.a3m', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/facebookresearch/esm/tree/main/examples/data'}]}, 'disabled': False, 'name': 'file_2', 'optional': True, 'title': 'File 2 (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['a3m'], 'title': '.a3m', 'value': 'aligned fasta'}, 'dataStructure': 'Please provide data in aligned fasta format (.a3m)', 'demoDataDetails': {'description': 'Primary citation for 5AHW: A Universal Stress Protein (Usp) in Mycobacteria Binds Camp (https://pubmed.ncbi.nlm.nih.gov/25802331/). Structure information: https://www.ncbi.nlm.nih.gov/Structure/pdb/5AHW', 'fileName': '5ahw_1_A.a3m', 'filePath': 'apps/meta_esm/5ahw_1_A.a3m', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/facebookresearch/esm/tree/main/examples/data'}]}, 'disabled': False, 'name': 'file_3', 'optional': True, 'title': 'File 3 (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
MetaESM: Protein Variant Prediction,Generate accurate protein variant predictions.,"<p style=""text-align: start""><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">ESM-2 outperforms all tested single-sequence protein language models across a range of structure prediction tasks. This app has three stages. First, an embedding (fixed-dimensional vector representation) is obtained for each mutated sequence. Second, PCA is applied to reduce the number of dimensions prior to modelling. Third, a regression model is trained that can predict the mutation ""effect"" score given the embedding. Three types of model will be compared: random forests, support vector machines, and K nearest neighbours.</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""><br><br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-weight: bold"">Example Use Case</span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">: predicting the biological activity of mutations of a protein, using fixed embeddings from ESM. The output in this case describes scaled effect of the mutation.<br></span><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-size: 14px; font-family: Poppins, sans-serif""><br></span><span style=""color: rgba(0,0,0,0.87); background-color: rgb(255,255,255); font-weight: bold"">Technology</span><span style=""color: rgba(0,0,0,0.87); background-color: rgb(255,255,255)"">: if CPU is selected when submitting the job, then the esm2_t12_35M_UR50D model will be used (35M parameters), while if GPU is selected, then the more powerful esm2_t33_650M_UR50D model will be used (650M parameters).Â </span></p>",Facebook Meta,"['Variant Predictor', 'Proteomics', 'fasta', 'Computational Biology and Bioinformatics']",6384b3202ffa50c6deecdb6f,"[{'default_value': 'supervized_variant_prediction', 'hidden': True, 'input_type': 'user_input', 'name': 'app', 'title': 'app', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 50, 'increment': 1, 'input_type': 'slider', 'max_value': 150, 'max_value_included': True, 'min_value': 5, 'min_value_inclusive': True, 'name': 'PCA_components', 'title': 'PCA Components', 'tooltip': 'How many PCA components to detect in the data.', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['fasta'], 'title': '.fasta', 'value': 'fasta'}, 'dataStructure': 'Please provide data in fasta format', 'demoDataDetails': {'description': 'The data originally comes from a deep mutational scan and was released with the Envision paper (Gray, et al. 2018)', 'fileName': 'P62593.fasta', 'filePath': 'apps/meta_esm/P62593.fasta', 'fileSource': [{'title': 'Data Source', 'url': 'test'}]}, 'disabled': False, 'name': 'file_1', 'title': 'File 1', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Single Cell RNA-Seq Quality Control with AUTOZI,Check distribution and zero-inflation of an scRNA dataset,"<p>AutoZI is a deep generative model adapted from scVI allowing a gene-specific treatment of zero-inflation. Plots relating to batch effects and gene expression levels are also generated. Ideally, data should be provided in .h5ad format, which is native to the Anndata python package. Alternatively, .h5, .csv or.mtx files can be provided if their formatting is suitable.<br><span style=""font-size: 14px""><br></span><span style=""font-weight: bold"">Example use case:</span><span style=""font-size: 14px"">&nbsp;</span>In single-cell RNA sequencing data, biological processes or technical factors may induce an overabundance of zero measurements. Existing probabilistic approaches to interpreting these data either model all genes as zero-inflated, or none. But the overabundance of zeros might be gene-specific. AutoZI can distinguish between zero-inflated and non-zero inflated genes.</p>",scVI-Tools,"['Visualisation', 'Single-Cell Bioinformatics']",6384b4e12ffa50c6deecdb7a,"[{'default_value': 'autozi', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'object'}, {'default_value': 'autozi', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 1500, 'increment': 100, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1000, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 200, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Number of epochs used to train AutoZI model', 'type': 'integer'}, {'default_value': {'label': 'cell_type', 'value': 'cell_type'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'optional': False, 'options': [], 'title': 'Breakdown by', 'tooltip': 'Choose variable you want to see a breakdown by zero inflation'}, {'default_value': {'label': 'cell_source', 'value': 'cell_source'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'optional': True, 'options': [], 'title': 'Batch effect correction (optional)', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, .csv format', 'demoDataDetails': {'description': 'Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations. Dataset was filtered down randomly to 20k cells.', 'fileName': 'heart_atlas.h5ad', 'filePath': 'apps/scvi_tools/resources/heart_atlas.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.heartcellatlas.org/#DataSources'}], 'previewFileName': 'apps/scvi_tools/resources/heart_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Single Cell LDVAE,LDVAE produces a generative model comparable to probabilistic PCA or factor analysis,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">LDVAE (Linearly-decoded Variational Auto-encoder, also called Linear scVI) is a flavor of scVI with a linear decoder.<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">The advantages of LDVAE are: (i) Can be used to interpret latent dimensions with factor loading matrix. (ii) Scalable to very large datasets (>1 million cells).<br></span><br><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">The limitations of LDVAE include: (i) Less capacity than scVI differential expression or scANVI for annotation, which use a neural network decoder. (ii) Less capable of integrating data with complex batch effects.Â </span></p>",scVI-Tools,"['Dimensionality Reduction', 'h5', 'h5ad', 'csv', 'Single-Cell Bioinformatics']",6384b5c52ffa50c6deecdb86,"[{'default_value': 'ldvae', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': 'ldvae', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 20, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'n_latent', 'title': 'Number of Latent Variables', 'tooltip': 'The number of latent variables', 'type': 'integer'}, {'default_value': 1500, 'increment': 100, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1000, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 300, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'LDVAE Epochs', 'tooltip': 'Number of epochs used to train LDVAE model', 'type': 'integer'}, {'default_value': 128, 'increment': 1, 'input_type': 'slider', 'max_value': 512, 'max_value_included': True, 'min_value': 8, 'min_value_inclusive': True, 'name': 'n_hidden', 'title': 'Number of Hidden Variables', 'tooltip': 'The number of hidden variables', 'type': 'integer'}, {'default_value': 1, 'increment': 1, 'input_type': 'slider', 'max_value': 3, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'n_layers', 'title': 'Number of Layers', 'tooltip': 'The number of layers', 'type': 'integer'}, {'decimalPlace': 2, 'default_value': 0.1, 'increment': 0.1, 'input_type': 'slider', 'max_value': 0.5, 'max_value_included': True, 'min_value': 0, 'min_value_inclusive': True, 'name': 'dropout_rate', 'title': 'dropout_rate', 'tooltip': 'The dropout rate within the neural network', 'type': 'float'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, .csv format', 'demoDataDetails': {'description': 'Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations. Dataset was filtered down randomly to 20k cells.', 'fileName': 'heart_atlas.h5ad', 'filePath': 'apps/scvi_tools/resources/heart_atlas.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.heartcellatlas.org/#DataSources'}], 'previewFileName': 'apps/scvi_tools/resources/heart_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Single Cell Assign,CellAssign predict cell types for each cell using known cell-type-specific gene markers.,"<p>CellAssign is a simple yet, efficient approach for annotating scRNA-seq data in the scenario in which cell-type-specific gene markers are known. The method also allows users to control for nuisance covariates like batch or donor. The scvi-tools implementation of CellAssign uses stochastic inference, such that CellAssign will scale to very large datasets.</p>
<p>The advantages of CellAssign are: (i) Lightweight model that can be fit quickly, (ii) Ability to control for nuisance factors.</p>
<p>The limitations of CellAssign include: (i) Requirement for a cell types by gene markers binary matrix, (ii) The simple linear model may not handle non-linear batch effects.</p>",scVI-Tools,"['Classification', 'h5ad', 'csv', 'Single-Cell Bioinformatics']",638775cb2ffa50c6deecdc36,"[{'default_value': 'cell_assign', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 'training', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'task', 'type': 'object'}, {'default_value': 400, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Number of epochs used to train cell assign model', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv (multiple files)', 'value': ''}, 'dataStructure': 'Data should be in .h5ad format. Columns for covariate comparisons should be included in the dataset.', 'demoDataDetails': {'description': 'Single cell data for follicular lymphoma.', 'fileName': 'sce_follicular_annotated_final.h5ad', 'filePath': 'apps/scvi_tools/resources/sce_follicular_annotated_final.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.nature.com/articles/s41592-019-0529-1'}], 'previewFileName': 'apps/scvi_tools/resources/sce_follicular_annotated_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'tsv', 'txt'], 'title': '.tsv, .txt, or .csv', 'value': ''}, 'dataStructure': ""Data should be in .csv or .tsv format. Binary 1's and 0's should indicate which genes are associated with which cell types."", 'demoDataDetails': {'description': 'Marker gene matrix for follicular lymphoma data.', 'fileName': 'FL_celltype.csv', 'filePath': 'apps/scvi_tools/resources/FL_celltype.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.nature.com/articles/s41592-019-0529-1'}], 'previewFileName': 'apps/scvi_tools/resources/FL_celltype.csv'}, 'disabled': False, 'name': 'marker_path', 'title': 'Gene Marker Matrix', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
GrapHiC: Imputing missing Hi-C reads with graph-based approach,GrapHiC is a Hi-C imputation framework that imputes Hi-C contact matrices using a conditional Graph Autoencoder Network.,"<p>The three-dimensional (3D) architecture of the genome at various structural scales can be comprehended and investigated by scientists using Hi-C, a high-throughput chromosomal conformation capture technique. Generally, Hi-C experiment data is stored in a contact map of sizeÂ <em>N Ã N</em>. Each row and column correspond to fixed-widthÂ <em>N</em> windows (âbinsâ) in the range of 1 kbps to 1 mbps. The examination of these contact maps revealed significant structural features such as topologically associated domains (TADs).<br><br>Building high-resolution Hi-C contact maps often necessitate billions of reads, which is often impossible. GrapHiC imputes Hi-C contact maps by reformulating the Hi-C data as a position-aware graph, using less expensive ChIP-seq signals, and proposing a generative graph-autoencoder that first encodes the input graph into a latent representation.<br><br><strong>Example use case:</strong>  Imputation of Hi-C data<br><br><strong>Technology:</strong> Graph Auto-Encoder (GAE)<br><br><strong>Limitation:</strong><br>- Some of the parameters were left as default. Please check this <a href=""https://github.com/rsinghlab/GrapHiC/blob/main/parameters.py"" target=""_blank"">page</a> for more information.<br><br><strong>Metrics:</strong> Detailed metrics of the study can be found in <a href=""https://www.biorxiv.org/content/10.1101/2022.10.19.512942v2.supplementary-material"" target=""_blank"">the supplementary file</a>. <br><br><strong>Epigenetic Features:</strong><br><br><strong>All: </strong>['RAD-21', 'RNA-Pol2','CTCF', 'DNASE-Seq', 'H3K27ME3', 'H3K27AC', 'H3K36ME3', 'H3K4ME1', 'H3K4ME2', 'H3K4ME3', 'H3K79ME2', 'H3K9AC', 'H4K20ME1', 'H3K9ME3']<br><strong>DNA-Acessibility: </strong>['RAD-21', 'RNA-Pol2','CTCF', 'DNASE-Seq']<br><strong>Repression-Marker</strong>: ['H3K27ME3', 'H3K4ME2', 'H4K20ME1']<br><strong>Activating-Marker: </strong>['H3K4ME3', 'H3K9AC', 'H3K9ME3']<br><strong>Enchancer-Interaction-Marker:</strong> ['H3K36ME3', 'H3K79ME2']<br><strong>Gene-Related: </strong>['H3K36ME3', 'H3K79ME2']<br><strong>HiC-Reg-Reduced:</strong> ['CTCF', 'DNASE-Seq', 'H4K20ME1', 'H3K27ME3', 'H3K9ME3', 'H3K9AC', 'H3K4ME1', 'H3K27AC']</p>
","GhulamÂ Murtaza,Â JustinÂ Wagner,Â Justin M.Â Zook,Â RitambharaÂ Singh","['Graph Auto Encoder(GAE)', 'Hi-C', 'Computational Biology and Bioinformatics']",63888da92ffa50c6deecdca2,"[{'default_value': 100, 'increment': 1, 'input_type': 'user_input', 'max_value': 1000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'epoch', 'title': 'Epoch', 'tooltip': 'Epoch means one complete pass of the training dataset through the algorithm. Please specify epoch number for your experiment.', 'type': 'integer'}, {'default_value': 'GM12878-encode-0', 'input_type': 'user_input', 'name': 'base', 'title': 'Base', 'tooltip': 'Please specify the name of .hic file that you are interested has a low-read count as a real-world case. (that will be used for retraining in the algorithm). The given input name must exist in the dataset file. Please also specify the folder name before the file name as in the example. <GM12878> is folder name <encode-0> file name.(Please use dash between folder and file name)', 'type': 'string'}, {'default_value': 'GM12878-geo-raoetal', 'input_type': 'user_input', 'name': 'target', 'title': 'Target', 'tooltip': 'Please specify the name of .hic file that has high-read count matrices as a target. The given input name must exist in the dataset file. Please also specify the folder name before the file name as in the example. <GM12878> is folder name <geo-raoetal> file name. (Please use dash between folder and file name)', 'type': 'string'}, {'default_value': {'label': 'All', 'value': 'All'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'epi_features', 'options': [{'label': 'All', 'value': 'All'}, {'label': 'DNA-Acessibility', 'value': 'DNA-Acessibility'}, {'label': 'Repression-Marker', 'value': 'Repression-Marker'}, {'label': 'Activating-Marker', 'value': 'Activating-Marker'}, {'label': 'Enchancer-Interaction-Marker', 'value': 'Enchancer-Interaction-Marker'}, {'label': 'Gene-Related', 'value': 'Gene-Related'}, {'label': 'HiC-Reg-Reduced', 'value': 'HiC-Reg-Reduced'}, {'label': 'RAD-21', 'value': 'RAD-21'}, {'label': 'RNA-Pol2', 'value': 'RNA-Pol2'}, {'label': 'CTCF', 'value': 'CTCF'}, {'label': 'DNASE-Seq', 'value': 'DNASE-Seq'}, {'label': 'H3K27ME3', 'value': 'H3K27ME3'}, {'label': 'H3K27AC', 'value': 'H3K27AC'}, {'label': 'H3K36ME3', 'value': 'H3K36ME3'}, {'label': 'H3K4ME1', 'value': 'H3K4ME1'}, {'label': 'H3K4ME2', 'value': 'H3K4ME2'}, {'label': 'H3K4ME3', 'value': 'H3K4ME3'}, {'label': 'H3K79ME2', 'value': 'H3K79ME2'}, {'label': 'H3K9AC', 'value': 'H3K9AC'}, {'label': 'H4K20ME1', 'value': 'H4K20ME1'}, {'label': 'H3K9ME3', 'value': 'H3K9ME3'}, {'label': 'None', 'value': 'None'}], 'title': 'Epigenetic Features', 'tooltip': 'Please specify the epigenetic factor(s)(e.g. ChIP-seq signals) that assists the model in imputing Hi-C reads. Some group of factors shown above.'}, {'default_value': 'GM12878-encode-0,GM12878-encode-1,GM12878-encode-2,GM12878-geo-026,GM12878-geo-033', 'input_type': 'user_input', 'name': 'base_file_list', 'title': 'HIC File List', 'tooltip': 'Please specify other .hic files that to be imputed. File name should be specify in following format: <FolderName-FileName> (e.g. <GM12878> is folder name <encode-0> is file name.). Multiple .hic file names can be specified here by using comma as in the example.', 'type': 'string'}, {'default_value': 'K562', 'input_type': 'user_input', 'name': 'cell_line_name', 'title': 'Epigenetic Cell Line Name', 'tooltip': 'Please specify the epigenetic factor of cell line name that you used in experiment here. Input must be the exact folder name in the .tar.gz file. For example, you have epigenetic_features.tar.gz file and in that file you have folder name is K562 you must write this folder name here.', 'type': 'string'}, {'default_value': 10000, 'input_type': 'user_input', 'name': 'hic_data_resolution', 'title': 'HIC Data Resolution', 'tooltip': 'Please specify the Hi-C data resolution. One of the most crucial variables for Hi-C data analysis is resolution, which is also known as the bin size of the Hi-C interaction matrix.', 'type': 'integer'}, {'default_value': 27, 'input_type': 'user_input', 'name': 'input_embedding_size', 'title': 'Embedding Size', 'tooltip': 'Pleae specify the embedding size. The number of filters in every decoder residual block and the size of the node encodings across all encoder layers are represented by the embedding size.', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['.tar.gz'], 'title': '.tar.gz', 'value': ''}, 'dataStructure': 'Dataset file should be provided in .tar.gz format. In tar.gz file, there must be one folder that contains .hic files. An indexed binary format called .hic was created to provide quick random access to contact matrix heatmaps.', 'demoDataDetails': {'description': 'GM12878 Hi-C dataset is used for demo as in the article. All files were downloaded and compressed in one file.You can see the file links by clicking Data Source.', 'fileName': 'GM12878.tar.gz', 'filePath': 'apps/graphic/resources/GM12878.tar.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/rsinghlab/GrapHiC/blob/main/src/utils.py'}]}, 'disabled': False, 'name': 'hic_dataset_1', 'title': 'Upload HiC Dataset', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tar.gz'], 'title': '.tar.gz', 'value': ''}, 'dataStructure': 'Dataset file should be provided in .tar.gz format. In tar.gz file, there must be one folder that contains .bigwig files. File names in folder must contain same name in epigenetic feautures. File names cannot be random names. For example, you have <H3K4ME1> epigenetic factor in your dataset and .bigWig file name should be the same (e.g. H3K4ME1.bigwig, DNASE-Seq.bigwig). Genome-wide signal data are stored in BigWig files, a compressed, indexed, binary format used for calculations (like GC percent) or studies (like ChIP-seq/RNA-seq read depth).', 'demoDataDetails': {'description': 'K562 cell line is used for demo as in the article as well. All files were downloaded and compressed in one file. You can see the file links by clicking Data Source.', 'fileName': 'K562_epigenetic.tar.gz', 'filePath': 'apps/graphic/resources/K562_epigenetic.tar.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/rsinghlab/GrapHiC/blob/main/src/utils.py'}]}, 'disabled': False, 'name': 'epigenetic_dataset_1', 'title': 'Upload Epigenetic Dataset', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}]"
Single Cell Assign: HGSC Inference,A pretrained model for generating high-grade serous carcinoma (HGSC) cell type predictions,"<p>High-grade serous carcinoma (HGSC) is a type of tumour that arises from the serous epithelial layer in the abdominopelvic cavity and is mainly found in the ovary. This pretrained model can be used to generate cell type predictions, based on precalculated gene-cell associations. <span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">Note that the marker genes must be present in the uploaded dataset.Â </span></p>",scVI-Tools,"['Classification', 'h5ad', 'Single-Cell Bioinformatics']",63889e612ffa50c6deecdcbd,"[{'default_value': 'cell_assign', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 'inference', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'task', 'type': 'object'}, {'default_value': '6388a9312ffa50c6deecdcce', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'source_job_id', 'type': 'object'}, {'default_value': 400, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Number of epochs used to train cell assign model', 'type': 'integer'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'optional': True, 'options': [], 'title': 'Batch effect correction (optional)', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv (multiple files)', 'value': ''}, 'dataStructure': 'Data should be in .h5ad format. Columns for covariate comparisons should be included in the dataset.', 'demoDataDetails': {'description': 'Single cell data for follicular lymphoma.', 'fileName': 'sce_hgsc_annotated_final.h5ad', 'filePath': 'apps/scvi_tools/resources/sce_hgsc_annotated_final.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.nature.com/articles/s41592-019-0529-1'}], 'previewFileName': 'apps/scvi_tools/resources/sce_follicular_annotated_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Single Cell Assign: Follicular Lymphoma Inference,A pretrained model for generating follicular lymphoma cell type predictions,"<p>Follicular lymphoma is the most common type of of low-grade non-Hodgkin lymphoma (NHL). It develops when white blood cells cluster together to form lumps in lymph glands or organs. There are two main types of lymphoma: Hodgkin lymphoma and non-Hodgkin lymphoma. <span style=""color: rgb(0,0,0); background-color: rgb(255,255,255); font-family: Poppins, sans-serif"">This pretrained model can be used to generate cell type predictions, based on precalculated gene-cell associations. Note that the marker genes must be present in the uploaded dataset.</span></p>",scVI-Tools,"['Classification', 'h5ad', 'Single-Cell Bioinformatics']",63889f942ffa50c6deecdcbe,"[{'default_value': 'inference', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'task', 'type': 'object'}, {'default_value': 'cell_assign', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': '6388a8fd2ffa50c6deecdccb', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'source_job_id', 'type': 'object'}, {'default_value': 400, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Epochs', 'tooltip': 'Number of epochs used to train cell assign model', 'type': 'integer'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'optional': True, 'options': [], 'title': 'Batch effect correction (optional)', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv (multiple files)', 'value': ''}, 'dataStructure': 'Data should be in .h5ad format. Columns for covariate comparisons should be included in the dataset.', 'demoDataDetails': {'description': 'Single cell data for follicular lymphoma.', 'fileName': 'sce_follicular_annotated_final.h5ad', 'filePath': 'apps/scvi_tools/resources/sce_follicular_annotated_final.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.nature.com/articles/s41592-019-0529-1'}], 'previewFileName': 'apps/scvi_tools/resources/sce_follicular_annotated_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Stereoscope for Spatial Transcriptomics,"Stereoscope can stratify cells into discrete cell types, providing spatial representations of each","<p>Stereoscope posits a probabilistic model of spatial transcriptomics and an associated method for the deconvoluton of cell type profiles using a single-cell RNA sequencing reference dataset.<br><br>The advantages of Stereoscope are: (i) Can stratify cells into discrete cell types, (ii) Scalable to very large datasets (>1 million cells).<br><br>Stereoscope requires training two latent variable models (LVMs): one for the single-cell reference dataset and one for the spatial transcriptomics dataset, which incorporates the learned parameters of the single-cell reference LVM. The first LVM takes in as input a scRNA-seq gene expression matrix of UMI counts with cells and genes, along with a vector of cell type labels. Subsequently, the second LVM takes in the learned parameters of the first LVM, along with a spatial gene expression matrix with spots and genes. This matrix should be uploaded as a csv file with gene names, 3D location, and tissue values in different columns.<br><br><span style=""font-weight: bold"">Example use case: </span>Train a probabilistic model of spatial transcriptomics (measure all the gene activity in a tissue sample and map where the activity is occurring) and an associated method for the deconvoluton of cell type profiles (estimating the proportions of different cell types in samples collected from a tissue) using a single-cell RNA sequencing reference dataset.<br><br><span style=""font-weight: bold"">Limitations:</span> Effectively requires a GPU for fast inference.</p>",scVI-Tools,"['DGE Analysis', 'Structure Prediction', 'Spatial Transcriptomics', 'h5ad', 'Transcriptomics']",638fa7232ffa50c6deecde34,"[{'default_value': 'stereoscope', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': {'label': 'cell_states', 'value': 'cell_states'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target (labels)', 'tooltip': 'Choose variable representing the entity of interest (typically cell type)'}, {'default_value': 'stereoscope', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 6000, 'increment': 100, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1000, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 100, 'increment': 10, 'input_type': 'slider', 'max_value': 500, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'sc_epochs', 'title': 'RNA-seq Model Training Epochs', 'tooltip': 'Number of epochs used to train RNA-seq model', 'type': 'integer'}, {'default_value': 2000, 'increment': 100, 'input_type': 'slider', 'max_value': 4000, 'max_value_included': True, 'min_value': 100, 'min_value_inclusive': True, 'name': 'st_epochs', 'title': 'Spatial Model Training Epochs', 'tooltip': 'Number of epochs used to train spatial model', 'type': 'integer'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'options': [], 'title': 'Batch effect correction', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, .mtx, or .csv format', 'demoDataDetails': {'description': 'Adult heart-cell atlas data from LitviÅukovÃ¡ et al (2020).', 'fileName': 'hca_heart_LV_stereoscope_subset_raw_ctl201217.h5ad', 'filePath': 'apps/scvi_tools/resources/hca_heart_LV_stereoscope_subset_raw_ctl201217.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://ndownloader.figshare.com/files/26153564'}]}, 'disabled': False, 'name': 'sc_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Data should have an .h5, .h5ad, .mtx, or .csv extension, and should follow 10x genomics file format', 'demoDataDetails': {'description': 'Gene expression matrix from 10x Genomics', 'fileName': 'filtered_feature_bc_matrix.h5', 'filePath': 'apps/scvi_tools/resources/filtered_feature_bc_matrix.h5', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.10xgenomics.com/resources/datasets?menu%5Bproducts.name%5D=Spatial%20Gene%20Expression&query=&page=1&configure%5Bfacets%5D%5B0%5D=chemistryVersionAndThroughput&configure%5Bfacets%5D%5B1%5D=pipeline.version&configure%5BhitsPerPage%5D=500&configure%5BmaxValuesPerFacet%5D=1000'}]}, 'disabled': False, 'name': 'st_path', 'supportsPreview': True, 'title': 'Visium Spatial Transcriptomic Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'tsv', 'txt'], 'title': '.tsv, .txt, or .csv', 'value': ''}, 'dataStructure': 'Data should be in .csv or .tsv format. Gene names should be in first column, 3D location in 2nd-4th columns, and tissue values in 5th-6th columns.', 'demoDataDetails': {'description': 'Tissue location matrix for 10x genomics dataset.', 'fileName': 'tissue_positions_list.csv', 'filePath': 'apps/scvi_tools/resources/tissue_positions_list.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.10xgenomics.com/resources/datasets?menu%5Bproducts.name%5D=Spatial%20Gene%20Expression&query=&page=1&configure%5Bfacets%5D%5B0%5D=chemistryVersionAndThroughput&configure%5Bfacets%5D%5B1%5D=pipeline.version&configure%5BhitsPerPage%5D=500&configure%5BmaxValuesPerFacet%5D=1000'}]}, 'disabled': False, 'name': 'tissue_path', 'title': 'Tissue Position Matrix', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
SynthSeg: Contrast-agnostic Segmentation of Brain MRI,Segmentation of MRI brain scans of any contrast and resolution into 60 separate structures,"<p>SynthSeg is the first convolutional neural network for segmentation of brain scans of any contrast and resolution that works out-of-the-box, without retraining or fine-tuning. SynthSeg relies on a single model, which is robust to a wide array of subject populations: from young and healthy to ageing and diseased subjects, white matter lesions, scans with or without preprocessing, including bias field corruption, skull stripping, intensity normalisation, template registration, etc.<br><br><strong>Example use case: </strong>SynthSeg can segment real scans of any target domain, which enables analysis of huge amounts of heterogeneous clinical data.<br><br><strong>Technology: </strong>Convoluional neural network<br><br><strong>Metrics: </strong>Trained on a synthetic dataset. Obtains a dice score of &gt; 0.85 on most availiable brain MRI datasets</p>
",Benjamin Billot et. al.,"['Multi-organ Segmentation', 'Anatomy', 'nii.gz', 'Biomedical Image Analysis and Interpretation']",6390aef32ffa50c6deecde89,"[{'default_value': False, 'input_type': 'checkbox', 'name': 'robust', 'title': 'Robust', 'optional': True, 'tooltip': 'Check this box to use a more robust model for when (for example) analysing clinical data with large space spacing.'}, {'default_value': False, 'input_type': 'checkbox', 'name': 'parc', 'title': 'Cortical parcellation', 'optional': True, 'tooltip': 'Check this box to perform cortical parcellation in addition to whole-brain segmentation.'}]","[{'allowedFormats': {'fileExtensions': ['nii', 'nii.gz', 'gz'], 'title': '.nii, .nii.gz', 'value': ''}, 'dataStructure': 'Your file should be a single scan in .nii or .nii.gz format, any resolution or contrast is fine.', 'demoDataDetails': {'description': 'MR Session: HC_001_MR. Brain MRI of right handed, 13 year old male. Field strength 1.5T', 'fileName': 'anat.nii.gz', 'filePath': 'apps/synthseg/anat.nii.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.nitrc.org/ir/app/action/DisplayItemAction/search_element/xnat%3AmrSessionData/search_field/xnat%3AmrSessionData.ID/search_value/xnat_E02685/popup/false/project/cs_schizbull08'}]}, 'disabled': False, 'name': 'data', 'title': 'Upload Brain Scan', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
CITE-seq Analysis with totalVI,totalVI (total Variational Inference) models CITE-seq RNA and protein data,"<p><span style=""color: rgb(0,0,0); background-color: rgb(255,255,255)"">totalVI (total Variational Inference) provides a flexible generative model of CITE-seq RNA and protein data that can be used for many common downstream tasks.<br><br>The advantages of totalVI are: (i) Comprehensive in capabilities. (ii) Scalable to very large datasets (>1 million cells).<br><br>Data should include the protein expression matrix, with one row per observation, and one column per protein.</span><br><br><span style=""font-weight: bold"">Example use case: </span>Train a generative model of CITE-seq RNA and protein data that can be used for many common downstream tasks.<br><br><span style=""font-weight: bold"">Limitations:</span> Effectively requires a GPU for fast inference. And, difficult to understand the balance between RNA and protein data in the low-dimensional representation of cells.</p>",scVI-Tools,"['Dimensionality Reduction', 'Differential Protein Expression', 'Omics', 'Proteomics', 'h5ad', 'h5', 'Single-Cell Bioinformatics']",63925fd72ffa50c6deecdef4,"[{'default_value': 'totalvi', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': 1000, 'increment': 100, 'input_type': 'slider', 'max_value': 4000, 'max_value_included': True, 'min_value': 100, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 200, 'increment': 10, 'input_type': 'slider', 'max_value': 800, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'totalVI Max Epochs', 'tooltip': 'Number of epochs used to train totalVI model', 'type': 'integer'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 32, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'n_latent', 'title': 'Number of Latent Variables', 'tooltip': 'The number of latent variables', 'type': 'integer'}, {'default_value': {'label': 'Normal distribution', 'value': 'normal'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'latent_distribution', 'options': [{'label': 'Normal distribution', 'value': 'normal'}, {'label': 'Logistic normal distribution', 'value': 'ln'}], 'title': 'Latent Distribution', 'tooltip': 'Distribution assumed for latent variables'}, {'default_value': {'label': 'Negative binomial distribution', 'value': 'nb'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'gene_likelihood', 'options': [{'label': 'Negative binomial distribution', 'value': 'nb'}, {'label': 'Zero-inflated negative binomial distribution', 'value': 'zinb'}], 'title': 'Gene Likelihood', 'tooltip': 'Distribution assumed for latent variables'}, {'default_value': {'label': 'protein_expression', 'value': 'protein_expression'}, 'disabled': False, 'input_type': 'user_input', 'name': 'protein_key', 'title': 'Protein Expression Key', 'tooltip': 'Provide name of matrix which contains protein expression values'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'options': [], 'title': 'Batch effect correction', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, .mtx, or .csv format', 'demoDataDetails': {'description': 'Immune cells from the murine (mouse) spleen and lymph nodes. See https://www.nature.com/articles/s41592-020-01050-x', 'fileName': 'spleen_lymph_cite_seq.h5ad', 'filePath': 'apps/scvi_tools/resources/spleen_lymph_cite_seq.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/YosefLab/totalVI_reproducibility'}]}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DestVI for Spatial Transcriptomics,DestVI models variation within cell types,"<p>DestVI (Deconvolution of Spatial Transcriptomics profiles using Variational Inference) posits a conditional generative model of spatial transcriptomics down to the sub-cell-type variation level which can be used to explore the spatial organization of a tissue and understanding gene expression variation between tissues and conditions.<br>The advantages of DestVI are: (i) Can stratify cells into discrete cell types and model continuous sub-cell-type variation, (ii) Scalable to very large datasets (>1 million cells).<br><br><span style=""font-weight: bold"">Example use case:</span> Deconvolution of, for example, 10x Visium spatial transcriptomics profiles using an accompanying single-cell RNA sequencing data.<br><br><span style=""font-weight: bold"">Limitations:</span> Effectively requires a GPU for fast inference.</p>",scVI-Tools,"['DGE Analysis', 'Structure Prediction', 'Spatial Transcriptomics', 'h5', 'h5ad', 'Transcriptomics']",6392629b2ffa50c6deecdefa,"[{'default_value': 'destvi', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': {'label': 'broad_cell_types', 'value': 'broad_cell_types'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target (labels)', 'tooltip': 'Choose variable representing the entity of interest (typically cell type)'}, {'default_value': 4000, 'increment': 100, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1000, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 100, 'increment': 10, 'input_type': 'slider', 'max_value': 500, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'sc_epochs', 'title': 'RNA-seq Model Training Epochs', 'tooltip': 'Number of epochs used to train RNA-seq model', 'type': 'integer'}, {'default_value': 1000, 'increment': 100, 'input_type': 'slider', 'max_value': 4000, 'max_value_included': True, 'min_value': 100, 'min_value_inclusive': True, 'name': 'st_epochs', 'title': 'Spatial Model Training Epochs', 'tooltip': 'Number of epochs used to train spatial model', 'type': 'integer'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'batch_effect', 'options': [], 'title': 'Batch effect correction', 'tooltip': 'Choose variable to correct for batch effects'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, .mtx, or .csv format', 'demoDataDetails': {'description': 'Lopez et al. (2022) profiled immune cells from murine lymph nodes with 10x Chromium, as a control / case study to study the immune response to exposure to a mycobacteria', 'fileName': 'scRNA-LN-compressed.h5ad', 'filePath': 'apps/scvi_tools/resources/scRNA-LN-compressed.h5ad', 'previewFileName': 'apps/scvi_tools/resources/scRNA-LN-compressed_sample.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/romain-lopez/DestVI-reproducibility/blob/master/lymph_node/deconvolution/'}]}, 'disabled': False, 'name': 'sc_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Data should have an .h5, .h5ad, .mtx, or .csv extension, and should include spatial transcriptomic data', 'demoDataDetails': {'description': 'Lopez et al. (2022) profiled immune cells from murine lymph nodes with 10x Chromium, as a control / case study to study the immune response to exposure to a mycobacteria', 'fileName': 'ST-LN-compressed.h5ad', 'filePath': 'apps/scvi_tools/resources/ST-LN-compressed.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/romain-lopez/DestVI-reproducibility/blob/master/lymph_node/deconvolution/'}], 'previewFileName': 'apps/scvi_tools/resources/ST-LN-compressed_sample.h5ad'}, 'disabled': False, 'name': 'st_path', 'supportsPreview': True, 'title': 'Spatial Transcriptomic Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DiffSBDD: Structure-based Drug Design with Equivariant Diffusion Models,Generate small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets using AI diffusion.,"<p>Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. This app generates small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets using AI diffusion.<br><br><strong>Example use case:</strong> Generate ligands for a binding pocket inside a target of interest to elcit a desired therapeutic effect<br> <br><strong>Technology: </strong>E(3)-equivariant 3D-conditional diffusion</p>
","Arne Schneuing, Yuanqi Du, et. al.","['Diffusion', 'Drug Discovery', 'Drug Discovery and Design']",639730e62ffa50c6deecdf9c,"[{'default_value': '', 'input_type': 'user_input', 'name': 'residue_list', 'title': 'List of Residues', 'tooltip': 'Provide a list where each residue is specified as <chain_id>:<res_id>, e.g, A:1 A:2 A:3 A:4 A:5 A:6 A:7. Leave this field blank if you instead fill in the parameter below'}, {'default_value': 'A:330', 'input_type': 'user_input', 'name': 'reference_ligand', 'title': 'Reference Ligands', 'tooltip': 'If the uploaded PDB structure contains a reference ligand in the target pocket, you can specify its location as <chain_id>:<res_id> and the pocket will be extracted automatically. Leave this field blank if you fill in the above parameter'}, {'decimalPlace': 0, 'default_value': 10, 'input_type': 'slider', 'max_value': 100, 'min_value': 1, 'name': 'n_samples', 'title': 'Number of samples', 'tooltip': 'Number of ligands to generate'}, {'decimalPlace': 0, 'default_value': 20, 'input_type': 'slider', 'max_value': 200, 'min_value': 10, 'name': 'ligand_nodes', 'title': 'Number of ligand nodes', 'tooltip': 'Number of nodes the generated ligands will have'}, {'default_value': {'label': 'Conditional full atom', 'value': 'conditional_full_atom'}, 'input_type': 'dropdown', 'name': 'model', 'options': [{'label': 'Conditional full atom', 'value': 'conditional_full_atom'}, {'label': 'In painting', 'value': 'inpaint_ca'}], 'title': 'Model', 'tooltip': ""'Conditional full atom' receives a fixed pocket representation as context in each denoising step, and 'In painting' approximates the joint distribution of ligand-pocket pairs combined with inpainting at inference time""}, {'decimalPlace': 0, 'default_value': 100, 'increment': 50, 'input_type': 'slider', 'max_value': 1000, 'min_value': 1, 'name': 'timesteps', 'title': 'Time steps', 'tooltip': 'Number of time steps to run the generation of each ligand for (more time steps means longer execution time)'}, {'decimalPlace': 0, 'default_value': 1, 'input_type': 'slider', 'max_value': 100, 'min_value': 1, 'name': 'resamplings', 'title': 'Resamplings', 'tooltip': ""This parameter only applies when using the 'in painting' model""}, {'decimalPlace': 0, 'default_value': 1, 'input_type': 'slider', 'max_value': 100, 'min_value': 1, 'name': 'jump_length', 'title': 'Jump length', 'tooltip': ""This parameter only applies when using the 'in painting' model""}, {'default_value': False, 'input_type': 'checkbox', 'name': 'keep_all_fragments', 'title': 'Keep all fragments', 'optional': True, 'tooltip': 'Keep all disconnected fragments of generated ligands'}, {'default_value': True, 'input_type': 'checkbox', 'name': 'sanitize', 'title': 'Sanitize', 'optional': True, 'tooltip': 'Sanitize molecules (invalid molecules will be removed if this flag is present)'}, {'default_value': True, 'input_type': 'checkbox', 'name': 'relax', 'title': 'Relax', 'optional': True, 'tooltip': 'Relax generated structure in force field'}]","[{'allowedFormats': {'fileExtensions': ['pdb'], 'title': 'pdb', 'value': ''}, 'dataStructure': 'A single protein in an pdb file.', 'demoDataDetails': {'description': 'Structure of 3RFM in a pdb', 'fileName': '3rfm.pdb', 'filePath': 'apps/diffsbdd/input.pdb', 'fileSource': [{'title': 'Data Source', 'url': 'http://files.rcsb.org/download/3rfm.pdb'}]}, 'disabled': False, 'name': 'data', 'title': 'Upload protein structure', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepFRI:Structure-Based Function Prediction using Graph Convolutional Networks,DeepFRI is a Graph Convolutional Networks (GCN)-based method for predicting the functions of protein sequences and structures.,"<p>One of the most significant biological challenges in the post-genomic era is understanding the functional roles and investigating the mechanisms of newly found proteins. A deep learning technique called DeepFRI uses both sequences and contact map representations of 3D structures to predict protein function. The protein structures from the PDB and SWISS-MODEL are used to train DeepFRI. LSTM-LM(Long Short-Term Memory Language Model) was used to learn features from protein sequences and GCN was used to discover features from contact maps.<br><br><strong>Example use case:</strong>  Predicting protein functions<br><br><strong>Technology:</strong> Graph Convolutional Networks (GCN), LSTM-LM<br><br><strong>Limitation: </strong>Some of the options to predict protein functions are currently not available. Please check this <a href=""https://github.com/flatironinstitute/DeepFRI"" target=""_self"">page</a> for more information.<br><br><strong>Metrics:</strong> Some of the metrics related to work can be found <a href=""https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-021-23303-9/MediaObjects/41467_2021_23303_MOESM1_ESM.pdf"" target=""_self"">here</a></p>
","GligorijeviÄ, V., Renfrew, P.D., Kosciolek, T.Â et al.","['Graph Convolutional Network', 'Protein', 'fasta', 'Computational Biology and Bioinformatics']",63988c622ffa50c6deece042,"[{'default_value': {'label': 'Molecular Function', 'value': 'mf'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'ontology', 'options': [{'label': 'GO-Molecular Function', 'value': 'mf'}, {'label': 'GO-Biological Process', 'value': 'bp'}, {'label': 'GO-Cellular Component', 'value': 'cc'}, {'label': 'Enzyme Commission Number', 'value': 'ec'}], 'title': 'Ontology Type', 'tooltip': 'To characterize many facets of protein functioning, GeneOntology (GO)\xa0organizes proteins into hierarchically related functional classes grouped into three separate ontologies: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC). Based on the chemical reactions that enzymes catalyze, the Enzyme Commission number (EC number) is a system of numerical classification for enzymes. Every EC number in the system of enzyme nomenclature has a suggested name for the corresponding enzyme-catalyzed reaction.'}]","[{'allowedFormats': {'fileExtensions': ['fasta', 'npz', 'pdb'], 'title': '.fasta/.npz/.pdb', 'value': ''}, 'dataStructure': 'Three file formats are acceptable as input. For the FASTA file, multiple amino acid sequences can be specified. You can see an example structure below.\n>protein1\nAKSMDTTDIGAFâ¦\n>protein\nKPVTLYDIAGFFAâ¦\nFor contact maps prediction, file format should be in .npz format. The .npz file format is a compressed collection of files with variable-based names. In the .npz compressed file, there should be .npy files in the example. For example, there are three .npy files inside the .npz file (C_alpha.npy, C_beta.npy and seqres.npy). For more detail please check the method section of the article. On the other hand, a text-based file format called Protein Data Bank (PDB) is used to store information about the three-dimensional molecular structures. If user wants to make a prediction from three-dimensional molecular structures, .pdb format should be provided.', 'demoDataDetails': {'description': 'As demo data, .fasta file was used as in the GitHub repository of the app.', 'fileName': 'pdb_chains.fasta', 'filePath': 'apps/deepfri/resources/pdb_chains.fasta', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/flatironinstitute/DeepFRI/tree/master/examples'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Upload .FASTA/.PDB/.NPZ File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Tangram for Spatial Transcriptomics,For mapping single-cell gene expression data onto spatial gene expression data.,"<p>Tangram is for mapping single-cell (or single-nucleus) gene expression data onto spatial gene expression data. The single-cell dataset and the spatial dataset should be collected from the same anatomical region/tissue type, ideally from a biological replicate, and need to share a set of genes. Tangram aligns the single-cell data in space by fitting gene expression on the shared genes. Spatial data need to be organized as a voxel-by-gene matrix. The voxel coordinates are saved in the fields obs.x and obs.y which we can use to visualize the spatial ROI. Each ""dot"" is the center of a 10um voxel.<br><br><span style=""font-weight: bold"">Example use case: </span>The most common application of Tangram is to resolve cell types in space. Another usage is to correct gene expression from spatial data: as scRNA-seq data are less prone to dropout than (e.g.) Visium or Slide-seq, the ""new"" spatial data generated by Tangram resolve many more genes. As a result, we can visualize program usage in space, which can be used for ligand-receptor pair discovery or, more generally, cell-cell communication mechanisms. If cell segmentation is available, Tangram can be also used for deconvolution of spatial data. If your single cell are multimodal, Tangram can be used to spatially resolve other modalities, such as chromatin accessibility.</p>","Biancalani T., Scalia G. et al. ","['DGE Analysis', 'Spatial Transcriptomics', 'h5ad', 'Single-Cell Bioinformatics']",639902792ffa50c6deece0a6,"[{'default_value': 'tangram', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': {'label': 'cell_subclass', 'value': 'cell_subclass'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target (labels)', 'tooltip': 'Choose variable representing the entity of interest (typically cell type)'}, {'default_value': {'label': 'cluster', 'value': 'cluster'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'group_by', 'options': [], 'title': 'Group By (optional)', 'tooltip': 'Choose variable to use for clustering / grouping for further analysis', 'optional': True}, {'default_value': 500, 'increment': 10, 'input_type': 'slider', 'max_value': 1500, 'max_value_included': True, 'min_value': 100, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Tangram Training Epochs', 'tooltip': 'Number of epochs used to train Tangram model', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, .mtx, or .csv format', 'demoDataDetails': {'description': 'Mouse brain cortex data taken from Tasic et al. (2018)', 'fileName': 'sc_mouse_cortex.h5ad', 'filePath': 'apps/scvi_tools/resources/sc_mouse_cortex.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://docs.scvi-tools.org/en/stable/tutorials/notebooks/tangram_scvi_tools.html'}], 'previewFileName': 'apps/scvi_tools/resources/sc_mouse_cortex_sample.h5ad'}, 'disabled': False, 'name': 'sc_path', 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Data should have an .h5, .h5ad, or .csv extension, and should include spatial transcriptomic data', 'demoDataDetails': {'description': 'Mouse brain cortex data taken from Tasic et al. (2018)', 'fileName': 'visium_fluo_adata_crop.h5ad', 'filePath': 'apps/scvi_tools/resources/visium_fluo_adata_crop.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://docs.scvi-tools.org/en/stable/tutorials/notebooks/tangram_scvi_tools.html'}], 'previewFileName': 'apps/scvi_tools/resources/visium_fluo_sample.h5ad'}, 'disabled': False, 'name': 'st_path', 'title': 'Spatial Transcriptomic Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Superbio AutoML: Classification,AutoML pipeline by Superbio for classification (binary and multiclass).,"<p>Creates a series of models for tabular data and picks the best one. You can save the best model for later use at the end of the training.<br><br><span style=""font-weight: bold"">Limitations</span>: Data should not have leakage and be as clean as possible.<br><br><span style=""font-weight: bold"">Technology</span>: Classical ML models including XgBoost, Ensamble, and Bagging.<br><br><span style=""font-weight: bold"">Use cases</span>: Create a classification model (binary or multiclass) from tabular data.</p>",Superbio,"['AutoML', 'General Use', 'csv', 'Computational Biology and Bioinformatics']",639940382ffa50c6deece0b8,"[{'default_value': {'label': 'Target', 'value': 'Target'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target', 'tooltip': 'Choose variable/column you want to predict.'}, {'default_value': 'classification', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': 'classification', 'hidden': True, 'input_type': 'user_input', 'name': 'task_ex', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': 'train', 'hidden': True, 'input_type': 'user_input', 'name': 'mode', 'title': 'mode', 'tooltip': 'mode', 'type': 'text'}, {'default_value': {'label': 'mcc', 'value': 'mcc'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'eval_metric', 'options': [{'label': 'mcc', 'value': 'mcc'}, {'label': 'Accuracy', 'value': 'accuracy'}, {'label': 'Balanced Accuracy', 'value': 'balanced_accuracy'}, {'label': 'ROC-AUC-OVO-Macro', 'value': 'roc_auc_ovo_macro'}, {'label': 'Precision', 'value': 'precision'}, {'label': 'Recall', 'value': 'recall'}, {'label': 'F1', 'value': 'f1'}, {'label': 'Quadratic Kappa', 'value': 'quadratic_kappa'}], 'title': 'Metric', 'tooltip': 'Choose the metric you want to optimize during training. Suggested: mcc or ROC'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'class_importance', 'options': [{'label': 'None', 'value': 'None'}, {'label': 'Macro', 'value': 'macro'}, {'label': 'Weighted', 'value': 'weighted'}], 'title': 'Class Importance', 'tooltip': 'Choose Macro if all classes are equally important; Weighted if the importance of the classes should depend on their size. Only affects F1, Recall, and Precision metrics.'}, {'default_value': 0.2, 'increment': 0.01, 'input_type': 'slider', 'max_value': 0.99, 'max_value_included': True, 'min_value': 0.01, 'min_value_inclusive': True, 'name': 'test_size', 'title': 'Percentage Test-Data', 'tooltip': 'Percentage of the dataset to be used as Test', 'type': 'float'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': 'csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format. Each column is a variable, and each row an observation.', 'demoDataDetails': {'description': 'Test data sampled from the original paper (Debernardi et al., 2020) that predicts pancreas diseases based on Urinary Biomarkers', 'fileName': 'demo_data.csv', 'filePath': 'apps/sb_automl_training/resources/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://doi.org/10.1371/journal.pmed.1003489.s009'}], 'previewFileName': 'apps/sb_automl_training/resources/demo_data.csv'}, 'disabled': False, 'name': 'train_data', 'optional': False, 'supportsPreview': True, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Superbio AutoML: Regression,AutoML pipeline by Superbio for regression.,"<p>Creates a series of models for tabular data and picks the best one. You can save the best model for later use at the end of the training.<br><br><span style=""font-weight: bold"">Limitations:</span> Data should not have leakage and be as clean as possible.<br><br><span style=""font-weight: bold"">Technology:</span> Classical ML models including XgBoost, Ensamble, and Bagging.<br><br><span style=""font-weight: bold"">Use cases:</span> Create a regression model from tabular data.</p>",Superbio,"['AutoML', 'General Use', 'csv', 'Computational Biology and Bioinformatics']",639a80982ffa50c6deece221,"[{'default_value': {'label': 'Target', 'value': 'Target'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target', 'tooltip': 'Choose variable/column you want to predict.'}, {'default_value': 'regression', 'hidden': True, 'input_type': 'user_input', 'name': 'task_ex', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': 'train', 'hidden': True, 'input_type': 'user_input', 'name': 'mode', 'title': 'mode', 'tooltip': 'mode', 'type': 'text'}, {'default_value': {'label': 'RMSE', 'value': 'root_mean_squared_error'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'eval_metric', 'options': [{'label': 'RMSE', 'value': 'root_mean_squared_error'}, {'label': 'MSE', 'value': 'mean_squared_error'}, {'label': 'MAE', 'value': 'mean_absolute_error'}, {'label': 'Median Abs Error', 'value': 'median_absolute_error'}, {'label': 'r2', 'value': 'r2'}, {'label': 'Mean Abs Perc Error', 'value': 'mean_absolute_percentage_error'}], 'title': 'Metric', 'tooltip': 'Choose the metric you want to optimize during training. Suggested: RMSE or r2'}, {'default_value': 0.2, 'increment': 0.01, 'input_type': 'slider', 'max_value': 0.99, 'max_value_included': True, 'min_value': 0.01, 'min_value_inclusive': True, 'name': 'test_size', 'title': 'Percentage Test-Data', 'tooltip': 'Percentage of the dataset to be used as Test', 'type': 'float'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format. Each column is a variable, and each row an observation.', 'demoDataDetails': {'description': 'Data obtained from Applying the AFRAID and FRIGHT Clocks to Novel Preclinical Mouse Models of Polypharmacy. It computes the AFRAID-clock which measures the expected lifespan for lab mice.', 'fileName': 'demo_data.csv', 'filePath': 'apps/sb_automl_training/resources_regression/demo_data_reg.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://pubmed.ncbi.nlm.nih.gov/35313348/'}], 'previewFileName': 'apps/sb_automl_training/resources_regression/demo_data_reg.csv'}, 'disabled': False, 'name': 'train_data', 'optional': False, 'supportsPreview': True, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Predict Binding of Inhibitors to BACE-1,Predicts inhibition for SMILES-molecules to human beta-secretase 1 using ChemBERTa.,"<p>Predicts binding and inhibition of molecules, in SMILES format, to human beta-secretace1 (BACE-1). BACE-1 has been implicated as a central player in the pathogenesis of Alzheimer's disease. Our model was fine-tuned with the BACE dataset and uses the ChemBERTa transformer.<br><br><strong>Example use case</strong>: Alzheimer's research.<br><br><strong>Technology</strong>: ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.845&nbsp;</p>
",ChemBERTa & Superbio,"['Classification', 'Drug-target Interactions', 'csv', 'Cheminformatics']",639aa7de2ffa50c6deece263,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'BACE1', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the BACE1 dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/BACE1/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://moleculenet.org/datasets-1'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Skin and Tissue,Predicts if a SMILES-molecule will cause skin and subcutaneous tissue disorders using ChemBERTa.,"<p>Predicts possible undesirable side effects on the skin and subcutaneous tissue of molecules (SMILES format). Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.73</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639ab2422ffa50c6deece26f,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Skin and subcutaneous tissue disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Skin and subcutaneous tissue disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
SpliceAI: A deep learning-based tool to identify splice variants,SpliceAI can precisely predict splice junctions from any pre-mRNA transcript sequence by using a deep neural network.,"<p>Pre-mRNAs are spliced into mature transcripts with extraordinary precision, but it is still unclear how the cellular machinery manages to be so particular. SpliceAI is a deep residual neural network that just requires the genomic sequence of the pre-mRNA transcript as input to predict whether each point in a pre-mRNA transcript is a splice donor, acceptor, or neither.<br><br><strong>Example use case:</strong>  Predicting splice variants<br><br><strong>Technology:</strong> Deep Neural Network (DNN)<br><br><strong>Limitation: </strong>Some of the parameters are kept as default. Please check this <a href=""https://github.com/Illumina/SpliceAI"" target=""_self"">page</a> for more information.<br><br><strong>Metrics:</strong> Some of the metrics related to work can be found in the <a href=""https://www.cell.com/cell/fulltext/S0092-8674(18)31629-5?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867418316295%3Fshowall%3Dtrue#secsectitle0035"" target=""_self"">article</a>.</p>
",Illumina Inc.,"['Deep Neural Network (DNN)', 'Genomics']",639b02ee2ffa50c6deece2a1,"[{'default_value': {'label': 'HG19', 'value': 'hg19'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'ref_genome', 'options': [{'label': 'HG19', 'value': 'hg19'}, {'label': 'HG38', 'value': 'hg38'}], 'title': 'Reference Genome', 'tooltip': 'Please specify the reference genome that you used in the alignment step. For demo file, referance genome should be HG19.'}]","[{'allowedFormats': {'fileExtensions': ['vcf'], 'title': '.vcf', 'value': ''}, 'dataStructure': 'The app accepts a VCF file as input. VCF stands for Variant Call Format. It is a text file format that is used to represent SNP, indel, and structural variation calls.', 'demoDataDetails': {'description': ""As the demo input file, a sample file from the app's GitHub repository was used."", 'fileName': 'input.vcf', 'filePath': 'apps/spliceai/resources/input.vcf', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/Illumina/SpliceAI/tree/master/examples'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Upload VCF File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Product Issues,Predicts if a SMILES-molecule will encounter Product Issues using ChemBERTa.,"<p>Predicts possible undesirable product issues of molecules (SMILES format). Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.66</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639bc7182ffa50c6deece317,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Product issues', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Product issues/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Investigations,Predicts if a SMILES-molecule had Investigations issues using ChemBERTa.,"<p>Predicts possible Investigations issues of molecules (SMILES format). The issues include laboratory tests and other medical investigations that gave an unusual reading. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.67</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639bc94a2ffa50c6deece31f,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Investigations', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Investigations/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - General Disorders and Administration Site Conditions,Predicts if a SMILES-molecule will have General disorders and administration site conditions.,"<p>Predicts possible undesirable General disorders and administration site conditions of molecules (SMILES format). These are a class of disorders that encompasses conditions of a general kind that result from a disease, the treatment of disease or administration of treatment at a particular site and are manifested by a characteristic set of symptoms and signs. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.71</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639bcb202ffa50c6deece324,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'General disorders and administration site conditions', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/General disorders and administration site conditions/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Eye disorders,"Predicts if a SMILES-molecule will cause eye disorders, using ChemBERTa.","<p>Predicts if a molecule may produce undesirable eye disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.65</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639bccbf2ffa50c6deece330,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Eye disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Eye disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Endocrine disorders,"Predicts if a SMILES-molecule may cause Endocrine disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Endocrine disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><strong>Example use case</strong>: Drug interactions and side effects.<br><br><strong>Technology</strong>: ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics</strong></p>
<p>Test-AUC 0.67</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639bce4e2ffa50c6deece335,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Endocrine disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Endocrine disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Blood and lymphatic system disorders,"Predicts if a SMILES-molecule may cause Blood and lymphatic system disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Blood and lymphatic system disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature.&nbsp;</p>
<p><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.67</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639bcf6d2ffa50c6deece33a,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Blood and lymphatic system disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Blood and lymphatic system disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect -  Musculoskeletal and connective tissue disorders,"Predicts if a SMILES-molecule may cause Musculoskeletal and connective disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Musculoskeletal and connective tissue disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.72</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639cab2d2ffa50c6deece3ce,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Musculoskeletal and connective tissue disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format.', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Musculoskeletal and connective tissue disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Gastrointestinal disorders,"Predicts if a SMILES-molecule may cause Gastrointestinal disorders, using ChemBERTa.","<p>Predicts if a molecule may cause Gastrointestinal disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.78</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639cac392ffa50c6deece3d4,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Gastrointestinal disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format.', 'demoDataDetails': {'description': 'Test data from the SIDER dataset', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Gastrointestinal disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Renal and urinary disorders,"Predicts if a SMILES-molecule may cause Renal and urinary disorders, using ChemBERTa.","<p>Predicts if a molecule may cause  Renal and urinary disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology:</strong> ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.69</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639cad762ffa50c6deece3dc,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Renal and urinary disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format.', 'demoDataDetails': {'description': 'Test data from the SIDER dataset.', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Renal and urinary disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
"ChemBERTa: Molecule Side Effect - Respiratory, thoracic and mediastinal disorders","Predicts if a SMILES-molecule may cause Respiratory and mediastinal disorders, using ChemBERTa.","<p>Predicts if a molecule may cause  Respiratory, thoracic and mediastinal disorders. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case</strong>: Drug interactions and side effects.<br><br><strong>Technology</strong>: ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics</strong><br>Test-AUC 0.67</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639cae792ffa50c6deece3e1,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Respiratory, thoracic and mediastinal disorders', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format.', 'demoDataDetails': {'description': 'Test data from the SIDER dataset.', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Respiratory, thoracic and mediastinal disorders/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChemBERTa: Molecule Side Effect - Infections and infestations,"Predicts if a SMILES-molecule may contribute to Infections and infestations, using ChemBERTa.","<p>Predicts if a molecule may contribute to Infections and infestations caused by pathogens. Our model was fine-tuned with the SIDER dataset and uses the ChemBERTa transformer. We follow the standard ""System Organ Classes"" nomenclature. <br><br><strong>Example use case:</strong> Drug interactions and side effects.<br><br><strong>Technology: </strong>ChemBERTa Transformer of 77 million molecules.<br><br><strong>Metrics: </strong>Test-AUC 0.67</p>
","ChemBERTa, SIDER & Superbio","['Classification', 'Drug Side Effects', 'csv', 'Cheminformatics']",639cb1232ffa50c6deece3e7,"[{'default_value': {'label': 'Canonical SMILES', 'value': 'canonical_smiles'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'smiles_format', 'options': [], 'title': 'SMILES', 'tooltip': 'Choose SMILES format'}, {'default_value': 'Infections and infestations', 'hidden': True, 'input_type': 'user_input', 'name': 'pipeline', 'title': 'pipeline', 'tooltip': 'pipeline', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': 'csv'}, 'dataStructure': 'Data should be in csv format with a single column named smiles. The molecule must be in smiles format.', 'demoDataDetails': {'description': 'Test data from the SIDER dataset.', 'fileName': 'demo_data.csv', 'filePath': 'apps/chemberta_models/Infections and infestations/demo_data.csv', 'fileSource': [{'title': 'Data Source', 'url': 'http://sideeffects.embl.de/'}]}, 'disabled': False, 'name': 'inference_data', 'optional': False, 'title': 'Train Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepConsensus: Correct Errors in PacBio CSS Data,DeepConsensus uses gap-aware sequence transformers to correct errors in PacBio data.,"<p>DeepConsensus (v1.2) uses gap-aware sequence transformers to correct errors in Pacific Biosciences (PacBio) Circular Consensus Sequencing (CCS) data.Â This results in greater yield of high-quality reads.<br><br><span style=""font-weight: bold"">Example use case: </span>Correct errors in Pacific Biosciences (PacBio) Circular Consensus Sequencing (CCS) data.<br><br><span style=""font-weight: bold"">Technology: </span>Gap-aware sequence transformers<br><br><span style=""font-weight: bold"">Limitation: </span>This is not an official Google product. The content of this research code repository (i) is not intended to be a medical device; and (ii) is not intended for clinical use of any kind, including but not limited to diagnosis or prognosis.<br><br><span style=""font-weight: bold"">Metrics: </span>Some of the metrics related to work can be found <span style=""color: #0088FF""><a href=""https://github.com/google/deepconsensus/blob/r1.2/docs/assembly_metrics.md"" target=""_blank"" rel=""noreferrer"">here</a></span></p>",Google,"['Transformers', 'Long Read Sequencing', 'Bioinformatics', 'bam']",639cf8f82ffa50c6deece42b,"[{'default_value': 'apps/deep_consensus/v1.2/resources', 'hidden': True, 'input_type': 'user_input', 'name': 'resources', 'title': 'resources', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'google/deepconsensus:1.2.0', 'hidden': True, 'input_type': 'user_input', 'name': 'docker_name', 'title': 'docker_name', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'google/deepconsensus:1.2.0', 'hidden': True, 'input_type': 'user_input', 'name': 'docker_image_location', 'title': 'docker_image_location', 'tooltip': 'NA', 'type': 'object'}]","[{'allowedFormats': {'fileExtensions': ['bam'], 'title': '.bam', 'value': ''}, 'dataStructure': 'Data should be in .bam format.', 'demoDataDetails': {'description': 'Example data that contains 1000 ZMWs', 'fileName': 'n1000.subreads.bam', 'filePath': 'apps/deep_consensus/v1.2/demo_data/n1000.subreads.bam', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/google/deepconsensus'}]}, 'disabled': False, 'name': 'input', 'title': 'Upload Subread Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Auto3D: Generating Low-Energy Conformers from SMILES,Auto3D generates low-energy 3D structures with ANI Neural Network Potentials using SMILES as the input.,"<p>Computational programs speed up the processes of chemical discovery, but they frequently require accurate three-dimensional molecular data as part of the input. Obtaining optimal molecular structures is difficult because it necessitates the enumeration and optimization of a vast space of stereoisomers and conformers. Auto3D allows you to obtain favorable 3D conformations of organic molecules from an automatically generated stereoisomeric conformational space that has been optimized by atomistic neural network potentials (NNPs) like ANI or AIMNet.<br><br><span style=""font-weight: bold"">Example use case:</span> Generating 3D structures from SMILES<br><br><span style=""font-weight: bold"">Technology:</span> Neural Network Potentials (NNPs)<br><br><span style=""font-weight: bold"">Limitation:</span><br>- The current approach does not take into account the physical environment, and all calculations were done in the gas phase.<br>- In real-world applications, some chiral molecules are used in racemic form or have poorly defined stereo centers, so assigning specific stereo information may result in over-curation.<br>- The current NNPs of Auto3D optimize geometries in a vacuum condition.<br>- Only AIMNET and ANI2x models are currently available.<br>- Currently, twenty 3D structures of SMILES can be generated.<br><br><span style=""font-weight: bold"">Metrics:</span> Some of the metrics related to work can be found in the <span style=""color: #0088FF; text-decoration: underline""><a href=""https://chemrxiv.org/engage/chemrxiv/article-details/631b69105351a3bdb1f4a2c1"" target=""_blank"" rel=""noreferrer"">article</a></span>.</p>","Zhen Liu, Tetiana Zubatiuk, Adrian Roitberg, and Olexandr Isayev","['AIMNET', 'ANI', 'Chemical Structure', 'Molecular Structures', 'Molecules']",63a047f72ffa50c6deece48c,"[{'default_value': {'label': 'AIMNET', 'value': 'AIMNET'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'optimizing_engine', 'options': [{'label': 'AIMNET', 'value': 'AIMNET'}, {'label': 'ANI2x', 'value': 'ANI2x'}], 'title': 'Optimizing Engine', 'tooltip': 'Please specify the model for energy calculation and geometry optimization.'}]","[{'allowedFormats': {'fileExtensions': ['smi'], 'title': '.smi', 'value': ''}, 'dataStructure': 'The file must contain SMILES in the first column and their IDs in the second column respectively. ID can contain anything like numbers or letters, but not <_>, the underscore. The file format should be in .smi. Currently, the number of SMILES in the file cannot exceed 20.', 'demoDataDetails': {'description': 'For demo data, example file in the GitHub repo page was used. ', 'fileName': 'smiles.smi', 'filePath': 'apps/auto3d/resources/smiles.smi', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/isayevlab/Auto3D_pkg/tree/main/example/files'}]}, 'disabled': False, 'name': 'input_file', 'title': 'Upload SMILES File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
PeakVI for scATAC-seq Analysis,peakVI for scTAC-seq data can be used for differential accessibility analysis among other tasks,"<p>peakVI (Python class PEAKVI) is a generative model of scATAC-seq data that can subsequently be used for many common downstream tasks. The advantages of peakVI are: (i) Comprehensive in capabilities. (ii) Scalable to very large datasets (>1 million cells).<span style=""font-size: 14px""><br><br></span><span style=""font-weight: bold"">Example use case:</span> Analyze and visualize scATACseq data<br><span style=""font-size: 14px""><br></span><span style=""font-weight: bold"">Limitations:</span><br>-Effectively requires a GPU for fast inference.<br>-Latent space is not interpretable, unlike that of a linear method.</p>",scVI-Tools,"['Differential Accessibility', 'Dimensionality Reduction', 'Epigenomics', 'Gene Expression']",63a1c70f2ffa50c6deece4f0,"[{'default_value': 'peakvi', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': 'training', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': 0.05, 'increment': 0.01, 'input_type': 'slider', 'max_value': 0.1, 'max_value_included': True, 'min_value': 0, 'min_value_inclusive': True, 'name': 'filter_threshold', 'title': 'Filter Rare Peaks', 'tooltip': 'Filter peaks that are detected in fewer than this proportion of cells', 'type': 'float'}, {'default_value': 0.3, 'increment': 0.2, 'input_type': 'slider', 'max_value': 0.8, 'max_value_included': True, 'min_value': 0.01, 'min_value_inclusive': True, 'name': 'cluster_resolution', 'title': 'Cluster Resolution', 'tooltip': 'Controls size and resolution of clusters', 'type': 'float'}, {'default_value': 50, 'increment': 10, 'input_type': 'slider', 'max_value': 200, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Training Epochs', 'tooltip': 'Number of epochs used to train peakVI model', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['mtx'], 'title': '.mtx', 'value': ''}, 'dataStructure': 'Matrix should be in .mtx format', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'matrix.mtx', 'filePath': 'apps/scvi_tools/resources/peakvi/matrix.mtx', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'name': 'matrix_path', 'requireValidation': False, 'supportsPreview': False, 'title': 'Matrix Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tsv'], 'title': '.tsv', 'value': ''}, 'dataStructure': 'Data should have a .tsv extension, and should include barcode data', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'barcodes.tsv', 'filePath': 'apps/scvi_tools/resources/peakvi/barcodes.tsv', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'name': 'barcodes_path', 'requireValidation': False, 'supportsPreview': False, 'title': 'Barcodes Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bed'], 'title': '.bed', 'value': ''}, 'dataStructure': 'Data should have a .bed extension, and should include peaks data', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'peaks.bed', 'filePath': 'apps/scvi_tools/resources/peakvi/peaks.bed', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'name': 'peaks_path', 'requireValidation': False, 'supportsPreview': False, 'title': 'Peaks Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
MultiVI for Multiomic Data Analysis,For the analysis of scRNA and scATAC-seq datasets that were jointly profiled (multiomic/ paired),"<p>MultiVI multimodal generative model capable of integrating multiome, scRNA-seq and scATAC-seq data. After training, it can be used for many common downstream tasks, and also for imputation of a missing modality.<br>The advantages of multiVI are: (i) Comprehensive in capabilities. Able to perform DE gene, DA region analysis. (ii) Scalable to very large datasets (&gt;1 million cells). (iii) Once trained with sufficient multimodal data, able to accurately input missing modalities.<br><br>Important: MultiVI requires the datasets to use shared features. scATAC-seq datasets need to be processed to use a shared set of peaks. This features dataset must be included in the inputs<br><br><strong>Example use case:</strong>  MultiVI can be used for many common downstream tasks, and also for imputation of a missing modality<br><br><strong>Limitations:</strong>  Effectively requires a GPU for fast inference.</p>
",scVI-Tools,"['Omics', 'Epigenomics', 'Single-Cell Bioinformatics']",63a1cc462ffa50c6deece4f6,"[{'default_value': 'multivi', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': 'training', 'hidden': True, 'input_type': 'user_input', 'name': 'task', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': 300, 'increment': 10, 'input_type': 'slider', 'max_value': 600, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Training Epochs', 'tooltip': 'Number of epochs used to train multiVI model', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['mtx'], 'title': '.mtx', 'value': ''}, 'dataStructure': 'Matrix should be in .mtx format', 'demoDataDetails': {'description': '3kPBMC sample dataset from 10X genomics', 'fileName': 'matrix.mtx', 'filePath': 'apps/scvi_tools/resources/multivi/matrix.mtx', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.10xgenomics.com/welcome?closeUrl=%2Fresources%2Fdatasets&lastTouchOfferName=PBMC%20from%20a%20Healthy%20Donor%20-%20Granulocytes%20Removed%20Through%20Cell%20Sorting%20%283k%29&lastTouchOfferType=Dataset&product=chromium&redirectUrl=%2Fresources%2Fdatasets%2Fpbmc-from-a-healthy-donor-granulocytes-removed-through-cell-sorting-3-k-1-standard-2-0-0'}]}, 'disabled': False, 'name': 'matrix_path', 'title': 'Matrix Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tsv', 'csv', 'txt'], 'title': '.tsv, .csv, or .txt', 'value': ''}, 'dataStructure': 'Data should have a .tsv extension, (or .csv or .txt tab delimited) and should include barcode data', 'demoDataDetails': {'description': '3kPBMC sample dataset from 10X genomics', 'fileName': 'barcodes.tsv', 'filePath': 'apps/scvi_tools/resources/multivi/barcodes.tsv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.10xgenomics.com/welcome?closeUrl=%2Fresources%2Fdatasets&lastTouchOfferName=PBMC%20from%20a%20Healthy%20Donor%20-%20Granulocytes%20Removed%20Through%20Cell%20Sorting%20%283k%29&lastTouchOfferType=Dataset&product=chromium&redirectUrl=%2Fresources%2Fdatasets%2Fpbmc-from-a-healthy-donor-granulocytes-removed-through-cell-sorting-3-k-1-standard-2-0-0'}]}, 'disabled': False, 'name': 'barcodes_path', 'title': 'Barcodes Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tsv', 'csv', 'txt'], 'title': '.tsv, .csv, or .txt', 'value': ''}, 'dataStructure': 'Data should have a .tsv extension, (or .csv or .txt tab delimited) and should include shared features data', 'demoDataDetails': {'description': '3kPBMC sample dataset from 10X genomics', 'fileName': 'features.tsv', 'filePath': 'apps/scvi_tools/resources/multivi/features.tsv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.10xgenomics.com/welcome?closeUrl=%2Fresources%2Fdatasets&lastTouchOfferName=PBMC%20from%20a%20Healthy%20Donor%20-%20Granulocytes%20Removed%20Through%20Cell%20Sorting%20%283k%29&lastTouchOfferType=Dataset&product=chromium&redirectUrl=%2Fresources%2Fdatasets%2Fpbmc-from-a-healthy-donor-granulocytes-removed-through-cell-sorting-3-k-1-standard-2-0-0'}]}, 'disabled': False, 'name': 'features_path', 'title': 'Shared Features Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
"DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking",Predict the binding structure of a small molecule ligand to a protein using AI diffusion.,"<p>Predict the binding structure of a small molecule ligand to a protein. Here, molecular docking is framed as a generative modeling problem over the non-Euclidean manifold of ligand poses. This manifold is mapped to the product space of the degrees of freedom (translational, rotational, and torsional) involved in docking.<br><br><span style=""font-weight: bold"">Example use case: </span>Predict binding structure of a ligand to a protein for the sake of drug discovery<br><br><span style=""font-weight: bold"">Technology: </span>Diffusion<br><br><span style=""font-weight: bold"">Metrics: </span>38% top-1 success rate (RMSD<2Ã) on PDB-Bind</p>","Gabriele Corso, Hannes Stark, Bowen Jing et. al.","['Diffusion', 'Protein', 'Drug', 'csv', 'Structural Bioinformatics']",63a335cfaf3a0a1151c0fb77,"[{'decimalPlace': 0, 'default_value': 20, 'input_type': 'slider', 'max_value': 300, 'min_value': 1, 'name': 'inference_steps', 'title': 'Number of inference steps', 'tooltip': 'More steps can mean more accurate results, however will mean a greater execution time'}, {'decimalPlace': 0, 'default_value': 40, 'input_type': 'slider', 'max_value': 100, 'min_value': 1, 'name': 'samples_per_complex', 'title': 'Number of samples per complex', 'tooltip': '?'}]","[{'requireValidation': True, 'validationRules': {'preserveOrder': False, 'columns': {'columnsList': [{'name': 'pdb', 'allowedTypes': ['str']}, {'name': 'smiles', 'allowedTypes': ['str']}]}}, 'allowedFormats': {'fileExtensions': ['csv'], 'title': 'csv', 'value': 'text/csv'}, 'dataStructure': ""A csv where the first column named 'pdb' contains rcsb IDs of your complexes e.g 6agt, 6p8y, 6mo8. And, the second column named 'smiles' contains the ligands you wish to dock inside the complex as a pubchem ID or in SMILES format"", 'demoDataDetails': {'description': ""The proteins 1U5M with COc1ccc(cc1)n2c3c(c(n2)C(=O)N)CCN(C3=O)c4ccc(cc4)N5CCCCC5=O as the protein's ligand\n"", 'fileName': 'input.csv', 'filePath': 'apps/diffdock/input.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://colab.research.google.com/drive/1nvCyQkbO-TwXZKJ0RCShVEym1aFWxlkX#scrollTo=rVn2g1AcdPaM'}], 'previewFileName': 'apps/diffdock/input.csv'}, 'disabled': False, 'name': 'data', 'supportsPreview': True, 'title': 'Upload complex ligand pairs', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
PBMC scATAC-seq analysis with PeakVI,Pretrained PBMC model for analysis of differential accessibility,"<p style=""text-align:start;""><span style=""color: rgb(0,0,0);background-color: rgb(255,255,255);font-size: 14px;font-family: Poppins, sans-serif;"">peakVI (Python class PEAKVI) is a generative model of scATAC-seq data that can subsequently be used for many common downstream tasks. Here we present a pretrained PBMC (white blood cell) dataset which can be used for differential accessibility analysis.</span></p>
",scVI-Tools,"['Differential Accessibility', 'Dimensionality Reduction', 'Epigenomics', 'Gene Expression', 'Single-Cell Bioinformatics']",63a5af95af3a0a1151c0fc6a,"[{'default_value': 'peakvi', 'hidden': True, 'input_type': 'user_input', 'name': 'app_name', 'title': 'app_name', 'tooltip': 'app_name', 'type': 'text'}, {'default_value': '63c512cbaf3a0a1151c0ff0b', 'hidden': True, 'input_type': 'user_input', 'name': 'train_job_id', 'title': 'train_job_id', 'tooltip': 'train_job_id', 'type': 'text'}, {'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Transfer Learning', 'value': 'retraining'}], 'title': 'Infer only or train model further on new data', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': 0.3, 'increment': 0.01, 'input_type': 'slider', 'max_value': 0.8, 'max_value_included': True, 'min_value': 0.1, 'min_value_inclusive': True, 'name': 'cluster_resolution', 'title': 'Cluster Resolution', 'tooltip': 'Controls size and resolution of clusters', 'type': 'float'}, {'default_value': 50, 'increment': 10, 'input_type': 'slider', 'max_value': 200, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'epochs', 'title': 'Transfer Learning Epochs', 'tooltip': 'Number of epochs used to train peakVI model', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['mtx'], 'title': '.mtx', 'value': ''}, 'dataStructure': 'Matrix should be in .mtx format', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'matrix.mtx', 'filePath': 'apps/scvi_tools/resources/peakvi/matrix.mtx', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'name': 'matrix_path', 'requireValidation': False, 'supportsPreview': False, 'title': 'Matrix Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tsv'], 'title': '.tsv', 'value': ''}, 'dataStructure': 'Data should have a .tsv extension, and should include barcode data', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'barcodes.tsv', 'filePath': 'apps/scvi_tools/resources/peakvi/barcodes.tsv', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'name': 'barcodes_path', 'requireValidation': False, 'supportsPreview': False, 'title': 'Barcodes Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bed'], 'title': '.bed', 'value': ''}, 'dataStructure': 'Data should have a .bed extension, and should include peaks data', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'peaks.bed', 'filePath': 'apps/scvi_tools/resources/peakvi/peaks.bed', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'name': 'peaks_path', 'requireValidation': False, 'supportsPreview': False, 'title': 'Peaks Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
FoldingDiff: Diffusion Model for Protein Backbone generation,A new diffusion-based generative model that designs protein backbone structures via a procedure that mirrors the native folding process.,"<p>Since they are involved in practically every biological activity, proteins are essential for life. The capacity to create innovative, physically foldable protein structures using computation may result in new biological understandings and therapeutic developments for diseases without cures. In this study, inter-residue angles in protein backbones are used rather than cartesian atom coordinates. Training a denoising diffusion probabilistic model with a basic transformer backbone shows that the model produces very realistic protein structures with complexity and structural patterns that are similar to those of naturally occurring proteins.</p>
<p><span style=""font-weight: bold"">Example Use Case: </span>Generating 3D protein backbone structuresÂ from the <span style=""text-decoration: underline; color: #0088FF""><a href=""https://huggingface.co/wukevin/foldingdiff_cath"" target=""_blank"" rel=""noreferrer"">pre-trained model</a></span>.</p>
<p><span style=""font-weight: bold"">Technology: </span>Diffusion Model</p>
<p><span style=""font-weight: bold"">Limitations:</span></p>
<ul>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">Compared to <span style=""font-style: italic"">natural </span>proteins, the lengths of the produced structures are still quite small</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">When a protein is formulated as a series of angles, errors that occur early in the chain dramatically change the overall generated structure</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">The tool is incapable of handling multi-chain complexes or ligand interactions</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">Only capable of producing static structures</li>
  <li class=""list unordered-list-item depth0"" style=""margin-left:2.5em;list-style-type: disc;position: relative;margin-left: 2.5em"">Evaluating and visualizing (PyMOL) part is not included in this version. Please see the code page.</li>
</ul>
<p><span style=""font-weight: bold"">Metrics: </span>Some metricsÂ related to TM-Scores can be found in the <span style=""text-decoration: underline; color: #0088FF""><a href=""https://arxiv.org/abs/2209.15611"" target=""_blank"" rel=""noreferrer"">article</a></span>.</p>",Microsoft,"['3D Protein Structure Prediction', 'Structural Bioinformatics']",63dd1aecbd2a3db57fdf1e42,"[{'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'num', 'title': 'Example Number', 'tooltip': 'Number of examples to generate *per length* (default: 10)', 'type': 'integer'}, {'default_value': 50, 'input_type': 'user_input', 'name': 'length_1', 'title': 'First Length', 'tooltip': 'Range of lengths to sample from (default: [50, 128])', 'type': 'integer'}, {'default_value': 128, 'input_type': 'user_input', 'name': 'length_2', 'title': 'Second Length', 'tooltip': 'Range of lengths to sample from (default: [50, 128])', 'type': 'integer'}]",
BioGPT: Text Generation,"BioGPT is a language model trained for biomedical tasks, it is trained on the PubMed dataset which contains 15 million abstracts.","<div class=""public-DraftStyleDefault-ltr public-DraftStyleDefault-block"" style=""box-sizing: border-box; font-family: Poppins, sans-serif !important; text-align: inherit; position: relative; margin: 1em 0px; padding: 0px; direction: ltr""><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">BioGPT is a language model trained for biomedical tasks, it is trained on the PubMed dataset which contains 15 million abstracts. BioGPT outperforms larger, more general language models in biomedical language benchmarks.</span></div>
<div class=""public-DraftStyleDefault-ltr public-DraftStyleDefault-block"" style=""box-sizing: border-box; font-family: Poppins, sans-serif !important; text-align: inherit; position: relative; margin: 1em 0px; padding: 0px; direction: ltr""><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Example use case: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">Generate text within the biomedical domain. See examples below.<br><br></span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box; font-weight: bold"">Technology: </span><span style=""font-family: Poppins, sans-serif !important; margin: 0px; padding: 0px; box-sizing: border-box"">GPT-2 backbone<br></span><br><span style=""font-weight: bold"">Limitations: </span>Sometimes produces false information</div>",Microsoft,"['GPT', 'NLP', 'Biomedical Language Models']",63f771aabd2a3db57fdf1faf,,
BioGPT: Question and Answer - PubMed,BioGPT: Question and Answer - PubMed is a language model fine-tuned to answer yes/no/maybe questions for biomedical tasks.,"<p>BioGPT: Question and Answer - PubMed is a language model fine-tuned on the expert annotated PubMedQA dataset which is a biomedical question-answering dataset, to answer yes/no/maybe questions for biomedical tasks. BioGPT outperforms larger, more general language models in biomedical language benchmarks.<br><br><span style=""font-weight: bold"">Example use case:&nbsp;&nbsp;</span>Answering academic questions. See examples below.<br><br><span style=""font-weight: bold"">Technology:&nbsp;&nbsp;</span>GPT-2 Backbone<br><br><span style=""font-weight: bold"">Metrics: </span>78.2% Accuracy<br>&nbsp;&nbsp;<br><span style=""font-style: italic; font-weight: bold"">Note:</span><span style=""font-style: italic"">Â For better results, queries are separated into a question and a context for the question. See examples below.</span></p>",Microsoft,"['GPT', 'NLP', 'Biomedical Language Models']",63f772e4bd2a3db57fdf1fb0,,
"BioGPT: Relation Extraction - DDI, DTI, BC5CDR",BioGPT: Relation Extraction is a language model fine-tuned to find a relation between entities.,"<p>BioGPT: Relation Extraction is a language model fine-tuned to find a relation between entities.</p>
<p>Included in this app are three models finetuned on different datasets each with a different use case.</p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Finding the interaction between two drugs, finetuned on <span style=""color: #0088FF""><a href=""https://www.sciencedirect.com/science/article/pii/S1532046413001123"" target=""_blank"" rel=""noreferrer"">DDI</a></span></li>
<li style=""list-style-type: disc"">Finding the interaction between a drug and its target, fine-tuned on <span style=""color: #0088FF""><a href=""https://academic.oup.com/bioinformatics/article/38/22/5100/6751771"" target=""_blank"" rel=""noreferrer"">DTI</a></span></li>
<li style=""list-style-type: disc"">Finding the interaction between a chemical and a disease, finetuned on <span style=""color: #0088FF""><a href=""https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/"" target=""_blank"" rel=""noreferrer"">BC5CDR</a></span></li></ul>


<div><span style=""font-weight: bold"">Example use case:Â </span><span style=""display: inline !important; font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span>See examples below.<br><br><span style=""font-weight: bold"">Technology: </span>GPT-2 Backbone<br><br><span style=""font-weight: bold"">Metrics: </span>(Precision/Recall/F1) - DDI: (41.70/44.75/40.76), DTI: (40.00/39.72/38.42), BC5CDR: (49.52/43.25/46.17)<br><br><span style=""font-weight: bold; font-style: italic"">Note:</span><span style=""font-style: italic""> Input queries should be in the form of an abstract regarding the entities you wish to find the relation between.</span></div>",Microsoft,"['GPT', 'NLP', 'Biomedical Language Models']",63f773dfbd2a3db57fdf1fb3,,
BioGPT: Document Classification - Hallmarks of Cancer,BioGPT: Document Classification is a language model fine-tuned to classify snipped of documents into 10 categories of cancer hallmarks.,"<p>BioGPT: Document Classification is a language model fine-tuned to classify snipped of documents into 10 categories of cancer hallmarks. It is trained on the Hallmarks of Cancers corpus which consists of 1580 PubMed abstracts that have been manually annotated.<br><br><span style=""font-weight: bold"">Example use case: </span>Classify what hallmark of cancer a document is reporting on.<br>&nbsp;&nbsp;<br><span style=""font-weight: bold"">Technology: </span>GPT-2 backbone<br><br><span style=""font-weight: bold"">Metrics: </span>F1 score: 85.12<br><br><span style=""font-weight: bold; font-style: italic"">Note:</span><span style=""display: inline !important; font-style: italic; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: bold; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span><span style=""font-style: italic"">Input queries should be in the form of an abstract. See examples below.</span></p>",Microsoft,"['GPT', 'NLP', 'Biomedical Language Models']",63f7759dbd2a3db57fdf1fb6,,
CXR: Tuberculosis Detection,TB Detection using CXR and Superbio Neural Networks,"<div>This app processes data in two stages, using two different models, <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/CXR-Tuberculosis-Detection-c5390a5098fd473981879c28fc6634d1"" target=""_blank"" rel=""noreferrer"">details of which can be found here.</a></span></div>
<div><br></div>
<div>Files should be provided in either .png or .dcm format, with multiple files provided in a .zip compressed folder.</div>
<div><br></div>
<div><span style=""font-weight: bold"">Limitations</span>:</div>
<div><br></div>
<div>Should be used for research purposes only.</div>
<div><br></div>
<div>This is not a clinically validated tool. Do not use CXR for self-diagnosis and seek help from your local health authorities.</div>
<div><br></div>
<div>Results may not generalize well to other patient populations or manufacturers not used in training.</div>
<div><br></div>
<div><span style=""font-weight: bold"">Risks</span>: Although neither Google nor Superbio permanently store any data processed by these models, it is the data owner's responsibility to ensure that Personally identifiable information (PII) and Protected Health Information (PHI) are removed prior to data upload.</div>",Google Health,"['Classification', 'Medical Image', 'Medical Diagnosis', 'zip', 'png', 'Biomedical Image Analysis and Interpretation']",64020c553e3000de4dfb41af,"[{'default_value': 'inference', 'hidden': True, 'input_type': 'user_input', 'name': 'app_type', 'title': 'app_type', 'tooltip': 'task', 'type': 'text'}, {'default_value': 'Tuberculosis', 'hidden': True, 'input_type': 'user_input', 'name': 'case_name', 'title': 'case_name', 'tooltip': 'case_name', 'type': 'text'}, {'default_value': {'label': 'class', 'value': 'class'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'class', 'options': [], 'title': 'Target (optional labels)', 'tooltip': 'Target column for identifying labels'}, {'default_value': {'label': 'image_id', 'value': 'image_id'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'image_id', 'options': [], 'title': 'Image ID (optional labels)', 'tooltip': 'Target column for identifying file / image names'}, {'default_value': 'apps/cxr/resources/tb_model.h5', 'hidden': True, 'input_type': 'user_input', 'name': 'model_path', 'title': 'model_path', 'tooltip': 'model_path', 'type': 'text'}, {'default_value': False, 'input_type': 'checkbox', 'link': {'content': 'I have read and agree to the <link>', 'href': 'https://superbioai.notion.site/CXR-Foundation-Additional-Terms-of-Service-663ae7acb5c141c998e65e97682e16be', 'text': 'Google Terms of Service and CXR Foundation - Additional Terms of Service'}, 'name': 'terms', 'title': 'Terms of Service', 'optional': False, 'tooltip': 'Please confirm if you agree to the Terms of Service before proceeding', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['png', 'dcm', 'zip'], 'title': '.png, .dcm, zip', 'value': ''}, 'dataStructure': 'Data should be in .png, or .dcm (dicom) format. It can be a zip file of images.', 'demoDataDetails': {'description': 'Chest X-ray images for detection (note this is a different dataset than that used to train the model)', 'fileName': 's90.zip', 'filePath': 'apps/cxr/resources/tb_images/s90.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/raddar/tuberculosis-chest-xrays-shenzhen'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Chest X-ray Images (1000 images or 100mb max)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'txt', 'tsv'], 'title': '.csv, .txt, .tsv', 'value': 'text/csv/ tsv'}, 'dataStructure': 'Data should be in .csv, .txt or .tsv format, and should include filenames/ image_ids and the name of the target feature.', 'demoDataDetails': {'description': 'Labels and filenames for Tuberculosis data (note this is a different dataset than that used to train the model).', 'fileName': 'shenzhen_metadata.csv', 'filePath': 'apps/cxr/resources/shenzhen_metadata.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/raddar/tuberculosis-chest-xrays-shenzhen'}], 'previewFileName': 'apps/cxr/resources/shenzhen_metadata.csv'}, 'disabled': False, 'name': 'label_path', 'optional': True, 'supportsPreview': True, 'title': 'Test Data Labels (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
CXR: Chest X-Ray Image Classification,Image classification using CXR and Superbio Neural Networks,"<p>This app allows users to train models to predict clinical condition (e.g., Covid-19), or patient outcome (e.g., hospitalization), based on Chest X-Ray images. The user provides the images they want to train the model on, along with labels of the actual classification for each image. Once trained the model can then be applied to new datasets. <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/CXR-Chest-X-Ray-Image-Classification-634e765ebf1e4a98bb39b3492d201065"" target=""_blank"" rel=""noreferrer"">Further details on how this app works can be found here.</a></span>&nbsp;</p>
<p>Files should be provided in either .png or .dcm format, with multiple files provided in a .zip compressed folder. We recommend that at least 200 images should be used for training new models. Using more images for training will likely improve results. Labels should also be provided in .csv format: with 1 indicating the presence of a condition, and 0 indicating the control group. If multiple labels are provided instead, in string format, in a single column, then a multilabel model will be trained instead.</p>
<p><span style=""font-weight: bold"">Limitations:</span></p>
<p>Should be used for research purposes only.</p>
<p>This is not a clinically validated tool. Do not use CXR for self-diagnosis and seek help from your local health authorities.</p>
<p>Results may not generalize well to other patient populations or manufacturers not used in training.</p>
<p><span style=""font-weight: bold"">Risks</span>: Although neither Google nor Superbio permanently store any data processed by these models, it is the data owner's responsibility to ensure that Personally identifiable information (PII) and Protected Health Information (PHI) are removed prior to data upload.</p>",Google Health,"['Classification', 'Medical Image', 'Medical Diagnosis', 'zip', 'png', 'Biomedical Image Analysis and Interpretation']",640613393e3000de4dfb424d,"[{'default_value': 'training', 'hidden': True, 'input_type': 'user_input', 'name': 'app_type', 'title': 'app_type', 'tooltip': 'task', 'type': 'text'}, {'default_value': {'label': 'Class', 'value': 'Class'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'class', 'options': [], 'title': 'Target', 'tooltip': 'Target column for identifying labels'}, {'default_value': {'label': 'image_id', 'value': 'image_id'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'image_id', 'options': [], 'title': 'Image ID Column', 'tooltip': 'Target column for identifying file / image names'}, {'default_value': 25, 'increment': 5, 'input_type': 'slider', 'max_value': 50, 'max_value_included': True, 'min_value': 5, 'min_value_inclusive': True, 'name': 'pretune_trials', 'title': 'Trials', 'tooltip': 'Number of trials to run, to identify optimal model, before training final model', 'type': 'integer'}, {'default_value': 50, 'increment': 10, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'tune_epochs', 'title': 'Epochs', 'tooltip': 'Number of epochs used to train trial models, as well as final model', 'type': 'integer'}, {'default_value': False, 'input_type': 'checkbox', 'link': {'content': 'I have read and agree to the <link>', 'href': 'https://superbioai.notion.site/CXR-Foundation-Additional-Terms-of-Service-663ae7acb5c141c998e65e97682e16be', 'text': 'Google Terms of Service and CXR Foundation - Additional Terms of Service'}, 'name': 'terms', 'optional': False, 'title': 'Terms of Service', 'tooltip': 'Please confirm if you agree to the Terms of Service before proceeding', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'tsv', 'txt'], 'title': '.tsv, .txt, or .csv', 'value': ''}, 'dataStructure': 'Data should be in .csv or .tsv format, and should include filenames/ image_ids and the name of the target feature.', 'demoDataDetails': {'description': 'Labels and filenames for Tuberculosis data.', 'fileName': 'Tmetadata.csv', 'filePath': 'apps/cxr/resources/Tmetadata.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset'}], 'previewFileName': 'apps/cxr/resources/Tmetadata.csv'}, 'disabled': False, 'name': 'label_path', 'supportsPreview': True, 'title': 'Labels and File/Image Names', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['png', 'dcm', 'zip'], 'title': '.png, .dcm, zip', 'value': ''}, 'dataStructure': 'Data should be in .png, or .dcm (dicom) format. It can be a zip file of images.', 'demoDataDetails': {'description': 'Chest X-ray image for classification', 'fileName': 'TB_Images_200.zip', 'filePath': 'apps/cxr/resources/tb_images/TB_Images_200.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Chest X-ray Images (1000 images or 100mb max)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
CXR: Covid-19 Detection,Covid-19 Detection using CXR and Superbio Neural Networks,"<p>This app processes data in two stages, using two different models, <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/CXR-Covid-19-Detection-9f7e8b99393840ddaf8c2a4cee2702a3"" target=""_blank"" rel=""noreferrer"">details of which can be found here.</a></span></p>
<p>Files should be provided in either .png or .dcm format, with multiple files provided in a .zip compressed folder.</p>
<p><span style=""font-weight: bold"">Limitations:</span></p>
<p>Should be used for research purposes only.</p>
<p>This is not a clinically validated tool. Do not use CXR for self-diagnosis and seek help from your local health authorities.</p>
<p>Results may not generalize well to other patient populations or manufacturers not used in training.</p>
<p><span style=""font-weight: bold"">Risks</span>: Although neither Google nor Superbio permanently store any data processed by these models, it is the data owner's responsibility to ensure that Personally identifiable information (PII) and Protected Health Information (PHI) are removed prior to data upload.</p>",Google Health,"['Classification', 'Medical Diagnosis', 'Medical Image', 'png', 'zip', 'Biomedical Image Analysis and Interpretation']",640630c53e3000de4dfb4269,"[{'default_value': 'inference', 'hidden': True, 'input_type': 'user_input', 'name': 'app_type', 'title': 'app_type', 'tooltip': 'task', 'type': 'text'}, {'default_value': 'Covid-19', 'hidden': True, 'input_type': 'user_input', 'name': 'case_name', 'title': 'case_name', 'tooltip': 'case_name', 'type': 'text'}, {'default_value': {'label': 'covid', 'value': 'covid'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'class', 'options': [], 'title': 'Target (optional labels)', 'tooltip': 'Target column for identifying labels'}, {'default_value': {'label': 'image_id', 'value': 'image_id'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'image_id', 'options': [], 'title': 'Image ID (optional labels)', 'tooltip': 'Target column for identifying file / image names'}, {'default_value': 'apps/cxr/resources/covid_model.h5', 'hidden': True, 'input_type': 'user_input', 'name': 'model_path', 'title': 'model_path', 'tooltip': 'model_path', 'type': 'text'}, {'default_value': False, 'input_type': 'checkbox', 'link': {'content': 'I have read and agree to the <link>', 'href': 'https://superbioai.notion.site/CXR-Foundation-Additional-Terms-of-Service-663ae7acb5c141c998e65e97682e16be', 'text': 'Google Terms of Service and CXR Foundation - Additional Terms of Service'}, 'name': 'terms', 'optional': False, 'title': 'Terms of Service', 'tooltip': 'Please confirm if you agree to the Terms of Service before proceeding', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['png', 'dcm', 'zip'], 'title': '.png, .dcm, zip', 'value': ''}, 'dataStructure': 'Data should be in .png, or .dcm (dicom) format. It can be a zip file of images.', 'demoDataDetails': {'description': 'Chest X-ray image for detection', 'fileName': 'covid50.zip', 'filePath': 'apps/cxr/resources/covid_images/covid50.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database'}]}, 'disabled': False, 'name': 'image', 'title': 'Upload Chest X-ray Images (1000 images or 100mb max)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'txt', 'tsv'], 'title': '.csv, .tsv, .txt', 'value': 'text/csv/ tsv'}, 'dataStructure': 'Data should be in .csv, .txt or .tsv format, and should include filenames/ image_ids and the name of the target feature.', 'demoDataDetails': {'description': 'Labels and filenames for Covid 19 data.', 'fileName': 'covid_metadata.csv', 'filePath': 'apps/cxr/resources/covid_metadata.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database'}], 'previewFileName': 'apps/cxr/resources/covid_metadata.csv'}, 'disabled': False, 'name': 'label_path', 'optional': True, 'supportsPreview': True, 'title': 'Test Data Labels (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepVariant: Deep Learning-based Variant Caller,DeepVariant (v1.5) is an analysis pipeline that treats the task of identifying genetic variants as an image classification problem from next-generation DNA sequencing data.,"<p>DeepVariant (v1.5) is a deep learning-based variant caller that analyzes and identifies variants associated with a specific trait, disease, or population.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Disease research and precision medicine</p>
<p><span style=""font-weight: bold"">Technology:</span> Convolutional neural network</p>
<p><span style=""font-weight: bold"">Metrics:</span> As <span style=""color: #0088FF""><a href=""https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md"" >reported</a></span><span style=""color: #0088FF"">&nbsp;</span>by the Genomics team in Google Health, ""DeepVariant maintains high accuracy across data from different sequencing technologies, prep methods, and species.""</p>",Google,"['Variant Calling', 'Computational Biology and Bioinformatics']",640b4aa1b7dfb773cbe47e15,"[{'default_value': {'label': 'ENSEMBL | GRCh37', 'value': 'ensembl_grch37'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'reference_genome', 'options': [{'label': 'ENSEMBL | GRCh37', 'value': 'ensembl_grch37'}, {'label': 'GATK | hg19', 'value': 'gatk_hg19'}, {'label': 'GATK | hg38', 'value': 'gatk_hg38'}, {'label': 'GATK | GRCh37', 'value': 'gatk_grch37'}, {'label': 'GATK | GRCh38', 'value': 'gatk_grch38'}, {'label': 'NCBI | build37.1', 'value': 'ncbi_build37.1'}, {'label': 'NCBI | build37.2', 'value': 'ncbi_build37.2'}, {'label': 'NCBI | GRCh38', 'value': 'ncbi_grch38'}, {'label': 'NCBI | GRCh38Decoy', 'value': 'ncbi_grch38Decoy'}, {'label': 'UCSC | hg19', 'value': 'ucsc_hg19'}, {'label': 'UCSC | hg38', 'value': 'ucsc_hg38'}], 'title': 'REFERENCE GENOME', 'tooltip': 'DeepVariant is trained for the human genome. Please select a reference genome that matches the genome used in your aligned read file!'}, {'default_value': {'label': 'WES', 'value': 'WES'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'model_type', 'options': [{'label': 'WES', 'value': 'WES'}, {'label': 'WGS', 'value': 'WGS'}, {'label': 'PACBIO', 'value': 'PACBIO'}], 'title': 'Model Type', 'tooltip': 'If your study is whole genome sequencing (Illumina - WGS), choose WGS model. If your study is related to whole exome sequencing (Illumina - WES), choose WES trained models.'}]","[{'allowedFormats': {'fileExtensions': ['bam'], 'title': '.bam', 'value': ''}, 'dataStructure': 'Standard BAM file.', 'demoDataDetails': {'description': 'Real exome sample for DeepVariant. Ashkenazim Father HG003/NA24149. Also other necessary files links are provided below.', 'fileName': 'HG003.bam', 'filePath': 'apps/deepVariant/resources/HG003.novaseq.wes_idt.100x.dedup.bam', 'fileSource': [{'title': 'Data Source - WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md'}, {'title': 'Data Source - WGS Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-case-study.md'}, {'title': 'Data Source - PACBIO Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-pacbio-model-case-study.md'}]}, 'multiple': True, 'disabled': True, 'name': 'input_file', 'title': 'Select Aligned Read File', 'uploadTypes': [{'title': 'SRA Search', 'type': 'search'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bai'], 'title': '.bai', 'value': ''}, 'dataStructure': 'Standard BAI index file.', 'demoDataDetails': {'description': 'Real exome sample for DeepVariant. Ashkenazim Father HG003/NA24149. Also other necessary files links are provided below', 'fileName': 'HG003.bam.bai', 'filePath': 'apps/deepVariant/resources/HG003.novaseq.wes_idt.100x.dedup.bam.bai', 'fileSource': [{'title': 'Data Source - WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md'}, {'title': 'Data Source - WGS Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-case-study.md'}, {'title': 'Data Source - PACBIO Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-pacbio-model-case-study.md'}]}, 'multiple': True, 'disabled': False, 'name': 'bai_file', 'title': 'Select Aligned Read Index File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
ChatGPT for Genetics,Natural Language queries for the Open Targets platform,"<p>Query the Open Targets Platform using natural language. The Open Targets Platform (platform.opentargets.org) integrates evidence from genetics, genomics, transcriptomics, drugs, animal models, and scientific literature to score and rank target-disease associations for drug-target identification. The model accepts queries in the form of "" What are the top [k] diseases associated with [GENE NAME]?"" and "" What are the top [k] genes related to [DISEASE NAME]?"" Alternatively, for improved precision, you can use the ENSG of the gene or the EFO id for the diseases.</p>
<p><span style=""font-weight: bold"">Example use case</span>: Querying Open Targets Platform with Natural Language. If you want to know the top 8 diseases associated with the APOE gene: ""What are the top 8 diseases associated with APOE?"" or the top 3 genes associated with Alzheimer's disease: ""Find the top 3 genes related to Alzheimer disease.""</p>
<p><span style=""font-weight: bold"">Technology</span>: Open Targets Platform and GPT3</p>
<p><span style=""font-weight: bold"">Limitations</span>: It does not produce any novelty or new-knowledge that is not available in the Open Targets Platform. We are currently improving the types of queries it accepts.</p>","cx0, Superbio, OpenAi, Open Targets","['GPT', 'NLP', 'Biomedical Language Models']",6410e7a2db9814665513ffab,,
Deeptrio: Deep learning-based trio variant caller,DeepTrio is a variant calling algorithm developed by the Google Brain team that extends the functionality of DeepVariant to identify genetic variants in trios or duos.,"<p>DeepTrio builds on DeepVariant's deep learning-based approach to variant calling and applies it to trio sequencing data. It uses a neural network to analyze the sequencing data from the child and both parents simultaneously, allowing it to more accurately identify de novo mutations and other genetic variants.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Identify genetic variants in trios or duos</p>
<p><span style=""font-weight: bold"">Technology:</span> Neural Network</p>
<p><span style=""font-weight: bold"">Limitations:</span> Currently, the app is only working only with trios<span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px""><br></span><br></p>",Google,"['Variant Calling', 'Bioinformatics', 'bam', 'bai']",641abd9c9d35843a448c201d,"[{'default_value': {'label': 'ENSEMBL | GRCh37', 'value': 'ensembl_grch37'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'reference_genome', 'options': [{'label': 'ENSEMBL | GRCh37', 'value': 'ensembl_grch37'}, {'label': 'GATK | hg19', 'value': 'gatk_hg19'}, {'label': 'GATK | hg38', 'value': 'gatk_hg38'}, {'label': 'GATK | GRCh37', 'value': 'gatk_grch37'}, {'label': 'GATK | GRCh38', 'value': 'gatk_grch38'}, {'label': 'NCBI | build37.1', 'value': 'ncbi_build37.1'}, {'label': 'NCBI | build37.2', 'value': 'ncbi_build37.2'}, {'label': 'NCBI | GRCh38', 'value': 'ncbi_grch38'}, {'label': 'NCBI | GRCh38Decoy', 'value': 'ncbi_grch38Decoy'}, {'label': 'UCSC | hg19', 'value': 'ucsc_hg19'}, {'label': 'UCSC | hg38', 'value': 'ucsc_hg38'}], 'title': 'REFERENCE GENOME', 'tooltip': 'DeepVariant is trained for the human genome. Please select a reference genome that matches the genome used in your aligned read file!'}, {'default_value': {'label': 'WES', 'value': 'WES'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'model_type', 'options': [{'label': 'WES', 'value': 'WES'}, {'label': 'WGS', 'value': 'WGS'}], 'title': 'Model Type', 'tooltip': 'If your study is whole genome sequencing (Illumina - WGS), choose WGS model. If your study is related to whole exome sequencing (Illumina - WES), choose WES trained models.'}]","[{'allowedFormats': {'fileExtensions': ['bam'], 'title': '.bam', 'value': ''}, 'dataStructure': 'The BAM (Binary Alignment/Map) file format is a binary file format used in genomics to store DNA sequence alignment data, typically generated from high-throughput sequencing experiments. BAM files are compressed and indexed versions of SAM (Sequence Alignment/Map) files, which are text-based.', 'demoDataDetails': {'description': 'Ashkenazim Child HG002. Also other necessary file link are provided below.', 'fileName': 'HG002', 'filePath': 'apps/deeptrio/resources/HG002.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam', 'fileSource': [{'title': 'Data Source - WGS/WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md'}]}, 'disabled': True, 'name': 'child_bam_file', 'title': 'Upload Child BAM File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bam'], 'title': '.bam', 'value': ''}, 'dataStructure': 'The BAM (Binary Alignment/Map) file format is a binary file format used in genomics to store DNA sequence alignment data, typically generated from high-throughput sequencing experiments. BAM files are compressed and indexed versions of SAM (Sequence Alignment/Map) files, which are text-based.', 'demoDataDetails': {'description': 'Ashkenazim Father HG003/NA24149. Also other necessary files links are provided below.', 'fileName': 'HG003', 'filePath': 'apps/deeptrio/resources/HG003.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam', 'fileSource': [{'title': 'Data Source - WGS/WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md'}]}, 'disabled': True, 'name': 'parent1_bam_file', 'title': 'Upload Parent1 BAM File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bam'], 'title': '.bam', 'value': ''}, 'dataStructure': 'The BAM (Binary Alignment/Map) file format is a binary file format used in genomics to store DNA sequence alignment data, typically generated from high-throughput sequencing experiments. BAM files are compressed and indexed versions of SAM (Sequence Alignment/Map) files, which are text-based.', 'demoDataDetails': {'description': 'Ashkenazim Mother HG004. Also other necessary files links are provided below.', 'fileName': 'HG004', 'filePath': 'apps/deeptrio/resources/HG004.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam', 'fileSource': [{'title': 'Data Source - WGS/WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md'}]}, 'disabled': True, 'name': 'parent2_bam_file', 'title': 'Upload Parent2 BAM File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bai'], 'title': '.bai', 'value': ''}, 'dataStructure': 'The .bai file format is a binary index file format used in genomics to index BAM (Binary Alignment/Map) files. A BAM file typically contains a large amount of sequencing data and indexing is necessary to enable efficient access to specific regions of interest in the data.', 'demoDataDetails': {'description': 'Ashkenazim Child HG002. Also other necessary files links are provided below', 'fileName': 'HG002', 'filePath': 'apps/deeptrio/resources/HG002.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam.bai', 'fileSource': [{'title': 'Data Source - WGS/WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md'}]}, 'disabled': False, 'name': 'child_bai_file', 'title': 'Upload Child BAI File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bai'], 'title': '.bai', 'value': ''}, 'dataStructure': 'The .bai file format is a binary index file format used in genomics to index BAM (Binary Alignment/Map) files. A BAM file typically contains a large amount of sequencing data and indexing is necessary to enable efficient access to specific regions of interest in the data.', 'demoDataDetails': {'description': 'Ashkenazim Father HG003. Also other necessary files links are provided below', 'fileName': 'HG003', 'filePath': 'apps/deeptrio/resources/HG003.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam.bai', 'fileSource': [{'title': 'Data Source - WGS/WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md'}]}, 'disabled': False, 'name': 'parent1_bai_file', 'title': 'Upload Parent1 BAI File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bai'], 'title': '.bai', 'value': ''}, 'dataStructure': 'The .bai file format is a binary index file format used in genomics to index BAM (Binary Alignment/Map) files. A BAM file typically contains a large amount of sequencing data and indexing is necessary to enable efficient access to specific regions of interest in the data.', 'demoDataDetails': {'description': 'Ashkenazim Mother HG004. Also other necessary files links are provided below', 'fileName': 'HG004', 'filePath': 'apps/deeptrio/resources/HG004.novaseq.pcr-free.35x.dedup.grch38_no_alt.chr20.bam.bai', 'fileSource': [{'title': 'Data Source - WGS/WES Model Type', 'url': 'https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md'}]}, 'disabled': False, 'name': 'parent2_bai_file', 'title': 'Upload Parent2 BAI File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
BOLT-LMM: Mixed Model Association Testing,BOLT-LMM is used for performing genome-wide association studies (GWAS) to identify genetic variants associated with complex traits or diseases.,"<p>The BOLT-LMM (v2.4.1) algorithm employs a linear mixed model (LMM) to calculate statistical measures for examining the relationship between a phenotype (observable trait) and genotypes (genetic information). BOLT-LMM assumes a Bayesian mixture of normals before the random impact attributed to SNPs other than the one being tested by default. This model generalizes the traditional ""infinitesimal"" mixed model employed by prior mixed-model association approaches (e.g., EMMAX, FaST-LMM, GEMMA, GRAMMAR-Gamma, GCTA-LOCO), allowing for enhanced detection power while reducing false positives.<br><br><span style=""font-weight: bold"">Example use case: </span>GWAS (Genome-Wide Association Study)<span style=""font-weight: bold""><br></span><br><span style=""font-weight: bold"">Technology: </span>Linear mixed model<br><br><span style=""font-weight: bold"">Limitations:<br></span>- Currently, bgen format option is not available.<br>- BOLT-LMM is recommended for analyses of human genetic datasets with more than 5,000 samples.<br>- It is also noted that association test statistics obtained from BOLT-LMM are valid for quantitative traits as well as (reasonably) balanced case-control traits.<br>- The BOLT-LMM method, similar to other mixed-model approaches, can experience reduced effectiveness when applied to the analysis of large sets of case-control data in rare diseases, which may result in decreased statistical power.<br>- The research conducted does not aim to determine how much population structure or relatedness may affect the heritability parameter (h2g) estimated by BOLT-LMM, nor does it carry out or assess genetic prediction using external validation samples from a separate group.<br>- The performance of mixed-model techniques has not been examined in datasets where family structure plays a significant role.<br>- BOLT-LMM has only been evaluated on datasets consisting of human genetic data, which exhibit distinct genetic architectures and patterns of linkage disequilibrium compared to plant and animal data.<br><br><span style=""font-weight: bold"">Metrics: </span>Some of the metrics related to the study can be found in the <span style=""text-decoration: underline; color: #0088FF""><a href=""https://www.nature.com/articles/ng.3190"" target=""_blank"" rel=""noreferrer"">article</a></span>.</p>","Loh, PR., Tucker, G., Bulik-Sullivan, B.Â et al.","['GWAS', 'bed', 'bim', 'fam', 'Structural Bioinformatics']",641db05c9d35843a448c20fd,"[{'input_type': 'user_input', 'name': 'phenoCol', 'placeholder': 'PHENO', 'title': 'Pheno Column', 'tooltip': 'Target phenotype of interest. Please specify the target column you want to be predicted from covariate columns. If you have a column name with any spaces, please remove spaces from target column name.', 'type': 'text', 'validation': '^\\S*$'}, {'input_type': 'user_input', 'name': 'covarCol', 'placeholder': 'CAT_COV', 'title': 'Covariate Column(s) (Optional)', 'tooltip': 'Please specify categorical covariate column(s) in the Covariate File.', 'type': 'text'}, {'input_type': 'user_input', 'name': 'qCovarCol', 'placeholder': 'QCOV1,QCOV2', 'title': 'Quantative Covariate Column(s) (Optional)', 'tooltip': 'Please specify quantative covariate column(s) in the Covariate File.', 'type': 'text'}, {'default_value': 0, 'increment': 0.01, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 0, 'min_value_inclusive': True, 'name': 'impute2MinMAF', 'title': 'MAF (Minumum Allele Frequency) Threshold on IMPUTE2 Genotypes (Optional)', 'tooltip': 'This parameter can be specified when IMPUTE2 dosage file(s) provided. MAF threshold on IMPUTE2 genotypes; lower-MAF SNPs will be ignored', 'type': 'integer'}, {'default_value': 22, 'increment': 1, 'input_type': 'user_input', 'max_value_included': True, 'min_value': 0, 'min_value_inclusive': True, 'name': 'Nautosomes', 'title': 'Number of Autosomes (Optional)', 'tooltip': 'Number of autosomes for organism being studied. It is option for non-human analyses. Default: 22 (Human)', 'type': 'integer'}, {'default_value': False, 'input_type': 'checkbox', 'name': 'verboseStats', 'title': 'verboseStats Flag (Optional)', 'optional': True, 'tooltip': 'To output chi-square statistics for all association tests, use this checkbox'}, {'default_value': {'label': 'None', 'value': 'None'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'geneticMapFile', 'options': [{'label': 'None', 'value': 'None'}, {'label': 'hg17', 'value': 'apps/bolt_lmm/resources/genetic_map_hg17_withX.txt.gz'}, {'label': 'hg18', 'value': 'apps/bolt_lmm/resources/genetic_map_hg18_withX.txt.gz'}, {'label': 'hg19', 'value': 'apps/bolt_lmm/resources/genetic_map_hg19_withX.txt.gz'}, {'label': 'hg38', 'value': 'apps/bolt_lmm/resources/genetic_map_hg38_withX.txt.gz'}], 'title': 'Geneticmapfile (Optional)', 'tooltip': 'Oxford-format file for interpolating genetic distances: tables/genetic_map_hg##.txt.gz. The BOLT-LMM software provides reference maps that allow for interpolation of genetic map coordinates from SNP physical positions in situations where the PLINK bim file lacks genetic coordinates measured in Morgans. This is important because the BOLT-LMM association testing algorithm relies on genetic positions to avoid issues related to genetic proximity. By using these reference maps, BOLT-LMM can effectively account for the genetic proximity of SNPs, even when the PLINK bim file does not contain genetic coordinate information.You may use the --geneticMapFile option even if your PLINK bim file does contain genetic coordinates; in this case, the genetic coordinates in the bim file will be ignored, and interpolated coordinates will be used instead'}]","[{'allowedFormats': {'fileExtensions': ['fam', 'fam.gz'], 'title': '.fam, .fam.gz', 'value': '.fam, .fam.gz'}, 'dataStructure': 'PLINK .fam file (note: file names ending in .gz are auto-[de]compressed). Sample information file accompanying a .bed binary genotype table.A text file with no header line, and one line per sample.', 'demoDataDetails': {'description': ""This is demo .fam file from software's example files."", 'fileName': 'EUR_subset.fam', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.fam', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}, {'title': 'Data Format', 'url': 'https://www.cog-genomics.org/plink/1.9/formats#fam'}]}, 'disabled': False, 'name': 'fam', 'title': 'Upload .fam File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bim', 'bim.gz'], 'title': '.bim, bim.gz', 'value': '.bim, bim.gz'}, 'dataStructure': 'PLINK .bim file. Extended variant information file accompanying a .bed binary genotype table. ', 'demoDataDetails': {'description': ""This is demo .bim file from software's example files."", 'fileName': 'EUR_subset.bim', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.bim', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}, {'title': 'Data Format', 'url': 'https://www.cog-genomics.org/plink/1.9/formats#bim'}]}, 'disabled': False, 'name': 'bim', 'title': 'Upload .bim File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['bed', 'bed.gz'], 'title': '.bed, .bed.gz', 'value': '.bed, .bed.gz'}, 'dataStructure': ""PLINK .bed file. Primary representation of genotype calls at biallelic variants. Must be accompanied by .bim and .fam files. Do not confuse this with the UCSC Genome Browser's BED format, which is totally different."", 'demoDataDetails': {'description': ""This is demo .bed file from software's example files."", 'fileName': 'EUR_subset.bed', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.bed', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}, {'title': 'Data Format', 'url': 'https://www.cog-genomics.org/plink/1.9/formats#bed'}]}, 'disabled': False, 'name': 'bed', 'title': 'Upload .bed File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tab', 'tab.gz', 'txt', 'txt.gz'], 'title': '.tab, .tab.gz, .txt, .txt.gz', 'value': '.tab, .tab.gz, .txt, .txt.gz'}, 'dataStructure': 'Phenotype file (header required; FID IID must be first two columns)', 'demoDataDetails': {'description': ""This is demo phenotype file from software's example files."", 'fileName': 'EUR_subset.pheno2.covars', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.pheno2.covars', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'phenoFile', 'title': 'Upload <phenoFile> File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tab.gz'], 'title': '.tab.gz', 'value': '.tab.gz'}, 'dataStructure': 'A table of reference LD scores is needed to calibrate the BOLT-LMM statistic. Reference LD scores appropriate for analyses of European-ancestry samples are provided in the example file. For analyses of non-European data, we recommend computing LD scores using the LDSC software on an ancestry-matched subset of the 1000 Genomes samples', 'demoDataDetails': {'description': ""This is demo LDScore file from software's example files."", 'fileName': 'LDSCORE.1000G_EUR.tab.gz', 'filePath': 'apps/bolt_lmm/resources/LDSCORE.1000G_EUR.tab.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'LDscoresFile', 'title': 'Upload LDScores File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt'], 'title': '.txt', 'value': '.txt'}, 'dataStructure': 'File(s) listing individuals to ignore (no header; FID IID must be first two columns). Data structure format should be same as .fam file.', 'demoDataDetails': {'description': ""This is demo remove .txt file from software's example files."", 'fileName': 'EUR_subset.remove.txt', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.remove', 'fileSource': [{'title': 'Data Source', 'url': 'TEST'}]}, 'disabled': False, 'multiple': True, 'name': 'remove', 'optional': True, 'title': 'Upload <remove> File(s) (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'txt.gz'], 'title': '.txt, .txt.gz', 'value': '.txt, .txt.gz'}, 'dataStructure': 'File(s) listing SNPs to ignore (no header; SNP ID must be first column)', 'demoDataDetails': {'description': ""This is demo exclude .txt file from software's example files."", 'fileName': 'EUR_subset.remove.txt', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.exclude', 'fileSource': [{'title': 'Data Source', 'url': 'TEST'}]}, 'disabled': False, 'multiple': True, 'name': 'exclude', 'optional': True, 'title': 'Upload <exclude> File(s) (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['tab', 'tab.gz', 'txt', 'txt.gz'], 'title': '.tab, .tab.gz, .txt, .txt.gz', 'value': '.tab .tab.gz, .txt, .txt.gz'}, 'dataStructure': 'Covariate file (header required; FID IID must be first two columns)', 'demoDataDetails': {'description': ""This is demo covariate file from software's example files."", 'fileName': 'EUR_subset.pheno2.txt', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.pheno2.covars', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'covarFile', 'optional': True, 'title': 'Upload Covariate File (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt'], 'title': '.tab, .tab.gz', 'value': '.tab, .tab.gz'}, 'dataStructure': 'File(s) listing SNPs to use in model (i.e.,GRM) (default: use all non-excluded SNPs) Note that even when a file of --modelSnps is specified, all SNPs in the genotype data are still tested for association; only the random effects in the mixed model are restricted to the --modelSnps. Also note that BOLT-LMM automatically performs leave-one-chromosome-out (LOCO) analysis, leaving out SNPs from the chromosome containing the SNP being tested in order to avoid proximal contamination.', 'demoDataDetails': {'description': ""This is demo modelSnps file from software's example files."", 'fileName': 'EUR_subset.modelSnps', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.modelSnps', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'multiple': True, 'name': 'modelSnps', 'optional': True, 'title': 'Upload <modelSnps> File (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'tab', 'gz'], 'title': '.tab, .tab.gz, .txt, .txt.gz', 'value': '.tab, .tab.gz, .txt, .txt.gz'}, 'dataStructure': 'File(s) containing imputed SNP dosages to test for association.\nExample:\nrsID\tchr\tpos\tallele1\tallele0\t[dosage = E[#allele1]] x N', 'demoDataDetails': {'description': ""This is demo imputed SNPs in dosage file from software's example files."", 'fileName': 'EUR_subset.dosage.txt', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.dosage.chr17first100', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'multiple': True, 'name': 'dosageFile', 'optional': True, 'title': 'Upload Dosage File(s) (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'txt.gz'], 'title': '.txt,.txt.gz', 'value': '.txt'}, 'dataStructure': '(This file should be provided when dosageFile is given.) File listing FIDs and IIDs of samples in dosageFile(s), one line per sample', 'demoDataDetails': {'description': ""This is demo dosage ID file from software's example files."", 'fileName': 'EUR_subset.dosage.indivs', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.dosage.indivs', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'dosageFidIidFile', 'optional': True, 'title': 'Upload Dosage ID File (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'gz', 'tab'], 'title': '.tab, .tab.gz, .txt, .txt.gz', 'value': '.txt, .tab.gz, .txt, .txt.gz, .gz'}, 'dataStructure': 'Please specify imputed SNPs as output by the IMPUTE2 The IMPUTE2 genotype file format is as follows:\nsnpID\trsID\tpos\tallele1\tallele0\t[p(11) p(10) p(00)] x N', 'demoDataDetails': {'description': ""This is demo IMPUTE2 file from software's example files."", 'fileName': 'EUR_subset.impute2.chr17first100.gz', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.impute2.chr17first100.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'multiple': True, 'name': 'impute2files', 'optional': True, 'title': 'Upload IMPUTE2 File(s) (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'gz'], 'title': '.txt,.txt.gz', 'value': '.txt,.txt.gz'}, 'dataStructure': '(This file should be provided when IMPUTE2 file(s) is given.) List of [chr file] pairs containing IMPUTE2 SNP probabilities to test for association.\nExample:\n17\tEUR_subset.impute2.chr17second100\n22\tEUR_subset.impute2.chr22last100.gz', 'demoDataDetails': {'description': ""This is demo IMPUTE2 list file from software's example files."", 'fileName': 'EUR_subset.impute2FileListcopy.txt', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.impute2FileListcopy.txt', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'impute2FileList', 'optional': True, 'title': 'Upload IMPUTE2 List File (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'gz'], 'title': '.txt,.txt.gz', 'value': '.txt, .txt.gz'}, 'dataStructure': '(This file should be provided when IMPUTE2 file(s) is given.). File listing FIDs and IIDs of samples in IMPUTE2 files, one line per sample.\nExample:\n1\tHG00096\n2\tHG00097\n3\tHG00099', 'demoDataDetails': {'description': ""This is demo IMPUTE2 ID file from software's example files."", 'fileName': 'EUR_subset.impute2.indivs', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.impute2.indivs', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'impute2FidIidFile', 'optional': True, 'title': 'Upload IMPUTE2 ID File (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt', 'gz'], 'title': '.txt,.txt.gz', 'value': '.txt, .txt.gz'}, 'dataStructure': 'You may also specify imputed SNPs as output by the Ri-copili pipeline and plink2 --dosage format=2. This file format consists of file pairs: (1)PLINK map files containing information about SNP locations; and (2) genotype probability files in the 2-dosage format.\nExample:\n2-dosage format:\nSNP\tA1\tA2\t[FID IID] x N', 'demoDataDetails': {'description': ""This is demo 2-dosage format file from software's example files."", 'fileName': 'EUR_subset.dosage2.chr17first100.gz', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.dosage2.chr17first100.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'multiple': True, 'name': '2dosagefiles', 'optional': True, 'title': 'Upload 2-Dosage File(s) (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['map'], 'title': '.map', 'value': '.map'}, 'dataStructure': '(This file should be provided when 2-Dosage file(s) is given.). You may also specify imputed SNPs as output by the Ri-copili pipeline and plink2 --dosage format=2. This file format consists of file pairs: (1)PLINK map files containing information about SNP locations; and (2) genotype probability files in the 2-dosage format.\nExample:\n2-dosage format:\nSNP\tA1\tA2\t[FID IID] x N\n.map file format:\nchr\trsID\tallele1\tallele0\t[p(11) p(10)] x N', 'demoDataDetails': {'description': ""This is demo 2-dosage .map format file from software's example files."", 'fileName': 'EUR_subset.dosage2.chr17first100.map', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.dosage2.chr17first100.map', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'multiple': True, 'name': '2dosagemapfile', 'optional': True, 'title': 'Upload 2-Dosage <.map> Format File(s) (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['txt'], 'title': '.txt', 'value': '.txt'}, 'dataStructure': '(This file should be provided when 2-Dosage file(s) is given.). List of [map dosage] file pairs with 2-dosage SNP probabilities (Ricopili/plink2 --dosage format=2) to test for association', 'demoDataDetails': {'description': ""This is demo 2-dosage list file from software's example files."", 'fileName': 'EUR_subset.dosage2FileListcopy.txt', 'filePath': 'apps/bolt_lmm/resources/EUR_subset.dosage2FileListcopy.txt', 'fileSource': [{'title': 'Data Source', 'url': 'https://alkesgroup.broadinstitute.org/BOLT-LMM/downloads/'}]}, 'disabled': False, 'name': 'dosage2FileList', 'optional': True, 'title': 'Upload 2-Dosage File List (Optional)', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
maxATAC: Transcription-Factor Binding Prediction From ATAC-seq with Deep Neural Networks,maxATAC is a user-friendly software suite that uses deep neural network models to predict transcription factor binding sites from ATAC-seq data.,"<p>Transcription factors play a critical role in connecting the DNA sequence to gene expression in different types of cells. By understanding how, where, and when these factors bind to chromatin, we can gain insights into the gene regulatory networks that control cellular behavior. This knowledge can help us unravel the complex mechanisms behind gene expression, potentially leading to new therapies for various diseases. maxATAC is the most extensive collection of state-of-the-art TFBS models available to date, with models available for 127 human TFs. Additionally, MaxATAC can perform well on primary cells and single-cell ATAC-seq data, making it a valuable tool for predicting TFBS in vivo.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Predicting TFs' binding locations can significantly aid biological research by supplying reference materials for experimental validation.</p>
<p><span style=""font-weight: bold"">Technology:</span> Deep Neural Network</p>
<p><span style=""font-weight: bold"">Limitation:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Currently, only the bulk ATAC-seq option is available.</li>
<li style=""list-style-type: disc"">Parameters in the <span style=""font-style: italic; color: #0088FF; text-decoration: underline""><a href=""https://github.com/MiraldiLab/maxATAC/blob/main/docs/readme/prepare.md"" target=""_blank"" rel=""noreferrer"">prepare</a></span> and <span style=""font-style: italic; color: #0088FF; text-decoration: underline""><a href=""https://github.com/MiraldiLab/maxATAC/blob/main/docs/readme/predict.md"" target=""_blank"" rel=""noreferrer"">predict</a></span> steps are kept default.</li>
<li style=""list-style-type: disc"">The batch size parameter is set to 512.</li>
<li style=""list-style-type: disc"">Currently, only human organism models are applicable. (HG38 reference genome only)</li></ul>","CazaresÂ TA, RizviÂ FW, IyerÂ B, ChenÂ X, KotliarÂ M, et al.","['Deep Neural Network (DNN)', 'bam', 'Computational Biology and Bioinformatics']",644128ded745a5b4de568800,"[{'default_value': {'label': 'CTCF', 'value': 'CTCF'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'tf', 'options': [{'label': 'CTCF', 'value': 'CTCF'}, {'label': 'MYBL2', 'value': 'MYBL2'}, {'label': 'ELF4', 'value': 'ELF4'}, {'label': 'CREM', 'value': 'CREM'}, {'label': 'NFIA', 'value': 'NFIA'}, {'label': 'NFATC3', 'value': 'NFATC3'}, {'label': 'REST', 'value': 'REST'}, {'label': 'SREBF2', 'value': 'SREBF2'}, {'label': 'POU5F1', 'value': 'POU5F1'}, {'label': 'ETV6', 'value': 'ETV6'}, {'label': 'ZBTB33', 'value': 'ZBTB33'}, {'label': 'RUNX1', 'value': 'RUNX1'}, {'label': 'NKRF', 'value': 'NKRF'}, {'label': 'MAFK', 'value': 'MAFK'}, {'label': 'ARID3A', 'value': 'ARID3A'}, {'label': 'NR2F2', 'value': 'NR2F2'}, {'label': 'EGR1', 'value': 'EGR1'}, {'label': 'ZBTB40', 'value': 'ZBTB40'}, {'label': 'ATF7', 'value': 'ATF7'}, {'label': 'ZNF24', 'value': 'ZNF24'}, {'label': 'NR2F6', 'value': 'NR2F6'}, {'label': 'NR2F1', 'value': 'NR2F1'}, {'label': 'ZBTB11', 'value': 'ZBTB11'}, {'label': 'ZEB1', 'value': 'ZEB1'}, {'label': 'GABPA', 'value': 'GABPA'}, {'label': 'ZNF592', 'value': 'ZNF592'}, {'label': 'ELK1', 'value': 'ELK1'}, {'label': 'NFIC', 'value': 'NFIC'}, {'label': 'SREBF1', 'value': 'SREBF1'}, {'label': 'PKNOX1', 'value': 'PKNOX1'}, {'label': 'PBX3', 'value': 'PBX3'}, {'label': 'IKZF1', 'value': 'IKZF1'}, {'label': 'FOSL2', 'value': 'FOSL2'}, {'label': 'FOXA1', 'value': 'FOXA1'}, {'label': 'SKIL', 'value': 'SKIL'}, {'label': 'RXRA', 'value': 'RXRA'}, {'label': 'ZNF569', 'value': 'ZNF569'}, {'label': 'ATF1', 'value': 'ATF1'}, {'label': 'NEUROD1', 'value': 'NEUROD1'}, {'label': 'BHLHE40', 'value': 'BHLHE40'}, {'label': 'IRF3', 'value': 'IRF3'}, {'label': 'MAZ', 'value': 'MAZ'}, {'label': 'JUND', 'value': 'JUND'}, {'label': 'ZSCAN29', 'value': 'ZSCAN29'}, {'label': 'USF1', 'value': 'USF1'}, {'label': 'NFYA', 'value': 'NFYA'}, {'label': 'CEBPD', 'value': 'CEBPD'}, {'label': 'ELF1', 'value': 'ELF1'}, {'label': 'ZZZ3', 'value': 'ZZZ3'}, {'label': 'MYC', 'value': 'MYC'}, {'label': 'GATA4', 'value': 'GATA4'}, {'label': 'GATA3', 'value': 'GATA3'}, {'label': 'CEBPB', 'value': 'CEBPB'}, {'label': 'SP1', 'value': 'SP1'}, {'label': 'ATF2', 'value': 'ATF2'}, {'label': 'FOXK2', 'value': 'FOXK2'}, {'label': 'TCF12', 'value': 'TCF12'}, {'label': 'ZNF274', 'value': 'ZNF274'}, {'label': 'SOX6', 'value': 'SOX6'}, {'label': 'ZNF217', 'value': 'ZNF217'}, {'label': 'STAT5A', 'value': 'STAT5A'}, {'label': 'MAFF', 'value': 'MAFF'}, {'label': 'TBP', 'value': 'TBP'}, {'label': 'TCF7', 'value': 'TCF7'}, {'label': 'MYB', 'value': 'MYB'}, {'label': 'NR2C2', 'value': 'NR2C2'}, {'label': 'CBX2', 'value': 'CBX2'}, {'label': 'ZNF407', 'value': 'ZNF407'}, {'label': 'NFYB', 'value': 'NFYB'}, {'label': 'SMAD5', 'value': 'SMAD5'}, {'label': 'NANOG', 'value': 'NANOG'}, {'label': 'HSF1', 'value': 'HSF1'}, {'label': 'NR2C1', 'value': 'NR2C1'}, {'label': 'MAX', 'value': 'MAX'}, {'label': 'SMAD1', 'value': 'SMAD1'}, {'label': 'MNT', 'value': 'MNT'}, {'label': 'NRF1', 'value': 'NRF1'}, {'label': 'ETS1', 'value': 'ETS1'}, {'label': 'KLF5', 'value': 'KLF5'}, {'label': 'ZNF143', 'value': 'ZNF143'}, {'label': 'ASH1L', 'value': 'ASH1L'}, {'label': 'PAX8', 'value': 'PAX8'}, {'label': 'RFX5', 'value': 'RFX5'}, {'label': 'LEF1', 'value': 'LEF1'}, {'label': 'FOSL1', 'value': 'FOSL1'}, {'label': 'MBD2', 'value': 'MBD2'}, {'label': 'CEBPZ', 'value': 'CEBPZ'}, {'label': 'MXI1', 'value': 'MXI1'}, {'label': 'CREB1', 'value': 'CREB1'}, {'label': 'ESRRA', 'value': 'ESRRA'}, {'label': 'BACH1', 'value': 'BACH1'}, {'label': 'SRF', 'value': 'SRF'}, {'label': 'ZFX', 'value': 'ZFX'}, {'label': 'TCF7L2', 'value': 'TCF7L2'}, {'label': 'ZNF384', 'value': 'ZNF384'}, {'label': 'HES1', 'value': 'HES1'}, {'label': 'YY1', 'value': 'YY1'}, {'label': 'ZBTB7A', 'value': 'ZBTB7A'}, {'label': 'ARNT', 'value': 'ARNT'}, {'label': 'GATAD2B', 'value': 'GATAD2B'}, {'label': 'YBX1', 'value': 'YBX1'}, {'label': 'SETDB1', 'value': 'SETDB1'}, {'label': 'CUX1', 'value': 'CUX1'}, {'label': 'SIX5', 'value': 'SIX5'}, {'label': 'SPI1', 'value': 'SPI1'}, {'label': 'TEAD4', 'value': 'TEAD4'}, {'label': 'ATF3', 'value': 'ATF3'}, {'label': 'MEF2A', 'value': 'MEF2A'}, {'label': 'ZBED1', 'value': 'ZBED1'}, {'label': 'E4F1', 'value': 'E4F1'}, {'label': 'ZNF687', 'value': 'ZNF687'}, {'label': 'E2F8', 'value': 'E2F8'}, {'label': 'FOS', 'value': 'FOS'}, {'label': 'RELA', 'value': 'RELA'}, {'label': 'ZKSCAN1', 'value': 'ZKSCAN1'}, {'label': 'NFE2L2', 'value': 'NFE2L2'}, {'label': 'JUNB', 'value': 'JUNB'}, {'label': 'FOXP1', 'value': 'FOXP1'}, {'label': 'USF2', 'value': 'USF2'}, {'label': 'ZNF207', 'value': 'ZNF207'}, {'label': 'RFX1', 'value': 'RFX1'}, {'label': 'KMT2A', 'value': 'KMT2A'}, {'label': 'JUN', 'value': 'JUN'}, {'label': 'ZHX2', 'value': 'ZHX2'}, {'label': 'FOXM1', 'value': 'FOXM1'}, {'label': 'ZNF282', 'value': 'ZNF282'}, {'label': 'NFXL1', 'value': 'NFXL1'}], 'title': 'Select TF Model', 'tooltip': 'User must provide either the TF name that they want to make predictions for. The best model will be used and the correct threshold file will be provided for peak calling.'}, {'input_type': 'checkbox', 'name': 'skip_dedup', 'title': 'Skip Dedup', 'tooltip': 'It is important to remove PCR duplicates from your ATAC-seq data if you have not done so already. Include this flag to perform PCR deduplication of the input BAM file if you know that it has not been deduplicated. Skipping this step will speed up data processing. Defualt: False', 'default_value': False, 'optional': True}]","[{'allowedFormats': {'fileExtensions': ['bam'], 'title': '.bam', 'value': '.bam'}, 'dataStructure': 'The BAM (Binary Alignment/Map) file format is a binary file format used in genomics to store DNA sequence alignment data, typically generated from high-throughput sequencing experiments. BAM files are compressed and indexed versions of SAM (Sequence Alignment/Map) files, which are text-based.', 'demoDataDetails': {'description': 'SRX2717911 bam file used. FASTQ files downloaded from SRA database and trimmed with trim_galore software. After that, STAR alignment software was used to for alignment step. .sam format converted to .bam format with samtools.', 'fileName': 'SRX2717911.bam', 'filePath': 'apps/maxatac/resources/SRR5427886_STAR_hg38.sorted.bam', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.ncbi.nlm.nih.gov/sra/SRX2717911%5Baccn%5D'}]}, 'disabled': True, 'name': 'bam', 'title': 'Upload BAM File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}]"
Bonito: Deep learning-based basecaller for Oxford Nanopore Reads,Bonito is an open-source basecaller for ONT reads.,"<p>A deep learning-based basecaller by Oxford Nanopore Technologies (ONT)</p>
<p><span style=""font-weight: bold"">Example use case: </span>Sequencing</p>
<p><span style=""font-weight: bold"">Technology: </span>A neural network architecture that consists of a single convolutional layer followed by three stacked bidirectional gated recurrent unit layers</p>
<p><span style=""font-weight: bold"">Limitations: </span>Works only with reads from ONT devices - does not work well with modified mRNA reads</p>",Oxford Nanopore Technologies,"['Base Caller', 'zip', 'fast5', 'Computational Biology and Bioinformatics']",64633cd5a81ca5a299cbeb9d,"[{'default_value': {'label': 'DNA_R9.4.1_E8 | FAST@3.4', 'value': 'dna_r9.4.1_e8_fast@v3.4'}, 'input_type': 'dropdown', 'name': 'model_type', 'options': [{'label': 'DNA_R9.4.1_E8 | FAST@v3.4', 'value': 'dna_r9.4.1_e8_fast@v3.4'}, {'label': 'DNA_R9.4.1_E8 | HAC@v3.3', 'value': 'dna_r9.4.1_e8_hac@v3.3'}, {'label': 'DNA_R9.4.1_E8 | SUP@v3.3', 'value': 'dna_r9.4.1_e8_sup@v3.3'}, {'label': 'DNA_R10.4.1_E8.2_400bps | FAST@v3.5.2', 'value': 'dna_r10.4.1_e8.2_400bps_fast@v3.5.2'}, {'label': 'DNA_R10.4.1_E8.2_400bps | HAC@v3.5.2', 'value': 'dna_r10.4.1_e8.2_400bps_hac@v3.5.2'}, {'label': 'DNA_R10.4.1_E8.2_400bps | SUP@v3.5.2', 'value': 'dna_r10.4.1_e8.2_400bps_sup@v3.5.2'}, {'label': 'DNA_R10.4.1_E8.2_260bps | FAST@v3.5.2', 'value': 'dna_r10.4.1_e8.2_260bps_fast@v3.5.2'}, {'label': 'DNA_R10.4.1_E8.2_260bps | HAC@v3.5.2', 'value': 'dna_r10.4.1_e8.2_260bps_hac@v3.5.2'}, {'label': 'DNA_R10.4.1_E8.2_260bps | SUP@v3.5.2', 'value': 'dna_r10.4.1_e8.2_260bps_sup@v3.5.2'}, {'label': 'DNA_R10.4.1_E8.2_400bps | FAST@v4.0.0', 'value': 'dna_r10.4.1_e8.2_400bps_fast@v4.0.0'}, {'label': 'DNA_R10.4.1_E8.2_400bps | HAC@v4.0.0', 'value': 'dna_r10.4.1_e8.2_400bps_hac@v4.0.0'}, {'label': 'DNA_R10.4.1_E8.2_400bps | SUP@v4.0.0', 'value': 'dna_r10.4.1_e8.2_400bps_sup@v4.0.0'}, {'label': 'DNA_R10.4.1_E8.2_260bps | FAST@v4.0.0', 'value': 'dna_r10.4.1_e8.2_260bps_fast@v4.0.0'}, {'label': 'DNA_R10.4.1_E8.2_260bps | HAC@v4.0.0', 'value': 'dna_r10.4.1_e8.2_260bps_hac@v4.0.0'}, {'label': 'DNA_R10.4.1_E8.2_260bps | SUP@v4.0.0', 'value': 'dna_r10.4.1_e8.2_260bps_sup@v4.0.0'}, {'label': 'DNA_R10.4.1_E8.2_400bps | FAST@v4.1.0', 'value': 'dna_r10.4.1_e8.2_400bps_fast@v4.1.0'}, {'label': 'DNA_R10.4.1_E8.2_400bps | HAC@v4.1.0', 'value': 'dna_r10.4.1_e8.2_400bps_hac@v4.1.0'}, {'label': 'DNA_R10.4.1_E8.2_400bps | SUP@v4.1.0', 'value': 'dna_r10.4.1_e8.2_400bps_sup@v4.1.0'}, {'label': 'DNA_R10.4.1_E8.2_260bps | FAST@v4.1.0', 'value': 'dna_r10.4.1_e8.2_260bps_fast@v4.1.0'}, {'label': 'DNA_R10.4.1_E8.2_260bps | HAC@v4.1.0', 'value': 'dna_r10.4.1_e8.2_260bps_hac@v4.1.0'}, {'label': 'DNA_R10.4.1_E8.2_260bps | SUP@v4.1.0', 'value': 'dna_r10.4.1_e8.2_260bps_sup@v4.1.0'}], 'title': 'MODEL TYPE', 'tooltip': 'Please select a model that matches your Oxford Nanopore Sequencing chemistry! SUP stands for <Super High Accuracy>. This model is the most accurate, but it is also the slowest. HAC stands for <High Accuracy>. This model is less accurate than SUP, but it is faster. FAST stands for <Fast>. This model is the least accurate, but it is the fastest.'}, {'default_value': {'label': '.fastq', 'value': 'fastq'}, 'disabled': True, 'input_type': 'dropdown', 'name': 'output_format', 'options': [{'label': '.fastq', 'value': 'fastq'}, {'label': '.sam', 'value': 'sam'}, {'label': '.bam', 'value': 'bam'}, {'label': '.cram', 'value': 'cram'}], 'title': 'OUTPUT FORMAT', 'tooltip': 'Bonito supports writing aligned/unaligned\xa0fastq, sam, bam, cram format files.'}]","[{'allowedFormats': {'fileExtensions': ['zip', 'gz'], 'title': '.gz,.zip', 'value': ''}, 'dataStructure': 'FAST5 files are Hierarchical Data Format 5 (HDF5) files which store raw current-signal data generated from ONT devices. FAST5 files should be provided in compressed version. Either .zip or .gz extensions can be used. Compressed file should contain only reads files. Please do NOT compress a folder that contains files!', 'demoDataDetails': {'description': 'Files from ONT sequencing of SARS-CoV-2. ', 'fileName': 'SP1-3-fast5', 'filePath': 'apps/bonito/resources/SP1_mapped.tar.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/clara-parabricks/Compute4COVID/tree/master/long_read_basecalling/data'}]}, 'disabled': True, 'name': 'input_file', 'title': 'Upload Oxford Nanopore Read File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}]"
nf-encyclopedia: A NextFlow pipeline for chromatogram library DIA proteomics workflows,"nf-encyclopedia is a NextFlow pipeline that analyzes DIA proteomics experiments, including those with or without chromatogram libraries. It integrates MSconvert, EncyclopeDIA, and MSstats to process mass spectra and generate quantified peptides and proteins.","<p>Data-independent acquisition (DIA) mass spectrometry techniques are highly valuable for comprehensive and systematic quantification of the proteome. However, the current landscape of open-source tools dedicated to analyzing DIA proteomics experiments remains limited. Moreover, the effective utilization of gas phase fractionated (GPF) chromatogram libraries for improved peptide detection and quantification in DIA experiments is lacking.</p>
<p>To bridge this gap, a novel open-source NextFlow pipeline called nf-encyclopedia was developed. This pipeline seamlessly integrates three open-source tools, namely MSConvert, EncyclopeDIA, and MSstats, forming a comprehensive solution for analyzing DIA proteomics experiments, regardless of the use of chromatogram libraries. <span style=""text-decoration: underline; color: #0088FF""><a href=""https://superbioai.notion.site/nf-encylopedia-6ccbda70600a4ced9e2a47b41bd60f58"" target=""_blank"" rel=""noreferrer"">Further information on this app can be found here.</a></span></p>
<p><span style=""font-weight: bold"">Example use case:</span> DIA mass spectrometry data analysis</p>
<p><span style=""font-weight: bold"">Technology:</span> Nextflow</p>
<p><span style=""font-weight: bold"">Limitation:</span> Some of the parameters were kept default. Please see this <span style=""text-decoration: underline; color: #0088FF""><a href=""https://talusbio.github.io/nf-encyclopedia/parameters/"" >page</a></span> for more detail.</p>","Carolyn Allen, Rico Meinl, Brian C Searle, Seth Just, Lindsay K Pino, William E Fondrie","['Mass Spectrometry', 'csv', 'fasta', 'Proteomics']",646f2d37a81ca5a299cbecb7,"[{'default_value': {'label': 'equalizeMedians', 'value': 'equalizeMedians'}, 'input_type': 'dropdown', 'name': 'msstats_normalization', 'options': [{'label': 'equalizeMedians', 'value': 'equalizeMedians'}, {'label': 'quantile', 'value': 'quantile'}, {'label': 'none', 'value': 'none'}], 'title': 'Msstats Normalization', 'tooltip': ""The normalization method employed by MSstats, which can be either 'equalizeMedians', 'quantile', or 'none', is specified in the analysis. The default method is 'equalizeMedians', but researchers have the option to choose a different normalization approach according to their specific requirements.""}, {'default_value': False, 'input_type': 'checkbox', 'name': 'aggregate', 'optional': True, 'title': 'Aggregate', 'tooltip': 'When the Aggregate groups into a single analysis option is set to true, each group in the analysis is searched separately using EncyclopeDIA against its corresponding chromatogram library. The search results from each group are then combined, and the false discovery rate (FDR) is estimated for the entire set of groups. On the other hand, when the option is set to false (the default), the groups are analyzed individually, and the FDR is estimated within each group separately.'}, {'default_value': False, 'input_type': 'checkbox', 'name': 'msstats_reports', 'optional': True, 'title': 'Msstats Reports', 'tooltip': 'Generate MSstats reports. Default: false'}]","[{'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': ''}, 'dataStructure': '<p>The input file used for the analysis is a CSV file that provides a list of the mass spectrometry data files to be processed. This file should consist of at least two columns: ""<strong>file</strong>"" and ""<strong>chrlib</strong>"". The ""<strong>file</strong>"" column contains the paths to the mass spectrometry data files, which should be in formats compatible with MSconvert. The ""<strong>chrlib</strong>"" column specifies whether a file should be considered part of a chromatogram library, indicated by true or false values.<br />In addition to these mandatory columns, an optional ""group"" column can be included to specify which chromatogram library files should be used for analyzing each quantitative run. Furthermore, the ""<strong>condition</strong>"" and ""<strong>bioreplicate</strong>"" columns can also be included, which will be utilized by MSstats for further analysis.<br />The format of the input file allows for flexible configuration and customization of the analysis, catering to the specific experimental design and requirements.</p>', 'demoDataDetails': {'description': 'Example input.csv file', 'fileName': 'input.csv', 'filePath': 'apps/nf_encyclopedia/resources/input.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/clara-parabricks/Compute4COVID/tree/master/long_read_basecalling/data'}], 'previewFileName': 'apps/nf_encyclopedia/resources/demo_input.csv'}, 'disabled': False, 'name': 'input_csv', 'supportsPreview': True, 'title': 'Upload Input File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}, {'title': 'Local', 'type': 'local'}]}, {'allowedFormats': {'fileExtensions': ['raw', 'mzML.gz'], 'title': '.raw, .mzML.gz', 'value': ''}, 'dataStructure': 'The .raw file format is commonly used in mass spectrometry data analysis, including DIA experiments. It is a binary file format that stores the raw data acquired from the mass spectrometer during the experiment. The specific data structure of a .raw file can vary depending on the instrument manufacturer and software used for data acquisition. The .mzML.gz file format is commonly used in mass spectrometry data analysis, including DIA experiments. It is a compressed XML-based file format that conforms to the mzML standard developed by the Proteomics Standards Initiative (PSI). The .mzML.gz file contains structured data that represents the acquired mass spectrometry data in a standardized and interoperable manner.', 'demoDataDetails': {'description': 'Showcase files from Center for Computational Mass Spectrometry Database', 'fileName': 'data_files', 'filePath': 'apps/nf_encyclopedia/resources/data_files.tar.gz', 'fileSource': [{'title': 'Data Source', 'url': 'https://massive.ucsd.edu/ProteoSAFe/dataset_files.jsp?task=e340c79fbdc64e14a710265761bfeed5'}]}, 'disabled': False, 'multiple': True, 'name': 'data_files', 'title': 'Upload Data Files', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['dlib'], 'title': '.dlib', 'value': ''}, 'dataStructure': 'A spectral library in EncyclopeDIAâs DLIB format. See the EncyclopeDIA documentation for details. The .dlib file format is specific to the EncyclopeDIA software tool used for DIA (Data-Independent Acquisition) analysis. It is a binary file format that contains the precomputed chromatogram libraries required for peptide identification and quantification in DIA experiments. The data structure of a .dlib file is organized as follows:', 'demoDataDetails': {'description': 'Example dlib file from Prosit-Derived Spectral Libraries', 'fileName': 'saccharomyces_cerevisiae_prosit_generated_library', 'filePath': 'apps/nf_encyclopedia/resources/saccharomyces_cerevisiae_prosit_generated_library.dlib', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.proteomesoftware.com/hc/en-us/articles/360035151172-Prosit-Derived-Spectral-Libraries-for-Scaffold-DIA-Searches'}]}, 'disabled': False, 'multiple': True, 'name': 'dlib_file', 'title': 'Upload .dlib File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['fasta'], 'title': '.fasta', 'value': ''}, 'dataStructure': 'The FASTA containing the subset of proteins sequences for which to search. The .fasta file format is a commonly used file format in bioinformatics, including DIA (Data-Independent Acquisition) analysis. It is a text-based format that stores protein or nucleotide sequence information. The .fasta file format serves as a reference database containing protein sequences that can be used for peptide identification in DIA analysis. Software tools like EncyclopeDIA or other search engines compare the acquired mass spectrometry data against the protein sequences stored in the .fasta file to identify the peptides and subsequently quantify them.', 'demoDataDetails': {'description': 'Example fasta file from Prosit-Derived Spectral Libraries', 'fileName': 'saccharomyces_cerevisiae_reviewed_uniprot', 'filePath': 'apps/nf_encyclopedia/resources/saccharomyces_cerevisiae_reviewed_uniprot.fasta', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.proteomesoftware.com/hc/en-us/articles/360035151172-Prosit-Derived-Spectral-Libraries-for-Scaffold-DIA-Searches'}]}, 'disabled': False, 'multiple': True, 'name': 'fasta_file', 'title': 'Upload .fasta File', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv'], 'title': '.csv', 'value': ''}, 'dataStructure': 'The contrast matrix for hypothesis tests in MSstats is specified as a CSV file. Each column of the file represents a condition from the input CSV file, and the first column specifies the name of each hypothesis test.', 'demoDataDetails': {'description': 'Example contrast file', 'fileName': 'constrast.csv', 'filePath': 'apps/nf_encyclopedia/resources/contrast.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.proteomesoftware.com/hc/en-us/articles/360035151172-Prosit-Derived-Spectral-Libraries-for-Scaffold-DIA-Searches'}], 'previewFileName': 'apps/nf_encyclopedia/resources/contrast.csv'}, 'disabled': False, 'multiple': True, 'name': 'contrast_file', 'optional': True, 'title': 'Upload Contrast File (Optional)', 'uploadTypes': [{'title': 'Remote', 'type': 'remote'}, {'title': 'Local', 'type': 'local'}]}]"
Single Cell RNA-Seq Annotation: Custom Model,"Train a customized single cell annotation model, using scVI-Tools.","<p><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Train a customized single cell annotation model, using scVI-Tools. Data should be in .h5ad, .h5, mtx, or .csv format. Uses the Anndata python package, which natively supports .h5ad meaning that file format is most suitable. The target should be the feature you want to label: most commonly this will be cell type. Please ensure that the column with these values is selected. A model will be trained to predict cell type from input data, which can then be saved and used for other data sets, even where cell type is not known.<br><br></span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: bold; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Example use case: </span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Train a model that can annotate cell types after clustering single-cell RNA sequencing (scRNA-seq) data</span></p>",scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",6489ea4aa81ca5a299cbf02b,"[{'default_value': 'training', 'hidden': True, 'input_type': 'user_input', 'name': 'task_flag', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': 'scanvi_custom', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': {'label': 'cell_type', 'value': 'cell_type'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target', 'tooltip': 'Choose variable you want to annotate by or use for predictions on unseen data'}, {'default_value': 1500, 'increment': 100, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1000, 'min_value_inclusive': True, 'name': 'top_n', 'title': 'Filter Top N Genes', 'tooltip': 'Analyses differential expression and generates clusters using the top N genes by variability', 'type': 'integer'}, {'default_value': 400, 'increment': 10, 'input_type': 'slider', 'max_value': 1000, 'max_value_included': True, 'min_value': 50, 'min_value_inclusive': True, 'name': 'scvi_epochs', 'title': 'scVI Pretraining Epochs', 'tooltip': 'Number of epochs used to train scVI model', 'type': 'integer'}, {'default_value': 25, 'increment': 5, 'input_type': 'slider', 'max_value': 100, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Annotation Epochs', 'tooltip': 'Number of epochs used to train perform annotation', 'type': 'integer'}, {'decimalPlace': 1, 'default_value': 0.2, 'increment': 0.05, 'input_type': 'slider', 'max_value': 0.5, 'max_value_included': True, 'min_value': 0, 'min_value_inclusive': True, 'name': 'downsample_ratio', 'title': 'Downsample Ratio', 'tooltip': 'Used to downsample largest classes, to correct for imbalances', 'type': 'float'}, {'default_value': 8, 'increment': 1, 'input_type': 'slider', 'max_value': 128, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'n_latent', 'title': 'Number of Latent Variables', 'tooltip': 'The number of latent variables', 'type': 'integer'}, {'default_value': 64, 'increment': 1, 'input_type': 'slider', 'max_value': 512, 'max_value_included': True, 'min_value': 8, 'min_value_inclusive': True, 'name': 'n_hidden', 'title': 'Number of Hidden Variables', 'tooltip': 'The number of hidden variables', 'type': 'integer'}, {'default_value': 2, 'increment': 1, 'input_type': 'slider', 'max_value': 3, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'n_layers', 'title': 'Number of Layers', 'tooltip': 'The number of layers', 'type': 'integer'}, {'decimalPlace': 2, 'default_value': 0.1, 'increment': 0.1, 'input_type': 'slider', 'max_value': 0.5, 'max_value_included': True, 'min_value': 0, 'min_value_inclusive': True, 'name': 'dropout_rate', 'title': 'dropout_rate', 'tooltip': 'The dropout rate within the neural network', 'type': 'float'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, or .csv format', 'demoDataDetails': {'description': 'Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations. Dataset was filtered down randomly to 20k cells.', 'fileName': 'heart_atlas.h5ad', 'filePath': 'apps/scvi_tools/resources/heart_atlas.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.heartcellatlas.org/#DataSources'}], 'previewFileName': 'apps/scvi_tools/resources/heart_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Heart Cell Annotation: Single Cell Inference & Retraining,scANVI model trained on Heart Atlas dataset,"<p><span style=""display: inline !important; font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; orphans: 2; font-size: 16px; font-variant-ligatures: normal; font-family: Poppins, sans-serif; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; float: none; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">scANVI model trained on Heart Atlas dataset from The Heart Cell Atlas Database. Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations.</span></p>",scVI Tools,"['Classification', 'Single-Cell Bioinformatics']",6489eb01a81ca5a299cbf031,"[{'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task_flag', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Retrain', 'value': 'retraining'}], 'title': 'Infer Only or Retrain Model', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': '633744092ea319cdd26e71ea', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 100, 'disabled': True, 'increment': 10, 'input_type': 'slider', 'max_value': 400, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Max Epochs', 'tooltip': 'Maximum Epochs for Retraining', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Input data should be in .h5ad format. Gene names, along with the name of the target feature, should be same as those used in training dataset.', 'demoDataDetails': {'description': 'Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations.', 'fileName': 'heart_atlas.h5ad', 'filePath': 'apps/scvi_tools/resources/heart_atlas.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.heartcellatlas.org/#DataSources'}], 'previewFileName': 'apps/scvi_tools/resources/heart_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Liver Cell Annotation: Single Cell Inference,scANVI model trained on human liver cell dataset,"<p><span style=""font-style: normal; color: rgb(0, 0, 0); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">scANVI model trained on human liver cell dataset from: ""Single-cell and bulk transcriptomics of the liver reveals potential targets of NASH with fibrosis.""</span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span></p>",scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",6489ebe0a81ca5a299cbf036,"[{'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task_flag', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Retrain', 'value': 'retraining'}], 'title': 'Infer Only or Retrain Model', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': '633ef27d977fb7d39626d913', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 100, 'disabled': True, 'increment': 10, 'input_type': 'slider', 'max_value': 400, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Max Epochs', 'tooltip': 'Maximum Epochs for Retraining', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'mtx', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv, .mtx', 'value': ''}, 'dataStructure': 'Input data should be in .h5ad format. Gene names, along with the name of the target feature, should be same as those used in training dataset.', 'demoDataDetails': {'description': 'scANVI model trained on human liver cell dataset from: Single-cell and bulk transcriptomics of the liver reveals potential targets of NASH with fibrosis.', 'fileName': 'liver.h5ad', 'filePath': 'apps/scvi_tools/resources/liver.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-10553/results/tsne'}], 'previewFileName': 'apps/scvi_tools/resources/liver_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Mouse Retina Cell Annotation: Single Cell Inference,scANVI model trained on Mouse retinal bipolar neuron drop seq dataset,"<p><span style=""font-style: normal; color: rgb(0, 0, 0); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">scANVI model trained on Mouse retinal bipolar neuron drop seq dataset from: ""Comprehensive classification of retinal bipolar neurons by single-cell transcriptomics.""</span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">&nbsp;</span></p>",scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",6489ec86a81ca5a299cbf03b,"[{'default_value': 'inference', 'input_type': 'dropdown', 'name': 'task_flag', 'options': [{'label': 'Infer', 'value': 'inference'}, {'label': 'Retrain', 'value': 'retraining'}], 'title': 'Infer Only or Retrain Model', 'tooltip': 'Generate predictions only, or train a new model on this data', 'type': 'object'}, {'default_value': '633c25fc6bcba0d40b5adfbc', 'hidden': True, 'input_type': 'user_input', 'name': 'source_job_id', 'title': 'source_job_id', 'tooltip': 'NA', 'type': 'object'}, {'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 100, 'disabled': True, 'increment': 10, 'input_type': 'slider', 'max_value': 400, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'ann_epochs', 'title': 'Max Epochs', 'tooltip': 'Maximum Epochs for Retraining', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Input data should be in .h5ad format. Gene names, along with the name of the target feature, should be same as those used in training dataset.', 'demoDataDetails': {'description': 'scANVI model trained on Mouse retinal bipolar neuron drop seq dataset from: Comprehensive classification of retinal bipolar neurons by single-cell transcriptomics.', 'fileName': 'retina.h5ad', 'filePath': 'apps/scvi_tools/resources/retina.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/broadinstitute/BipolarCell2016/blob/master/README.md'}], 'previewFileName': 'apps/scvi_tools/resources/retina_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Single Cell RNA-Seq Annotation: Auto Train Model,Train a single cell annotation model using Auto ML and scVI-Tools,"<div><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Automatically train a single cell annotation model, using scVI-Tools. Data should be in .h5ad, .h5, mtx, or .csv format. Uses the Anndata python package, which natively supports .h5ad meaning that file format is most suitable. The target should be the feature you want to label: most commonly this will be cell type. Please ensure that the column with these values is selected. A model will be trained to predict cell type from input data, which can then be saved and used for other data sets, even where cell type is not known.<br><br></span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: bold; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Example use case: </span><span style=""font-style: normal; color: rgb(51, 51, 51); text-decoration-color: initial; font-weight: 400; box-sizing: border-box; orphans: 2; margin: 0px; font-size: 16px; padding: 0px; font-variant-ligatures: normal; font-family: Poppins, sans-serif !important; text-decoration-style: initial; background-color: rgb(255, 255, 255); font-variant-caps: normal; text-decoration-thickness: initial; text-align: start; text-indent: 0px; word-spacing: 0px; widows: 2; letter-spacing: normal; text-transform: none; webkit-text-stroke-width: 0px"">Train a model that can annotate cell types after clustering single-cell RNA sequencing (scRNA-seq) data</span></div>",scVI-Tools,"['Classification', 'Single-Cell Bioinformatics']",6489ed39a81ca5a299cbf040,"[{'default_value': 'scanvi_auto', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 'training', 'hidden': True, 'input_type': 'user_input', 'name': 'task_flag', 'title': 'task', 'tooltip': 'task', 'type': 'text'}, {'default_value': True, 'hidden': True, 'input_type': 'user_input', 'name': 'Auto', 'title': 'Auto', 'tooltip': 'Auto', 'type': 'text'}, {'default_value': {'label': 'cell_type', 'value': 'cell_type'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'target', 'options': [], 'title': 'Target', 'tooltip': 'Choose variable you want to annotate by or use for predictions on unseen data'}, {'default_value': {'label': 'Fast', 'value': 'Fast'}, 'disabled': False, 'input_type': 'dropdown', 'name': 'mode', 'options': [{'label': 'Fast', 'value': 'Fast'}, {'label': 'Standard', 'value': 'Standard'}, {'label': 'Intensive', 'value': 'Intensive'}], 'title': 'Auto Training Mode', 'tooltip': 'Choose âFastâ for quick results or for testing. Other modes should improve performance, but will take longer to train (n.b. intensive requires a GPU)'}]","[{'allowedFormats': {'fileExtensions': ['csv', 'h5ad', 'h5'], 'title': '.h5ad, .h5, .csv', 'value': ''}, 'dataStructure': 'Data should be in .h5, .h5ad, or .csv format', 'demoDataDetails': {'description': 'Combined single cell and single nuclei RNA-Seq data of 485K cardiac cells with annotations. Dataset was filtered down randomly to 20k cells.', 'fileName': 'heart_atlas.h5ad', 'filePath': 'apps/scvi_tools/resources/heart_atlas.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://www.heartcellatlas.org/#DataSources'}], 'previewFileName': 'apps/scvi_tools/resources/heart_sample.h5ad'}, 'disabled': False, 'name': 'train_path', 'supportsPreview': True, 'title': 'Single Cell RNA-Seq Data', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
Paper QA,Question and answering from PDFs with no hallucinations and with in-text citations.,"<p>Paper QA answers questions from documents with citations. Upload PDF files you wish to ask questions about. You can upload as many files as needed as long as the sum of the file sizes is less than 7 MB. You can upload more files later, even after submitting a question. Our engineers may review questions and responses to improve our systems and bug fixes. Please don't share any sensitive information.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Summarize findings of biomedical research papers</p>
<p><span style=""font-weight: bold"">Limitations</span>: You are limited to 5000 tokens per day. Tokens are refilled daily at 00:00UTC. Can cite a maximum of 3 sources. Contact us at help@superbio.ai to upgrade to premium to increase your token limit.</p>",Andrew White,"['Generative Model', 'Biomedical Language Models']",64906a5de7cbb2d88e2e0016,,"[{'allowedFormats': {'fileExtensions': ['txt', 'pdf'], 'title': '.pdf', 'value': 'application/pdf,text/plain'}, 'dataStructure': 'PDF files', 'demoDataDetails': {'description': '5kPBMC sample dataset from 10X genomics', 'fileName': 'matrix.mtx', 'filePath': 'apps/scvi_tools/resources/peakvi/matrix.mtx', 'fileSource': [{'title': 'Data Source', 'url': 'https://support.10xgenomics.com/single-cell-atac/datasets/1.2.0/atac_pbmc_5k_nextgem'}]}, 'disabled': False, 'multiple': True, 'name': 'file', 'requireValidation': False, 'supportsPreview': False, 'title': 'Upload Text', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
SATURN: Uniting Single-cell Gene Expressions with Protein Sequences for Cross-Species Integration,"SATURN is a deep learning method that uses protein language models to learn universal cell embeddings, enabling joint analysis of cross-species single-cell datasets. It integrates RNA expression with protein embeddings, allowing the detection of functionally related genes across species.","<p>Cell mapping consortia have generated large-scale single-cell datasets to understand cellular processes. However, analyzing datasets from different species together remains challenging. SATURN is a deep learning approach that integrates cross-species single-cell RNA expression data by combining gene expression with protein embeddings from language models. SATURN introduces the concept of macrogenes, functionally related gene groups, based on protein representations.</p>
<p>It enables multi-species differential expression analysis and facilitates the mapping of datasets to a universal embedding space. SATURN is applied to integrate diverse datasets like the Human Cell Atlas, Mouse Cell Atlas, and Fly Cell Atlas, resulting in a comprehensive mammalian cell atlas. It also integrates frog and zebrafish embryogenesis datasets.</p>
<p>SATURN successfully transfers annotations across species, identifies homologous and species-specific cell types, and reveals potential functional differences in glaucoma-associated genes. By leveraging protein language models, SATURN improves cross-species analysis, enhancing our understanding of evolutionary processes and the link between cellular diversity and anatomical/physiological variation.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Performing multi-species single-cell differential expression analysis.</p>
<p><span style=""font-weight: bold"">Technology:</span> Embeddings, Large Protein Language Models</p>
<p><span style=""font-weight: bold"">Limitation:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Some of the parameters were kept default. Please see this <span style=""text-decoration: underline; color: #0088FF""><a href=""https://github.com/snap-stanford/SATURN/blob/main/Vignettes/frog_zebrafish_embryogenesis/Train%20SATURN.ipynb"" >page</a></span> for more details.</li>
<li style=""list-style-type: disc"">The training part for protein embeddings is not accessible in this version. However, pre-trained protein embeddings are available, limited explicitly to ESM-2.</li>
<li style=""list-style-type: disc"">The 'cell_type' information for cell types must be provided in the 'obs' section of the .h5ad datasets.</li></ul>","Rosen Y, BrbiÄ M, Roohani Y, Swanson K, Li Z, Leskovec J.","['Differential Expression Analysis', 'h5ad', 'csv', 'Single-Cell Bioinformatics']",6492bdb8e7cbb2d88e2e00c3,"[{'default_value': {'label': 'Frog', 'value': 'frog'}, 'input_type': 'dropdown', 'name': 'file_embeddings_1', 'options': [{'label': 'Frog', 'value': 'frog'}, {'label': 'Zebrafish', 'value': 'zebrafish'}, {'label': 'Human', 'value': 'human'}, {'label': 'Macaca Fascicularis', 'value': 'macaca_fascicularis'}, {'label': 'Macaca Mulatta', 'value': 'macaca_mulatta'}, {'label': 'Mouse', 'value': 'mouse'}, {'label': 'Mouse Lemur', 'value': 'mouse_lemur'}, {'label': 'Pig', 'value': 'pig'}], 'title': 'Protein Embeddings 1', 'tooltip': 'To utilize SATURN, protein embeddings are required. You can utilize one of the publicly available protein embedding datasets that they provide. These datasets offer pre-computed protein embeddings that can be directly used with SATURN for your analysis.', 'type': 'str'}, {'default_value': {'label': 'Zebrafish', 'value': 'zebrafish'}, 'input_type': 'dropdown', 'name': 'file_embeddings_2', 'options': [{'label': 'Zebrafish', 'value': 'zebrafish'}, {'label': 'Frog', 'value': 'frog'}, {'label': 'Human', 'value': 'human'}, {'label': 'Macaca Fascicularis', 'value': 'macaca_fascicularis'}, {'label': 'Macaca Mulatta', 'value': 'macaca_mulatta'}, {'label': 'Mouse', 'value': 'mouse'}, {'label': 'Mouse Lemur', 'value': 'mouse_lemur'}, {'label': 'Pig', 'value': 'pig'}], 'title': 'Protein Embeddings 2', 'tooltip': 'To utilize SATURN, protein embeddings are required. You can utilize one of the publicly available protein embedding datasets that they provide. These datasets offer pre-computed protein embeddings that can be directly used with SATURN for your analysis.', 'type': 'str'}, {'default_value': 1000, 'increment': 10, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'num_macrogenes', 'title': 'num_macrogenes', 'tooltip': 'The number of macrogenes that are subjected to this analysis. By default, 1000 macrogenes.', 'type': 'integer'}, {'default_value': 4000, 'increment': 10, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 10, 'min_value_inclusive': True, 'name': 'hv_genes', 'title': 'hv_genes', 'tooltip': 'To subset each AnnData, you should specify the number of highly variable genes that need to be included in the subset. By default, 4000 most highly variable genes.', 'type': 'integer'}, {'default_value': {'label': 'wilcoxon', 'value': 'wilcoxon'}, 'input_type': 'dropdown', 'name': 'DE_method', 'options': [{'label': 'wilcoxon', 'value': 'wilcoxon'}, {'label': 'logreg', 'value': 'logreg'}, {'label': 't-test', 'value': 't-test'}, {'label': 't-test_overestim_var', 'value': 't-test_overestim_var'}], 'title': 'DE_method', 'tooltip': ""The 'method' parameter in scanpy.tl.rank_genes_groups refers to the statistical test method employed to identify differentially expressed genes. In this case, the method 'wilcoxon' indicates that the Wilcoxon rank-sum test (also known as the Mann-Whitney U test) is used. "", 'type': 'str'}, {'default_value': 200, 'increment': 1, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'pretraining_epoch', 'title': 'pretraining_epoch', 'tooltip': 'Number of pretraining epochs (default: 200)', 'type': 'integer'}, {'default_value': 50, 'increment': 1, 'input_type': 'slider', 'max_value': 10000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'metric_learning_epoch', 'title': 'metric_learning_epoch', 'tooltip': 'Number of epochs for metric learning (default: 50)', 'type': 'integer'}, {'default_value': 10, 'increment': 1, 'input_type': 'slider', 'max_value': 500, 'max_value_included': True, 'min_value': 5, 'min_value_inclusive': True, 'name': 'shown_num_macrogenes', 'title': 'shown_num_macrogenes', 'tooltip': 'Display the top macrogenes and their highest weights. By default, top 10 macrogenes will be shown.', 'type': 'integer'}, {'default_value': 'labels2', 'input_type': 'user_input', 'name': 'groupby', 'title': 'Group By', 'tooltip': 'The key of the observations grouping to consider in DE analysis.', 'type': 'text', 'validation': '^\\S*$'}, {'default_value': 'Ionocyte', 'input_type': 'user_input', 'name': 'groups', 'title': 'Groups', 'tooltip': 'Subset of groups, e.g. g1,g2,g3, to which comparison shall be restricted, or all, for all groups in DE analysis', 'type': 'text', 'validation': '^\\S*$'}, {'default_value': 'workflow', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['h5ad'], 'title': '.h5ad', 'value': '.h5ad'}, 'dataStructure': 'The h5ad format in scRNA-seq refers to the Hierarchical Data Format 5 (HDF5) Annotated Data format. It is commonly used to store single-cell gene expression data. The h5ad format organizes data in a hierarchical structure, including a raw gene expression matrix, cell and gene metadata, and additional annotations. Ensure that <strong>cell_type</strong> key is exist in <strong>obs</strong> section.', 'demoDataDetails': {'description': 'Demo .h5ad file of frog species from SATURN GitHub repo', 'fileName': 'frog.h5ad', 'filePath': 'apps/saturn/resources/frog.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/snap-stanford/SATURN/blob/main/Vignettes/frog_zebrafish_embryogenesis/dataloader.ipynb'}]}, 'disabled': False, 'name': 'file_h5ad_1', 'supportsPreview': False, 'title': 'Upload First Single Cell RNA-Seq Data File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['h5ad'], 'title': '.h5ad', 'value': '.h5ad'}, 'dataStructure': 'The h5ad format in scRNA-seq refers to the Hierarchical Data Format 5 (HDF5) Annotated Data format. It is commonly used to store single-cell gene expression data. The h5ad format organizes data in a hierarchical structure, including a raw gene expression matrix, cell and gene metadata, and additional annotations. Ensure that <strong>cell_type</strong> key is exist in <strong>obs</strong> section.', 'demoDataDetails': {'description': 'Demo .h5ad file of zebrafish species from SATURN GitHub repo', 'fileName': 'zebrafish.h5ad', 'filePath': 'apps/saturn/resources/zebrafish.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/snap-stanford/SATURN/blob/main/Vignettes/frog_zebrafish_embryogenesis/dataloader.ipynb'}]}, 'disabled': False, 'name': 'file_h5ad_2', 'supportsPreview': False, 'title': 'Upload Second Single Cell RNA-Seq Data File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}, {'allowedFormats': {'fileExtensions': ['csv', 'tsv', 'txt'], 'title': '.csv', 'value': ''}, 'dataStructure': 'A cell type mapping file is required during training as we perform scoring. It provides the necessary information for mapping cell types accurately. The file ensures that cell types are correctly labeled and associated with the corresponding cells in the dataset. Data should be in .csv format', 'demoDataDetails': {'description': 'Demo scoring .csv file from SATURN GitHub repo', 'fileName': 'frog_zebrafish_cell_type_map.csv', 'filePath': 'apps/saturn/resources/frog_zebrafish_cell_type_map.csv', 'fileSource': [{'title': 'Data Source', 'url': 'https://github.com/snap-stanford/SATURN/tree/main/Vignettes/frog_zebrafish_embryogenesis/data'}], 'previewFileName': 'apps/saturn/resources/frog_zebrafish_cell_type_map.csv'}, 'disabled': False, 'name': 'file_cell_type_map_csv', 'supportsPreview': True, 'title': 'Upload Cell Type Mapping File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
scGPT: Gene Regulatory Network Inference on Pre-trained Models,scGPT is a generative pre-trained transformer model explicitly designed for single-cell biology research and analysis.,"<p>scGPT is a foundation model for single-cell biology, based on generative pre-trained transformers trained on a vast repository of over 33 million cells. The scGPT model demonstrates the ability to extract valuable biological insights and can be further optimized through transfer learning for various downstream applications, including cell-type annotation, multi-batch integration, genetic perturbation prediction, and gene network inference.</p>
<p><span style=""font-weight: bold"">Example use case:</span> Gene regulatory network inference</p>
<p><span style=""font-weight: bold"">Technology:</span> Transformers</p>
<p><span style=""font-weight: bold"">Limitation:</span></p>
<ul style=""margin-left: 36pt"">
<li style=""list-style-type: disc"">Some of the parameters were kept default. Please see this <span style=""color: #0088FF""><a href=""https://scgpt.readthedocs.io/en/latest/tutorial_grn.html"" >page</a></span> for more details.</li></ul>",Haotian Cui and Chloe Wang and Hassaan Maan and Kuan Pang and Fengning Luo and Bo Wang,"['Transformers', 'h5ad', 'Single-Cell Bioinformatics']",64b804fb823bc93b64c10a76,"[{'default_value': 3, 'increment': 1, 'input_type': 'slider', 'max_value': 5000, 'max_value_included': True, 'min_value': -1, 'min_value_inclusive': True, 'name': 'filter_gene_counts', 'title': 'Filter Gene Counts', 'tooltip': 'Filter genes based on number of cells or counts. If the value is -1, the filter will not be applied.', 'type': 'integer'}, {'default_value': -1, 'increment': 1, 'input_type': 'slider', 'max_value': 5000, 'max_value_included': True, 'min_value': -1, 'min_value_inclusive': True, 'name': 'filter_cell_counts', 'title': 'Filter Cell Counts', 'tooltip': 'Filter cell outliers based on counts and numbers of genes expressed. If the value is -1, the filter will not be applied.', 'type': 'integer'}, {'default_value': 4, 'increment': 1, 'input_type': 'user_input', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'filter_genes_on_cluster', 'title': 'Filter Genes On Cluster', 'tooltip': ""Number of highly-variable genes to keep. Mandatory if flavor='seurat_v3'"", 'type': 'integer'}, {'default_value': 1200, 'increment': 1, 'input_type': 'user_input', 'max_value': 10000, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'number_hvg', 'title': 'Number of Highly Variable Genes', 'tooltip': 'Obtain the set of gene programs from clusters with #genes > 4. Default:4', 'type': 'integer'}, {'default_value': {'label': 'cell_ranger', 'value': 'cell_ranger'}, 'input_type': 'dropdown', 'name': 'hvg_flavor', 'options': [{'label': 'cell_ranger', 'value': 'cell_ranger'}, {'label': 'seurat_v3', 'value': 'seurat_v3'}, {'label': 'seurat', 'value': 'seurat'}], 'title': 'hvg_flavor', 'tooltip': 'Choose the flavor for identifying highly variable genes.', 'type': 'str'}, {'default_value': {'label': 'Reactome_2022', 'value': 'Reactome_2022'}, 'input_type': 'dropdown', 'name': 'db_pathway', 'options': [{'label': 'Reactome_2022', 'value': 'Reactome_2022'}, {'label': 'GO_Biological_Process_2021', 'value': 'GO_Biological_Process_2021'}, {'label': 'GO_Molecular_Function_2021', 'value': 'GO_Molecular_Function_2021'}], 'title': 'db_pathway', 'tooltip': 'Choose database for pathway analysis. Default: Reactome', 'type': 'str'}, {'default_value': {'label': 'human_blood', 'value': 'human_blood'}, 'input_type': 'dropdown', 'name': 'pretrained_model', 'options': [{'label': 'human_all', 'value': 'human_all'}, {'label': 'human_blood', 'value': 'human_blood'}, {'label': 'human_brain', 'value': 'human_brain'}, {'label': 'human_heart', 'value': 'human_heart'}, {'label': 'human_kidney', 'value': 'human_kidney'}, {'label': 'human_lung', 'value': 'human_lung'}, {'label': 'human_pancancer', 'value': 'human_pancancer'}], 'title': 'pretrained_model', 'tooltip': 'Please select one of the pretrained models.', 'type': 'str'}, {'default_value': 'batch', 'hidden': False, 'input_type': 'user_input', 'name': 'batch_key', 'placeholder': 'None', 'title': 'Batch Column Name', 'tooltip': 'The key of AnnData.obs to use for batch information. This parameter is used in the highly variable gene selection step. Please type <None> if there is no batch in the dataset.', 'type': 'text', 'validation': '^\\S*$'}, {'default_value': 'final_annotation', 'hidden': False, 'input_type': 'user_input', 'name': 'celltype_col_name', 'placeholder': 'final_annotation', 'title': 'Cell Type Column Name', 'tooltip': 'The column name of cell type in AnnData.obs to use for algorithm. Please provide the column name for the cell type in your dataset. Default: final_annotation', 'type': 'text', 'validation': '^\\S*$'}, {'default_value': 'workflow.yml', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}, {'default_value': 3, 'increment': 1, 'input_type': 'user_input', 'max_value': 100, 'max_value_included': True, 'min_value': 1, 'min_value_inclusive': True, 'name': 'gene_program_index', 'title': 'Index Number of Gene Program', 'tooltip': 'The visualization of the connectivity between genes within any gene program can be achieved. To succeed in this step, we need to retrieve the gene program index, with the default set as 3, as shown in the example code in their tutorial. After the initial analysis with your own data, you can then choose the desired index.', 'type': 'integer'}]","[{'allowedFormats': {'fileExtensions': ['h5ad'], 'title': '.h5ad', 'value': '.h5ad'}, 'dataStructure': 'The h5ad format in scRNA-seq refers to the Hierarchical Data Format 5 (HDF5) Annotated Data format. It is commonly used to store single-cell gene expression data. The h5ad format organizes data in a hierarchical structure, including a raw gene expression matrix, cell and gene metadata, and additional annotations. Ensure that <strong>celltype</strong> key is exist in <strong>obs</strong> section.', 'demoDataDetails': {'description': 'Demo immune human dataset file from scGPT documentation.', 'fileName': 'Immune_ALL_human.h5ad', 'filePath': 'apps/scgpt/resources/Immune_ALL_human.h5ad', 'fileSource': [{'title': 'Data Source', 'url': 'https://scgpt.readthedocs.io/en/latest/tutorial_grn.html#Step-1:-Load-pre-trained-model-and-dataset'}], 'previewFileName': 'apps/scgpt/resources/Immune_ALL_human.h5ad'}, 'disabled': False, 'name': 'file_h5ad', 'supportsPreview': True, 'title': 'Upload Single Cell RNA-Seq Data File', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"
DeepLIIF Inference,Segment cells by positive versus negative protein expression levels,,Memorial Sloan Kettering Cancer Center,"['Image Segmentation', 'zip', 'Biomedical Image Analysis and Interpretation']",64c3f597823bc93b64c10c1e,"[{'default_value': {'label': 'File name', 'value': 'filename'}, 'input_type': 'dropdown', 'name': 'breakdown', 'options': [{'label': 'Category', 'value': 'category'}, {'label': 'File name', 'value': 'filename'}], 'title': 'Breakdown results by', 'tooltip': 'Arrange images in results by file name or image type', 'type': 'str'}, {'default_value': 'inference', 'hidden': True, 'input_type': 'user_input', 'name': 'workflow_name', 'title': 'workflow_name', 'tooltip': 'workflow_name', 'type': 'text'}]","[{'allowedFormats': {'fileExtensions': ['zip', 'gz', 'tar', 'zip'], 'title': 'Files must be provided in .zip, .gz, or .tar compressed format', 'value': ''}, 'dataStructure': 'Images should be provided in a .zip, .gz or .tar compressed file', 'demoDataDetails': {'description': '20 example breast carcinoma images from DeepLIIF paper', 'fileName': 'sample_images.zip', 'filePath': 'apps/deepliif/sample_images.zip', 'fileSource': [{'title': 'Data Source', 'url': 'https://zenodo.org/record/4751737#.YKRTS0NKhH4'}]}, 'disabled': False, 'name': 'test_path', 'supportsPreview': False, 'title': 'Images for inference', 'uploadTypes': [{'title': 'Local', 'type': 'local'}, {'title': 'Remote', 'type': 'remote'}]}]"